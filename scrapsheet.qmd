---
title: "Scrapsheet"
---

Grocery list

-   Lunch
    -   Grilled chicken breasts?
-   3lbs of hamburger
-   Pop Tarts
    -   brown sugar cinnamon
    -   smores
-   Snack
    -   Chips
    -   Snickers
-   Frozen
    -   curly fries
    -   frozen breakfast burritos
    -   blueberry waffles
    -   snack to replace frozen pizzas

-   Notes from <https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/>

    -   To ensure that a project is reproducible you need to deal with at least four things:

        -   Make sure that the required/correct version of R (or any other language) is installed
        -   Make sure that the required versions of packages are installed
        -   Make sure that system dependencies are installed (for example, you'd need a working Java installation to install the {rJava} R package on Linux)
        -   Make sure that you can install all of this for the hardware you have on hand.

    -   Consensus seems to be a mixture of Docker to deal with system dependencies,`{renv}`for the packages (or`{groundhog}`, or a fixed CRAN snapshot like those [Posit provides](https://packagemanager.posit.co/__docs__/user/get-repo-url/#ui-frozen-urls)) and the [R installation manager](https://github.com/r-lib/rig) to install the correct version of R (unless you use a Docker image as base that already ships the required version by default). As for the last point, the only way out is to be able to compile the software for the target architecture.

    -   Nix

        -   a package manager for Linux distributions, macOS and apparently it even works on Windows if you enable WSL2.

        -   huge package repository, over 80K packages

        -   possible to install software in (relatively) isolated environments

-   text tiling

    -   Previous articles
        -   5 sentence chunks - Instead of creating chunks large enough to fit into a context window (langchain default), I propose that the chunk size should be the number of sentences it generally takes to express a discrete idea. This is because we will later embed this chunk of text, essentially distilling its semantic meaning into a vector. I currently use 5 sentences (but you can experiment with other numbers). I tend to have a 1-sentence overlap between chunks, just to ensure continuity so that each chunk has some contextual information about the previous chunk. ([2-stage summarizing method](https://towardsdatascience.com/summarize-podcast-transcripts-and-long-texts-better-with-nlp-and-ai-e04c89d3b2cb))
        -   Chunk markdown documents by section using header tags (h1, h2, etc.) ([company doc searchable db](https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#8ed1))
        -   Chunk size = Context window size (langchain default)
    -   [nltk.tokenize.texttiling](https://www.nltk.org/_modules/nltk/tokenize/texttiling.html) - text tiling method from {{nltk}}
    -   Created a test document that was the amalgam 4 different articles that can be used to test tiling method undefined

-   bayesian vid (currently at 23:14)

    -   in observational analysis its imagined that sample is drawn from a joint distribution of all the variables
    -   in causal inf, imagine intervening to change Z, treatment, independent of X, confounders.
    -   Frequentist method: G-Estimation
        -   Models
            -   propensity score models, $b(x;\gamma)$
                -   Equivalent to $\text{Pr} [Z = 1 |x]$

                -   Estimating Equation for $\gamma$

                    $$
                    \sum \limits_{i=1}^n x_i^T (z_i - b(x_i; \gamma)) = 0
                    $$
            -   treatment free mean model, $\mu_0(x; \beta)$
                -   Used for doubly robust estimation
            -   treatment effect (or blip) model $\tau z$, which can be extended to $z\mu_1(x;\tau)$
        -   Propensity Score Regression\
            \$\$\
            Y = Z \\tau + b(X; \\hat{\\gamma}) \\phi + \\epsilon\
            \$\$
            -   $\phi$ is the estimated coefficient for the propensity score model
    -   Bayesian
        -   There are other ways but this procedure is recommended
        -   Perform full Bayesian estimation of $\gamma$ , plug that (best) estimate into the propensity score model, $b(x_i; \hat{\gamma})$ , and then perform Bayesian analysis of $\tau$ (i.e. propensity score regression)
            -   The propensity score model part of the formula is basically a hack and not mimmicking any part of the dgp therefore for bayesians, the regression model is a misspecification.\
