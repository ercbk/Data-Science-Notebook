---
title: "Scrapsheet"
---

## Grocery list

-   

-   Snack

-   Frozen

## Propensity Score Analysis (PSA)

-   Notes from:

    -   nyhackr meet-up [Video](https://www.youtube.com/watch?v=JLV4mtFhRMM)
    -   Vignette: [PSAgraphics: An R Package to Support Propensity Score Analysis](https://www.jstatsoft.org/article/view/v029i06#:~:text=PSAgraphics%20is%20an%20R%20package,having%20adjusted%20for%20covariate%20differences.)
    -   Book: [Applied Propensity Score Analysis in R](https://psa.bryer.org/)

-   If two people have similar propensity scores, then they will be similar in all the values of the covariates that were used to create that score

-   `psa::psa_simulation_shiny` - App that simulates and visualizes balance of groups according effect size, sample size, estimand (e.g ATE, ATT, etc.), and PSA method

-   Methods:

    -   Stratification - Treatment and Comparison (aka Control) units are divided into strata (or subclasses) based upon a propensity score (e.g. quantiles), so that treated and comparison units are similar within each strata.

        -   Logistic Regression (treatment/control \~ covariates) can be used to estimate scores (i.e. predicted logits)

        ``` r
        lr.out <- 
          glm(
          treatment ~ x1 + x2 + x3,
          data = dat,
          family = binomial(link = logit)
          )
        dat$ps <- fitted(lr.out)
        ```

        -   5 stratum removes \> 90% of the bias in estimated treatment effect (Cochran 1968)

            ``` r
            breaks5 <- psa::get_strata_breaks(dat$ps)
            dat$strata5 <-
              cut(
                x = dat$ps,
                breaks = breaks5$breaks,
                include.lowest = TRUE,
                labels = breaks5$labels$strata
              )
            ```

        -   With Regression, each strata has very similar numbers of observations.

        -   Trees, strata are determined by the leaf nodes and each strata generally differs in the numbers of observations.

            -   In a decision tree example, strata had some funky proportions in relation to the categorical and continuous predictors (see Paper)

        -   Within each stratum, independent sample t-tests are conducted and then pooled to provide an overall estimate

    -   Matching - Each treatment unit is paired with a comparison unit base upon the pre-treatment covariates

        -   Algorithms

            -   Propensity Score Matching

            -   Limited Exact Matching

            -   Full Matching

            -   Nearest Neighbor Matching

            -   Optimal/Generic Matching

            -   Mahalanobis distance matching (quantitative covariates only)

            -   Matching with and without replacement

            -   One-to-One or One-to-Many Matching

        -   Choice of algorithm is trial and error --- whichever one gives the best balance.

        -   Dependent sample tests (e.g. repeated mearsures, t-test w/paired = TRUE) are conducted using the match pairs.

    -   Weighting - Each observation is weighted by the inverse of probability of being in that group

        -   Propensity Scores are used as weights for the regression model that you'll use to perform your analysis.

            -   The specific weights will depend on the estimand (e.g ATE, ATT, etc.)

        -   Average Treatment Effect (ATE): $\text{ATE} = E(Y_1 - Y_0|X) = E(Y_1|X) - E(Y_0|X)$

            -   Weight: $w_{\text{ATE}} = \frac{Z_i}{\pi_i} + \frac{1-Z_i}{1-\pi_i}$

            -   $Z_i = 1$ says the unit is in the treatment group

            -   Not sure what $\pi_i$ is.

            -   [Example]{.ribbon-highlight}:

                ``` r
                dat <- 
                  dat |> 
                  mutate(
                    ate_weights = psa::calculate_ps_weights(treatment, ps, estimand = "ATE"))

                # via {psa}
                psa::treatment_effect(
                  treatment = dat$treatment,
                  outcome = dat$outcome,
                  weights = dat$ate_weights
                )
                # via lm
                lm(outcome ~ treatment,
                   data = dat,
                   weights = dat$ate_weights)
                ```

        -   ATE Among the Treated (ATT): $\text{ATT} = E(Y_1 - Y_0|X,C = 1) = E(Y_1|X,C = 1) - E(Y_)|X,C = 1)$

            -   Weight: $w_{\text{ATT}} = \frac{\pi_i Z_i}{\pi_i} + \frac{\pi_i(1-Z_i)}{1-\pi_i}$

            -   [Example]{.ribbon-highlight}:

                ``` r
                dat <- 
                  dat |> 
                  mutate(
                    att_weights = psa::calculate_ps_weights(treatment, ps, estimand = "ATT"))

                # via {psa}
                psa::treatment_effect(
                  treatment = dat$treatment,
                  outcome = dat$outcome,
                  weights = dat$att_weights
                )
                # via lm
                lm(outcome ~ treatment,
                   data = dat,
                   weights = dat$att_weights)
                ```

        -   ATE Among the Control (ATC): $\text{ATC} = E(Y_1- Y_0|X = 0) = E(Y_1|X = 0) - E(Y_0|X = 0)$

            -   Weight: $w_{\text{ATC}} = \frac{(1-\pi_i)Z_i}{\pi_i} + \frac{(1-e_i)(1-Z_i)}{1-\pi_i}$

            -   Not sure what $e_i$ is

            -   [Example]{.ribbon-highlight}: Same as above except with ATC weights

        -   ATE Among the Evenly Matched (ATM): $\text{ATM}_d = E(Y_1 - Y_0|M_d = 1)$

            -   Weight: $w_{\text{ATM}} = \frac{\min\{\pi_i, 1-\pi_i\}}{Z_i \pi_i(1-Z_i)(1-\pi_i)}$

            -   [Example]{.ribbon-highlight}: Same as above except with ADM weights

        -   Shows mirrored axis histogram with PS on x-axis and count on y-axis; guessing treatment/control are top/bottom histograms?

        -   Treament Effects for Weighting

            $$
            \text{TE} = \frac{\sum Y_iZ_i}{\sum Z_i w_i} - \frac{Y_i(1-Z_i)w_i}{\sum(1-Z_i)w_i}
            $$

-   Process

    -   Phase 1
        -   Select covariates

            -   Typically whatever variables are available if it's a secondhand dataset
            -   If running and experiment, collect data that will demonstrate baseline equivalence (?), which can later be used in a PSA

        -   Choose PSA method

        -   Check Balance (i.e. do observations in treatment and control look equivalent)

        -   Repeat if necessary until sufficient balance is achieved
    -   Phase 2
        -   Estimate Treatment Effects
    -   Phase 3
        -   Sensitivity Analysis
            -   Test how sensitive the results are to an unobserved confounder
                -   i.e. How much variance would a variable need to have before it changes the results (sign change or just significance?)
        -   Go back to Phase I and choose a different method
            -   Tests how sensitive the results are to the PSA method chosen

-   Visualization

    -   Distribution of propensity scores

        ``` r
        ggplot(dat) +
          geom_histogram(
            data = dat[dat$treatment == 1, ],
            aes(x = ps, y = after_stat(count)),
            bins = 50,
            fill = cols[2]
          ) +
          geom_histogram(
            data = dat[dat$treatment == 0, ],
            aes(x = ps, y = -after_stat(count)),
            bins = 50,
            fill = cols[3]
          ) +
          geom_hline(
            yintercept = 0,
            lwd = 0.5
          ) + 
          scale_y_continuous(lable = abs)
        ```

    -   Multiple Covariate Balance Plot

        ``` r
        PSAgraphics::cv.bal.psa(
          dat[, 1:3],
          data$treatment,
          dat$ps,
          strata = 5
        )
        ```

        -   Absolute standardized Covariate effect sizes with (blue) and without (red) PS adjustment

        -   Want blue dots close to zero which says that after PS adjustment, the covariates have little predictive power in determining whether a unit is in the treatment group or control group. It means the PS are effectively adjusting for the selection bias of the treatment/control "assignment" in the observational data.

    -   Boxplot by Propensity Score Strata by Treatment

        ``` r
        PSAgraphics::box.psa(
          continuous = dat$x2,
          treatment = dat$treatment,
          strata = dat$strata5
        )
        ```

        -   For a continuous predictor, it allows you to visually examine the balance produced by the PS strata by comparing the distributions between treatment and control within each strata

        -   Connected dots are the means within each distribution and numbers below each box are its sample size.

            -   Setting [trim = 0.5]{.arg-text} will connect medians. (Range of trim is from 0 to 0.5)

        -   *Within* strata, the more similar the distributions between treatment and control, the better the balance. Balance should be assessed for each predictor.

        -   Trends or patterns *between* strata can hint at potential variation and may help explain effects detected in the later performed analysis

            -   Units in higher strata (i.e. higher PS) are more likely to be treated than those in lower strata, so looking at the values of predictor, you can say whether those with higher or lower values of the predictor are more likely to be treated.

        -   With [balance = TRUE]{.arg-text} (default is FALSE),

            -   Histogram

                -   Permuted data are randomly assigned to strata, absolute differences of means calculated within each strata, and the differences summed to produce the statistic.

                -   Repeated until there's a distribution which is then visualized as a histogram

                -   The sum of the mean differences of the original data is represented by a red dot.

                -   The further left the red dot is from the mean (or median with [trim = 0.5]{.arg-text}) of the permuation distribution, the better the balance

                    -   i.e. the **smaller** the sum of mean differences of the original data as compared the permuted distribution of sums of mean differences, the better.

                    -   The rank shows where the original data statistic ranks in comparison to all of the summed differences in the permuted distribution.

                        -   Total_number_of_ranks = number_of_permutations + 1 (aka original data)

            -   Boxplot

                -   P-Values for KS-tests on treatment and control distributions are placed above the sample sizes of each strata. A *lack* of balance for a given strata would be indicated by a p-value \< 0.05.

    -   Stacked Bar Chart by Propensity Score Strata by Treatment

        ``` r
        PSAgraphics::cat.psa(
          categorical = dat$x3,
          treatment = dat$treatment,
          strata = dat$strat5
        )
        ```

        -   For a categorical predictor, it allows you to visually examine the balance produced by the PS strata by comparing the category proportions between treatment and control within each strata
        -   Within each strata, side-by-side segmented bars can be used to compare proportions of cases in each category
        -   Sample sizes are above each bar
        -   if subsequent analysis indicates large differences in size or direction of effects for different strata, then comparing covariate distributions across strata may give an initial indication of potential causes.
        -   With [balance = TRUE]{.arg-text} (default is FALSE), it's very similar to `box.psa`.
            -   Histogram
                -   Units within each category are permuted between strata
                -   Differences in proportions is used instead of difference in means
                -   Interpretation is the same
            -   Fisher's Exact Tests are performed and the p-values are shown at the bottom of the bars for each strata. A *lack* of balance for a given strata would be indicated by a p-value \< 0.05.

    -   Propensity Score Assessment Plot

        ``` r
        # code
        ```

        -   When differences in outcomes between treatments vary across strata, the investigator may want to learn how these differences are related to changes in covariate distributions within the strata.

        -   Displays contributions of individual strata to the overall effect, weighing contributions of individual strata according to the relative sizes of the respective strata. The overall effect is plotted as a heavy dashed diagonal line that runs parallel to the identity diagonal.

        -   The x-axis is the response values when treatment = 0, and the y-axis is the response values when treatment = 1. Labels depend on the values of the treatment variable.

        -   Circles

            -   Each circle represents a stratum, and the sizes of circles vary according to their respective sample sizes.

            -   The center of each stratum's circle corresponds to outcome means for the respective control and treatment groups for that stratum.

            -   The blue dashed line is the mean of the differences between the strata which is the ATE, and the green line is its 95%CI.

            -   CIs become increasingly unreliable for larger values of the trim arg.

        -   The vertical and horizontal dashed red lines represent the (weighted) response means for the control and treatment groups respectively.

        -   Interpretation

            -   Circles on the lower side of diagonal black line show that the corresponding x-axis (e.g. treatment = 0) mean for that strata is larger than the y-axis (e.g. treatment = 1) mean for that stratum

            -   Circles close proximity to one another on the same side of the diagonal indicates concordance of outcome values in these strata

            -   Circles far outside of the cluster of circles should be investigated via the other predictor charts above to see what characteristics make-up that particular strata. If the sizes of each strata aren't relatively balanced, then a strata with few units may present outside the cluster.

            -   The distance of the crosses from the diagonal indicates size of estimated effect. A stratum with a much larger effect would influence the ATE more strongly.

    -   LOESS Plot

        -   Can be used to define strata boundarys. Potential boundaries are indicated where the treatment and control lines narrow or cross.

            -   e.g. Setting `int = c(0.375, 0.55, 0.875, 1)` says that 0.357 and 1 are the minimum and maximum propensity scores and 0.55 and 0.875 are scores where the loess lines narrow or cross. This would represent 3 strata: (0.375, 0.55], (0.55, 0.875], and (0.875, 1].

## Reproducibility

-   Notes from <https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/>
-   To ensure that a project is reproducible you need to deal with at least four things:
    -   Make sure that the required/correct version of R (or any other language) is installed
    -   Make sure that the required versions of packages are installed
    -   Make sure that system dependencies are installed (for example, you'd need a working Java installation to install the {rJava} R package on Linux)
    -   Make sure that you can install all of this for the hardware you have on hand.
-   Consensus seems to be a mixture of Docker to deal with system dependencies,`{renv}`for the packages (or`{groundhog}`, or a fixed CRAN snapshot like those [Posit provides](https://packagemanager.posit.co/__docs__/user/get-repo-url/#ui-frozen-urls)) and the [R installation manager](https://github.com/r-lib/rig) to install the correct version of R (unless you use a Docker image as base that already ships the required version by default). As for the last point, the only way out is to be able to compile the software for the target architecture.
-   Nix
    -   a package manager for Linux distributions, macOS and apparently it even works on Windows if you enable WSL2.

    -   huge package repository, over 80K packages

    -   possible to install software in (relatively) isolated environments

## Text Tiling

-   Previous articles

    -   5 sentence chunks - Instead of creating chunks large enough to fit into a context window (langchain default), I propose that the chunk size should be the number of sentences it generally takes to express a discrete idea. This is because we will later embed this chunk of text, essentially distilling its semantic meaning into a vector. I currently use 5 sentences (but you can experiment with other numbers). I tend to have a 1-sentence overlap between chunks, just to ensure continuity so that each chunk has some contextual information about the previous chunk. ([2-stage summarizing method](https://towardsdatascience.com/summarize-podcast-transcripts-and-long-texts-better-with-nlp-and-ai-e04c89d3b2cb))
    -   Chunk markdown documents by section using header tags (h1, h2, etc.) ([company doc searchable db](https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#8ed1))
    -   Chunk size = Context window size (langchain default)

-   [nltk.tokenize.texttiling](https://www.nltk.org/_modules/nltk/tokenize/texttiling.html) - text tiling method from {{nltk}}

-   Created a test document that was the amalgam 4 different articles that can be used to test tiling method undefined

## Propensity Score Models?

-   bayesian vid (currently at 23:14)
    -   I don't remember which video this is
-   in observational analysis its imagined that sample is drawn from a joint distribution of all the variables
-   in causal inf, imagine intervening to change Z, treatment, independent of X, confounders.
-   Frequentist method: G-Estimation
    -   Models

        -   propensity score models, $b(x;\gamma)$
            -   Equivalent to $\text{Pr} [Z = 1 |x]$

            -   Estimating Equation for $\gamma$

                $$
                \sum \limits_{i=1}^n x_i^T (z_i - b(x_i; \gamma)) = 0
                $$
        -   treatment free mean model, $\mu_0(x; \beta)$
            -   Used for doubly robust estimation
        -   treatment effect (or blip) model $\tau z$, which can be extended to $z\mu_1(x;\tau)$

    -   Propensity Score Regression\

        $$
        Y = Z \tau + b(X; \hat{\gamma}) \phi + \epsilon
        $$

        -   $\phi$ is the estimated coefficient for the propensity score model
-   Bayesian
    -   There are other ways but this procedure is recommended
    -   Perform full Bayesian estimation of $\gamma$ , plug that (best) estimate into the propensity score model, $b(x_i; \hat{\gamma})$ , and then perform Bayesian analysis of $\tau$ (i.e. propensity score regression)
        -   The propensity score model part of the formula is basically a hack and not mimmicking any part of the dgp therefore for bayesians, the regression model is a misspecification.

## Copulas

-   I think copulas are used for bias correction in post-processing separate forecasts of variables that are related. See [paper](https://www.annualreviews.org/doi/10.1146/annurev-statistics-062713-085831#_i59) (section 4.2 and 4.3)
    -   stocks of the same sector
    -   ensemble forecasts
        -   weather - meteorologists will forecast a variable (e.g. temp) many times but each time the model uses a different set of atmosphereic conditions. These forecasts are put into a regression (i.e. the ensemble) to create the final forecast. But that forecast is biased because the forecasts are related to each other. Post-processing with copula corrects this.
-   Ensemble Copula Coupling (ECC) applies the empirical copula of the original ensemble to samples from the postprocessed predictive distributions. ([paper](https://arxiv.org/pdf/1302.7149.pdf))
    1.  Generate a raw ensemble, consisting of multiple runs of the computer model that differ in the inputs or model parameters in suitable ways.
    2.  Apply statistical postprocessing techniques, such as Bayesian model averaging or nonhomogeneous regression, to correct for systematic errors in the raw ensemble, to obtain calibrated and sharp predictive distributions for each univariate output variable individually.
    3.  Draw a sample from each postprocessed predictive distribution.
    4.  Rearrange the sampled values in the rank order structure of the raw ensemble to obtain the ECC postprocessed ensemble
-   Depending on the use of Quantiles, Random draws or Transformations at the sampling stage, we distinguish the ECC-Q, ECC-R and ECC-T variants
-   ECC is based on empirical copulas aimed at restoring the dependence structure of the forecast and is derived from the rank order of the members in the raw ensemble forecast, under a perfect model assumption, with exchangeable ensemble members. For Schaake shuffle (SSH), on the other hand, the dependence structure is derived from historical observations instead. (Overview of subject - [paper](https://journals.ametsoc.org/view/journals/bams/102/3/BAMS-D-19-0308.1.xml))
-   Packages
    -   <https://cran.r-project.org/web/packages/ensembleBMA/index.html>
    -   <https://cran.r-project.org/web/packages/ensemblepp/index.html>
        -   Data for book, Statistical Postprocessing of Ensemble Forecasts
    -   <https://cran.r-project.org/web/packages/ensembleMOS/index.html>\
