# ANOVA {#sec-phoc-anova .unnumbered}

## Misc {#sec-phoc-anova-misc .unnumbered}

-   Assumptions
    -   Each group category has a normal distribution.
    -   Each group category is independent of each other and identically distributed (iid)
    -   Group categories have of *similar* variance (i.e. homoskedastic variance)
        -   If this is violated

            -   and the ratio of the largest variance to the smallest variance is less than 4, then proceed with one-way ANOVA (robust to small differences)
            -   and the ratio of the largest variance to the smallest variance is greater than 4, we may instead choose to perform a Kruskal-Wallis test. This is considered the non-parametric equivalent to the one-way ANOVA. ([example](https://www.statology.org/kruskal-wallis-test-r/))

        -   EDA

            ``` r
            data %>%
              group_by(program) %>%
              summarize(var=var(weight_loss))
            #> A tibble: 3 x 2
            #>   program  var   
            #> 1 A      0.819
            #> 2 B      1.53 
            #> 3 C      2.46
            ```

        -   Perform a statisical test to see if these variables are statistically significant (See [Post-Hoc Analysis, Difference-in-Means \>\> EDA \>\> Tests for Equal Variances](post-hoc-analysis-general.qmd#sec-phoc-gen-eda-tfev){style="color: green"})
-   Eta Squared
    -   Metric to describe the effect size of a variable
    -   Range: \[0, 1\]; values closer to 1 indicating that a specific variable in the model can explain a greater fraction of the variation
    -   `lsr::etaSquared(anova_model)` (use first column of output)
    -   Guidelines
        -   0.01: Effect size is small.
        -   0.06: Effect size is medium.
        -   Large effect size if the number is 0.14 or above

## Mathematics {#sec-phoc-anova-math .unnumbered}

-   Asides:

    -   these look like the  variance formula except for not dividing by the sample size to get the "average" squared distance
    -   SSA formula - the second summation just translates to multiplying by ni, the group category sample size, since there is no j in that formula

-   Calculate SSA and SSE

    $$
    \begin{align}
    \text{SST} &= \text{SSA} + \text{SSE} \\
    &= \sum_{i = 1}^a \sum_{j=i}^{n_i} (x_{i,j} - \mu)^2 \\
    &= \sum_{i = 1}^a \sum_{j=i}^{n_i} (\bar x_i - \mu)^2 + \sum_{i = 1}^a \sum_{j=i}^{n_i} (x_{i,j} - \bar x_i)^2
    \end{align}
    $$

    -   $\text{SST}$: Sum of Squares Total
    -   $\text{SSA}$: Sum of Squares between categories, treatments, or factors
        -   "A" stands for attributes (i.e. categories)
    -   $\text{SSE}$: Sum of Squares of Errors; randomness within categories, treatments, or factors
    -   $x_{ij}$: The j^th^ observation of the i^th^ category
    -   $\bar x_i$: The sample mean of category i
    -   $\mu$: The overall sample mean
    -   $n_i$: The group category sample size
    -   $a$: The number of group categories

-   Calculate MSA and MSE

    $$
    \begin{align}
    \text{MSE} &= \frac{\text{SSE}}{N-a} \\
    \text{MSA} &= \frac{\text{SSA}}{a-1}
    \end{align}
    $$

    -   Where N is the total sample size

-   Calculate the F statistic and P-Value

    $$
    F = \frac{\text{MSA}}{\text{MSE}}
    $$

    -   Find the p-value (need a table to look it up)
    -   If our F statistic is less than the critical value F statistic for a α=0.05 than we cannot reject the null hypothesis (no statistical difference between categories)

-   Discussion

    -   If there is a group category that has more variance than the others attribute error (SSA) we should then pick that up when we compare it to the random error (SSE)
        -   If a group is further away from the overall mean then it will increase SSA and thus influence the overall variance but might not always increase random error

## Post-ANOVA Tests {#sec-phoc-gen-fdim-panov .unnumbered}

-   Assume approximately Normal distributions
-   For links to more details about each test, https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/post-hoc/
-   **Duncan's new multiple range test (MRT)**
    -   When you run Analysis of Variance (ANOVA), the results will tell you if there is a difference in means. However, it won't pinpoint the pairs of means that are different. Duncan's Multiple Range Test will identify the pairs of means (from at least three) that differ. The MRT is similar to the LSD, but instead of a t-value, a Q Value is used.
-   **Fisher's Least Significant Difference (LSD)**
    -   A tool to identify which pairs of means are statistically different. Essentially the same as Duncan's MRT, but with t-values instead of Q values.
-   **Newman-Keuls**
    -   Like Tukey's, this post-hoc test identifies sample means that are different from each other. Newman-Keuls uses different critical values for comparing pairs of means. Therefore, it is more likely to find significant differences.
-   **Rodger's Method**
    -   Considered by some to be the most powerful post-hoc test for detecting differences among groups. This test protects against loss of statistical power as the degrees of freedom increase.
-   **Scheffé's Method**
    -   Used when you want to look at post-hoc comparisons in general (as opposed to just pairwise comparisons). Scheffe's controls for the overall confidence level. It is customarily used with unequal sample sizes.
-   **Tukey's Test**
    -   The purpose of Tukey's test is to figure out which groups in your sample differ. It uses the "Honest Significant Difference," a number that represents the distance between groups, to compare every mean with every other mean.
-   **Dunnett's Test**
    -   Like Tukey's this post-hoc test is used to compare means. Unlike Tukey's, it compares every mean to a control mean.
    -   [{DescTools::DunnettTest}]{style="color: #990000"}
-   **Benjamin-Hochberg (BH) Procedure**
    -   If you perform a very large amount of tests, one or more of the tests will have a significant result purely by chance alone. This post-hoc test accounts for that false discovery rate.

## One-Way {#sec-phoc-anova-oneway .unnumbered}

-   Measures if there's a difference in means between *any* group category
-   [Example]{.ribbon-highlight}: 1 control, 2 Test groups
    -   Data

        ``` r
        data <- data.frame(Group = rep(c("control", "Test1", "Test2"), each = 10),
        value = c(rnorm(10), rnorm(10),rnorm(10)))
        data$Group<-as.factor(data$Group)
        head(data)
        #>   Group      value
        #> 1 control  0.1932123
        #> 2 control -0.4346821
        #> 3 control  0.9132671
        #> 4 control  1.7933881
        #> 5 control  0.9966051
        #> 6 control  1.1074905
        ```

    -   Fit model

        ``` r
        model <- aov(value ~ Group, data = data)
        summary(model)
        #>             Df    Sum Sq   Mean Sq  F value  Pr(>F) 
        #> Group        2     4.407    2.2036     3.71  0.0377 *
        #> Residuals   27    16.035    0.5939

        # or
        lm_mod <- lm(value ~ Group, data = data)
        anova(lm_mod)
        ```

        -   P-Value \< 0.05 says at least 1 group category has a statistically significant different mean from another category

    -   Dunnett's Test

        ``` r
        DescTools::DunnettTest(x=data$value, g=data$Group)

        #> Dunnett's test for comparing several treatments with a control : 
        #>     95% family-wise confidence level
        #> $control
        #>                     diff    lwr.ci      upr.ci  pval   
        #> Test1-control -0.8742469 -1.678514 -0.06998022 0.0320 * 
        #> Test2-control -0.7335283 -1.537795  0.07073836 0.0768 .
        ```

        -   Measures if there is any difference between treatments and the control
        -   The mean score of the test1 group was significantly higher than the control group. The mean score of the test2 group was not significantly higher than the control group.

    -   Tukey's HSD

        ``` r
        stats::TukeyHSD(model, conf.level=.95)
        ```

        -   Measures difference in means between all categories and each other

## ANCOVA {#sec-phoc-anova-ancova .unnumbered}

-   Analysis of Covariance is used to measure the main effect and interaction effects of categorical variables on a continuous dependent variable while controlling the effects of selected other continuous variables which co-vary with the dependent variable.

-   Misc

    -   Analysis of covariance is classical terminology from linear models but we often use the term also for nonlinear models (Harrell)
    -   See also
        -   [Harrell - Biostatistics for Biomedical Research Ch. 13](http://hbiostat.org/bbr/ancova.html)

-   Assumptions

    -   Independent observations (i.e. random assignment, avoid is having known relationships among participants in the study)

    -   Linearity: the relation between the covariate(s) and the dependent variable must be linear.

    -   Normality: the dependent variable must be normally distributed within each subpopulation. (only needed for small samples of n \< 20 or so)

    -   Homogeneity of regression slopes: the beta-coefficient(s) for the covariate(s) must be equal among all subpopulations. (regression lines for these individual groups are assumed to be parallel)

        -   Failure to meet this assumption implies that there is an interaction between the covariate and the treatment.
        -   This assumption can be checked with an F test on the interaction of the independent variable(s) with the covariate(s).
            -   If the F test is significant (i.e., significant interaction) then this assumption has been violated and the covariate should not be used as is.
            -   A possible solution is converting the continuous scale of the covariate to a categorical (discrete) variable and making it a subsequent independent variable, and then use a factorial ANOVA to analyze the data.

    -   The covariate (adjustment variable) and the treatment are independent

        ``` r
        model <- aov(grade ~ technique, data = data)
        summary(model)

        #>             Df Sum Sq Mean Sq F value Pr(>F)
        #> technique    2    9.8    4.92    0.14  0.869
        #> Residuals  87 3047.7  35.03
        ```

        -   H~0~: variables are independent

-   Homogeneity of variance: variance of the dependent variable must be equal over all subpopulations (only needed for sharply unequal sample sizes)

    ``` r
    # response ~ treatment
    leveneTest(exam ~ technique, data = data)

    #>       Df F value    Pr(>F)   
    #> group  2  13.752 6.464e-06 ***
    #>       87

    # alt test
    fligner.test(size ~ location, my.dataframe)
    ```

    -   H~0~: Homogeneous variance
    -   This one fails

-   Fit

    ``` r
    ancova_model <- aov(exam ~ technique + grade, data = data)
    car::Anova(ancova_model, type="III")

    #>                 Sum Sq Df F value    Pr(>F)   
    #>     (Intercept) 3492.4  1 57.1325 4.096e-11 ***
    #>     technique  1085.8  2  8.8814 0.0003116 ***
    #>     grade          4.0  1  0.0657 0.7982685   
    #>     Residuals  5257.0 86
    ```

    -   When adjusting for current grade (covariate), study technique (treatment) has a significant effect on the final exam score (response).

-   Does the effect differ by treatment

    ``` r
    postHocs <- multicomp::glht(ancova_model, linfct = mcp(technique = "Tukey"))
    summary(postHocs)

    #>             Estimate Std. Error t value Pr(>|t|)   
    #> B - A == 0   -5.279      2.021  -2.613  0.0284 * 
    #> C - A == 0    3.138      2.022   1.552  0.2719   
    #> C - B == 0    8.418      2.019   4.170  <0.001 ***
    ```

    -   Also see [Post-Hoc Analysis, Multilevel \>\> Tukey's Test](post-hoc-analysis-multilevel.html#sec-phoc-mixeff-tukey){style="color: green"}
    -   $A$, $B$, and $C$ are the study techniques (treatment)
    -   Significant differences between $B$ and $A$ and a pretty large difference between $B$ and $C$.

-   [Example]{.ribbon-highlight}: RCT

    $$
    \begin{align}
    \text{post}_i &\sim \mathcal{N}(\mu_i, \sigma_\epsilon)\\
    \mu_i &= \beta_0 + \beta_1 \text{tx}_i + \beta_2 \text{pre}_i
    \end{align}
    $$

    ``` r
    w2 <- glm(
      data = dw,
      family = gaussian,
      post ~ 1 + tx + pre)
    ```

    -   Specification
        -   [post]{.var-text}, [pre]{.var-text}: The post-treatment and pre-treatment measurement of the outcome variable
        -   [tx]{.var-text}: The treatment indicator variable
        -   $\beta_0$: Population mean for the outcome variable in the control group
        -   $\beta_1$: Parameter is the population level difference in pre/post change in the treatment group, compared to the control group.
            -   Also a causal estimate for the average treatment effect (ATE) in the population, τ
        -   Because [pre]{.var-text} is added as a covariate, both $\beta_0$ and $\beta_1$ are conditional on the outcome variable, as collected at baseline before random assignment.
