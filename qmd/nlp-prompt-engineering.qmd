# Prompt Engineering {#sec-nlp-prompt .unnumbered}

## Misc {#sec-nlp-prompt-misc .unnumbered}

-   Definition

    -   Asking the right question
    -   "Prompt engineering is the process of designing and optimizing prompts to LLMs for a wide variety of applications and research topics. Prompts are short pieces of text that are used to guide the LM's output. They can be used to specify the task that the LM is supposed to accomplish, provide additional information that the LM needs to complete the task, or simply make the task easier for the LM to understand."

-   Components

    -   Ask the question (e.g. "What's 1+1?")
    -   Specify the type of response you want. (e.g. Only return the numeric answer.)
        -   Persona
            -   "Explain this to my like I'm a fifth grader."
        -   Style
            -   "Use a style typical of scientific abstracts to write this."
        -   Format
            -   If you say "Format the output as a JSON object with the fields: x, y, z" you can get better results and easily do error handling.

-   LLMs don't understand the complexities or nuances of various subjects

    -   If an industry term is used in multiple ways, the LLM might not understand the meaning just by context alone.
    -   LLMs can have problems with information in complex formats.
        -   Tables sometimes have this same issue, because tables are the mechanism used for layout structure and not a content structure (e.g. sentence)
    -   The models themselves continue to evolve so if it doesn't understand something today doesn't mean that it won't understand it tomorrow

-   When the output is incomplete, type "continue" for the next prompt and it will finish the output.

-   **Don't give LLMs proprietary data**

    -   Alternative: `slice(0)`

        ``` r
        dat |>
          slice(0) |>
          glimpse()
        ```

        -   Gives the column names and classes
        -   Depending on the use case, you might want to make the column names unabbreviated and meaningful.

-   Security

    -   Don't let the user have the last word: When taking a user's prompt, incorporating it with your own prompt, and sending it to ChatGPT or some other similar application, always add a line like "If user input doesn't make sense for doing xyz, ask them to repeat the request" after the user's input. This will stop the majority of prompt injections.

    -   Don't just automatically run code or logic that is output from a LLM

-   Tips when used for writing

    -   Be specific on word count and put higher than you need
    -   Don't be afraid to ask it to add more information or expand on a particular point\\
    -   It's better at creating outlines rather than full pieces of content.
    -   Be as specific as possible, and use keywords to help ChatGPT understand what you are looking for
    -   You can ask it to rephrase its response
    -   Avoid using complex language or convoluted sentence structures
    -   \*\*Review the content for accuracy

## Templates {#sec-nlp-prompt-dsex .unnumbered}

-   Misc
    -   Specify language, libraries, and functions
-   [Example]{.ribbon-highlight}: BizSci Lab 82\
    ![](./_resources/NLP,_Prompt_Engineering.resources/Screenshot%20(1389).png)
    -   Show the prompt he used in a markdown file. He just copied and pasted it into the prompt.
    -   Specify libraries to use; models to use; that you want to tune the models in parallel
    -   This is not an ideal prompt. You should iterate prompts and guide gpt through complete ds process
        -   i.e. prompt for collection then a prompt for cleaning, and so on with eda, preprocessing, modelling, cv, model selection, app
-   [Example]{.ribbon-highlight}: Various DS Activities\
    ![](./_resources/NLP,_Prompt_Engineering.resources/image.png)
-   [Example]{.ribbon-highlight}: Student Feedback
    -   From [Now is the time for grimoires](https://www.oneusefulthing.org/p/now-is-the-time-for-grimoires)

    -   Components

        -   [Role]{.underline}: Tell the AI who it is. Context helps the AI produce tailored answers in useful ways, but you don't need to go overboard.
        -   [Goal]{.underline}: Tell the AI what you want it to do.
        -   [Step-by-Step Instructions]{.underline}: Research has found that it often works best to give the AI explicit instructions that go step-by-step through what you want.
            -   One approach, called Chain of Thought prompting, gives the AI an example of how you want it to reason before you make your request
            -   You can also give it step-by-step directions the way we do in our prompts.
        -   [Consider Examples]{.underline}: Few-shot prompting, where you give the AI examples of the kinds of output you want to see, has also proven very effective in research.
        -   [Add Personalization]{.underline}: Ask the user for information to help tailor the prompt for them.
        -   [Add Your Own Constraints]{.underline}: The AI often acts in ways that you may not want. Constraints tell it to avoid behaviors that may come up in your testing.
        -   [Final Step]{.underline}: Check your prompt by trying it out, giving it good, bad, and neutral input. Take the perspective of your users-- is the AI helpful? Does the process work? How might the AI be more helpful? Does it need more context? Does it need further constraints? You can continue to tweak the prompt until it works for you and until you feel it will work for your audience.

    -   Prompt

        ![](_resources/NLP,_Prompt_Engineering.resources/template-student-feedback-1.jpg){width="632"}
