# Generalized Additive Models {#sec-gam .unnumbered}

## Misc {#sec-gam-misc .unnumbered}

-   Also see [Feature Engineering, Splines](feature-engineering-splines.qmd#sec-feat-eng-spl){style="color: green"}
-   Packages
    -   [{]{style="color: #990000"}[mgcv](https://cran.r-project.org/web/packages/mgcv/index.html){style="color: #990000"}[}]{style="color: #990000"} - Mixed GAM Computation Vehicle with Automatic Smoothness Estimation
        -   See R \>\> Documents \>\> Regression \>\> GAMs \>\> Generalized Additive Models: An Introduction with R, Second Edition
    -   [{]{style="color: #990000"}[gamlss](https://www.gamlss.com/){style="color: #990000"}[}]{style="color: #990000"} - GAM modeling where all the parameters of the assumed distribution for the response can be modelled as functions of the explanatory variables
    -   [{]{style="color: #990000"}[gamboostLSS](https://cran.r-project.org/web/packages/gamboostLSS/index.html){style="color: #990000"}[}]{style="color: #990000"} - Boosting models for fitting generalized additive models for location, shape and scale ('GAMLSS') to potentially high dimensional data.
    -   [{]{style="color: #990000"}[bamlss](https://cran.r-project.org/web/packages/bamlss/index.html){style="color: #990000"}[}]{style="color: #990000"} - Bayesian Additive Models for Location, Scale, and Shape (and Beyond)
-   Resources
    -   [Video](https://www.youtube.com/watch?v=sgw4cu8hrZM&ab_channel=GavinSimpson) "Introduction to Generalized Additive Models with R and mgcv" Gavin Simpson
    -   [Video](https://www.youtube.com/watch?v=q4_t8jXcQgc&ab_channel=LanderAnalytics) "The Wonderful World of mgcv" Noam Ross
-   Large gaps in the values of the predictor variable can be a problem if you are trying to interpolate between those gaps. (See bkmks, `method = "reml" + s(x, m = 1)`)

## Diagnostics {#sec-gam-diag .unnumbered}

-   "Deviance explained" is the R^2^ value for GAMs

-   `mgcv::gam.check(gam_fit)` ![](./_resources/Generalized_Additive_Models_(GAM).resources/output_38_1.png){.lightbox width="832"}

    ``` r
    ## Method: GCV  Optimizer: magic
    ## Smoothing parameter selection converged after 19 iterations.
    ## The RMS GCV score gradient at convergence was 5.938335e-08 .
    ## The Hessian was positive definite.
    ## Model rank =  21 / 22 
    ## Basis dimension (k) checking results. Low p-value (k-index<1) may
    ## indicate that k is too low, especially if edf is close to k'.
    ##                                           k'  edf  k-index p-value   
    ## s(id)                                   1.00  0.35    0.82  <2e-16 ***
    ## s(log_profit_rug_business_b)            9.00  8.52    1.01    0.69   
    ## s(log_profit_rug_business_b):treatment 10.00  1.50    1.01    0.62   
    ## ---
    ## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
    ```

    -   Check if the size of the basis expansion (k) for each smooth is sufficiently large
        -   `k.check` can also do this
        -   If all your smoothing predictors are not sufficiently large, then this indicates that using a GAM is a bad fit for your data.
        -   See SO [post](https://stats.stackexchange.com/questions/612102/how-to-know-when-a-generalized-additive-model-need-to-be-used-for-binary-data/612113#612113) from Simpson

-   Formal test for the necessity of a smooth

    ``` r
    m <- 
      gam(y ~ x + s(x, m = c(2, 0), bs = "tp"),
          data = foo,
          method = "REML",
          family = binomial())
    ```

    -   See [EDA, General >> Continuous Predictor vs Outcome >> Continuous](eda-general.qmd#sec-eda-gen-contout-cont){style="color: green"} for an example
    -   `bs = "tp"` is just the default thin plate basis function
    -   Fit the predictor of interest as a linear term (x) plus a smooth function of x
    -   Modify the basis for the smooth so that it no longer includes linear functions in the span of the basis with [m = c(2, 0)]{.arg-text}
        -   [m]{.arg-text}: Controls the penalty on the wiggliness of spline
        -   [2]{.arg-text}: An order-2 penalty (the default and most common) penalizes the second derivative of the function, which relates to its curvature.
            -   Higher values would penalize higher-order derivatives, resulting in even smoother functions.
        -   [0]{.arg-text}: Specifies that no null space basis is required.
            -   The null space is the span of functions that aren't affected by the (main) penalty, because they have 0 second derivative. (i.e. terms that doen't have curvature)
            -   For an order-2 penalty, the null space typically includes constant and linear terms.
    -   `summary` will give a test for the necessity of the wiggliness provided by the smooth over the linear effect estimated by the linear term. Check the p-value of the smooth term. If it's significant, then a spline should be used. In your model, you wouldn't use the zeroed out null space specification though.
    -   From Simpson SO [post](https://stats.stackexchange.com/questions/612102/how-to-know-when-a-generalized-additive-model-need-to-be-used-for-binary-data/612113#612113)
    -   Also see Wood's "Generalized Additive Models: An Introduction with R", 2nd Ed, section 6.12.3, "Testing a parametric term against a smooth alternative" p 312-313 (R \>\> Documents \>\> Regression \>\> gam)
