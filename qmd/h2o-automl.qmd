# h2o automl

Notes from business science webinar


* The amount of ram needed on local machine equals four to five times the size of your data (usually) but really depends on max number of models to be trained.
* Diagnostic metrics used in classification models are AUC, log loss, and mean per class error
* Seems to use generic variable importance (mean decrease gini)
* I think a glm was used to ensemble its models
* In the binary classification example, the top models were "extremely randomized trees", xgboost, and gbm.
* Ensemble model reproducibility requires arguments: set seed and exclude\_model = "DNN"  (deep neural network)



