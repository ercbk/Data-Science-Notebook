# EDA

TOC

-   Misc
-   Basic Cleaning
-   Packages
-   Missingness
-   What is the problem?
-   Outliers
-   Group Calculations
-   Categorical/Discrete
-   Numeric
-   Correlation
-   Charts
    -   Numeric Predictor vs Outcome
    -   Interactions
    -   Categorical Predictor vs Outcome

## Misc

-   First contact with an unfamiliar database
    1.  select \* from limit 50
    2.  Look for keys/fields to connect tables
    3.  Make running list of Q's, try to answer them by poking around first
    4.  Find team/code responsible for DB and ask for time to review questions -- communication can be a superpower here!
-   Use domain knowledge to assess peculier relationships
    -   Example: Is there a nonlinear relationship between Driver hours and Incentive Level  
        ![](./_resources/EDA.resources/0-FmfHLkDICNkqaV1u.png)
        -   Common sense says if we raise payment bonuses, we should see more drivers want to work more hours.
        -   Reason behind the relationship shown in this chart is omitted variables: weather and holiday.
            -   Incentives stop having an effect on drivers because they hate going out in shitty weather and want to stay home with their family on the holidays.

## Basic Cleaning

-   tidy column names
-   shrink long column names to something reasonable enough for an axis label
-   make sure num vars aren't initially coded as cat vars and vice versa
-   Make note of columns with several values per cell and will need to be separated into multiple columns (e.g. addresses)
-   find duplicate rows
    -   These can cause data leakage if the same row is in the test and train sets.
-   remove columns that the target is a function of
    -   eg doen't use monthly salary to predict yearly salary
-   remove columns that occur after the target event
    -   eg using info occurring in or after a trial to predict something pre-trial
        -   you won't have this info beforehand when you make your prediction
-   Ordinal categorical
    -   reorder by a number in the text (parse_number)
        
        ```r         
        mutate(income_category = fct_reorder(income_category, parse_number(income_category)),
              # manually fix category that is still out of order
              # moves "Less thatn $40K" to first place in the levels
              income_category = fct_relevel(income_category, "Less than $40K"))
        ```

## Packages

-   skimr::skim(dat) - overall summary, check completion percentage for vars with too many NAs
-   dataexplorer (categorical) - dat %\>% plot_bar(maxcat = 50, nrow = 2) - distr of levels for each cat
    -   Examine cat vars with \>50 unique levels manually
-   dataexplorer (numerical) - dat %\>% plot_histogram()
-   [{]{style="color: #990000"}[dataxray](https://github.com/agstn/dataxray){style="color: #990000"}[}]{style="color: #990000"} - table with interactive distributions, summary stats, missingness, proportions. (dancho [article/video](https://www.r-bloggers.com/2023/01/cut-your-eda-time-into-5-minutes-with-exploratory-dataxray-analysis-edxa/))
-   [{]{style="color: #990000"}[visdat](https://docs.ropensci.org/visdat/){style="color: #990000"}[}]{style="color: #990000"} has decent visualization for group comparison, missingness, correlation, etc.
-   {Hmisc::describe}
    
    ```r         
    sparkline::sparkline(0)
    des <- describe(d)
    plot(des) # maybe for displaying in Viewer pane
    print(des, 'both') # maybe just a console df of the numbers
    maketabs(print(des, 'both'), wide=TRUE) # for Quarto
    ```

    -   "both" says display "continuous" and "categorical"

-   Numeric  
    ![](./_resources/EDA.resources/Screenshot%20(1434).png)

-   Categorical  
    ![](./_resources/EDA.resources/Screenshot%20(1433).png)

-   Columns (from Hmisc [Ref Manual](https://cran.r-project.org/web/packages/Hmisc/Hmisc.pdf))

    -   "Info": Info which is a relative information measure using the relative efficiency of a proportional odds/Wilcoxon test on the variable relative to the same test on a variable that has no ties. Info is related to how continuous the variable is, and ties are less harmful the more untied values there are. The formula for Info is one minus the sum of the cubes of relative frequencies of values divided by one minus the square of the reciprocal of the sample size. The lowest information comes from a variable having only one distinct value following by a highly skewed binary variable. Info is reported to two decimal places.
    -   "Mean" and "Sum" (Binary): , the sum (number of 1's) and mean (proportion of 1's)

## Missingness

-   Also see
    -   [Missingness](missingness.qmd#sec-missing){style="color: green"}
    -   [Model Building, tidymodels \>\> Recipe](model-building-tidymodels.html#sec-modbld-tidymod-recipe){style="color: green"} \>\> Imputation
-   Packages
    -   [{]{style="color: #990000"}[naniar](http://naniar.njtierney.com/){style="color: #990000"}[}]{style="color: #990000"} - tidy ways to summarize, visualize, and manipulate missing data with minimal deviations from the workflows in ggplot2 and tidy data
    -   [{]{style="color: #990000"}[qreport](http://hbiostat.org/R/qreport/){style="color: #990000"}[}]{style="color: #990000"} - Harrell package; a few of the charts aren't intuitive and don't have good documentation in terms of explaining how to interpret them. Fits an ordinal logistic regression model to describe which types of subjects (based on variables with no NAs) tend to have more variables missing. Hierarchically clusters variables that have similar observations missing
        -   See naclus [docs](https://www.rdocumentation.org/packages/Hmisc/versions/4.7-0/topics/varclus), RMS [Ch.19.1](https://hbiostat.org/rmsc/psmcase.html#descriptive-statistics), R Workflow [Ch.2.7](https://hbiostat.org/rflow/case.html#missing-data) (interprets the clustering), [Ch.6](https://hbiostat.org/rflow/missing.html) (interpretes the ordinal regression) (possibly more use cases in that ebook)
-   Questions
    -   Which features contain missing values?
    -   What proportion of records for each feature comprises missing data?
    -   Is the missing data missing at random (MAR) or missing not at random (MNAR) (i.e. informative)?
    -   Are the features with missing values correlated with other features?
-   Categoricals for binary classification  
    ![](./_resources/EDA.resources/Screenshot%20(244).png)
    
    ```r         
    train_raw %>%
      select(
        damaged, precipitation, visibility, engine_type,
        flight_impact, flight_phase, species_quantity
      ) %>%
      pivot_longer(precipitation:species_quantity) %>%
      ggplot(aes(y = value, fill = damaged)) +
      geom_bar(position = "fill") +
      facet_wrap(vars(name), scales = "free", ncol = 2) +
      labs(x = NULL, y = NULL, fill = NULL)
    ```
    
    -   The NAs (top row in each facet) aren't 50/50 between the two levels of the target. The target is imbalanced and the NAs seem to be predictive of "no damage," so they aren't random.
    -   Since these NAs look predictive, you can turn them into a category by using `step_unknown` in the preprocessing recipe.

## What is the problem?

-   General Questions
    -   "What variables are relevant to the problem I'm trying to solve?"
    -   "What are the key components of this data set?"
    -   "Can this data be categorized?"
    -   "Is this analysis result out of the ordinary?"
    -   "What are the key relationships?"
    -   "Is this the best way this company could be carrying out this task?"
    -   "What will happen under new conditions?"
    -   "What factors are best used to determine or predict this eventuality?"
-   Break down the problem into parts and focus on those during EDA
    -   Also see [Decison Intelligence \>\> Mental Models](decison-intelligence.qmd#sec-decint-mentmod){style="color: green"} for details on methods to break down components
-   Example: Why are sales down?
    -   How are sales calculated?
        -   e.g. Total Sales = \# of Orders \* Average Order Value
    -   Breakdown \# of orders and average order value
        -   number of orders = number of walk-ins \* % conversion
            -   has walk-ins or conversion declined?
        -   average order value
            -   bin avg order value by quantiles, plot and facet or group by binned groups. Is one group more responsible for the decline than others?
    -   Is there regional or store or brand variability? (grouping variables)
-   Drill down into each component until the data doesn't allow you to go any farther.
-   Segment data by groups
    -   color or facet by cat vars
    -   pay attention to counts of each category (may need to collapse categories)
    -   common segments in product analytics
        -   free vs paid users
        -   device type (desktop web vs mobile web vs native app)
        -   traffic source (people coming from search engines, paid marketing, people directly typing in your company's URL into their browser, etc.)
        -   day of the week.
-   TROPICS framework for analyzing changes in key performance metrics
    -   From https://towardsdatascience.com/answering-the-data-science-metric-change-interview-question-the-ultimate-guide-5e18d62d0dc6
    -   **Time** What to explore \* How has our performance been **trending** over the last few weeks (or months)? *If we saw a 10% increase in the last week, was the percentage change in the weeks before also 10%? In which case the 10% may actually be pretty normal? Or was the change lower? Higher?* \* Is this change [**seasonal**](https://www.sequoiacap.com/article/metrics-seasonal-factors#:~:text=Seasonality%20is%20often%20the%20root,behavioral%20change%20factor%20to%20explore.&text=You%20might%20then%20hypothesize%20that,or%20negative%E2%80%94of%20the%20product.)? Do we see the same spike around this time each year? *Does WhatsApp see a [spike in messages](https://www.flurry.com/blog/messaging-apps-spike-during-virtual-holiday-christmas-new-year/) sent during the holiday season?* \* Was the change **sudden or gradual**? Did we see a sudden spike or drop overnight? Or has the metric gradually been moving in this direction over time? *If product usage jumps by 50% overnight could there be a bug in our logging systems?* \* Are there **specific times** during the day or week where this change is more pronounced?
        -   Solution examples
            -   If the change is seasonal then there may not necessarily be anything you need to 'solve' for. But, you can leverage this to your advantage. *Amazon sales may jump up on Black Friday so they would want to make sure they have the proper infrastructure in place so the [site doesn't crash](https://www.theverge.com/2018/7/16/17577654/amazon-prime-day-website-down-deals-service-disruption). They may also see if there are certain types of products that are popular purchases and increase their inventory accordingly.*
            -   If there is a sudden decline, there may be **a bug in the logging** or a **new feature or update** recently launched that's creating problems that you may need to roll back.
            -   If there's a gradual decline, it may indicate a **change in user behavior**. *If the time spent listening to music is declining because people prefer to listen to podcasts then [Spotify may want to focus more of their content inventory on podcasts.](https://techcrunch.com/2019/01/10/spotifys-increased-focus-on-podcasts-in-2019-includes-selling-its-own-ads/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAIKqPepZqERJ58OeY27wAkiohH_MUbrRZIUzwNaqErpdLFt9sV_a07V0dfOR1ftRdoOqC68hZWcC8fMQacip0FkeKYwvSohInKqI44RewmFC582isa0WTvpOXA72LBFOF2a0TTX7ZYiFX4tTO_foSUaBWJ7-Up4D3llAUjwQIpPM)*
    -   **Region** What to explore \* Is this change concentrated in a **specific region** or do we see a similar change across the board?
        -   Solution examples
            -   There may be **newly enforced regulations** in countries that are affecting your product metrics. You would need to do further research to assess the impacts of these regulations and potential workarounds. [*Uber was temporarily banned in London in 2019*](https://www.nytimes.com/2019/11/25/business/uber-london.html) *for repeated safety failures* which resulted in a series of lawsuits and court cases.
            -   **Popular local events** may also be potential explanations. While these may not be areas to 'solve' for they can be opportunities to take advantage of. *Coachella season means a jump in the number of Airbnb bookings in Southern California that are capitalized on by surge pricing.*
    -   **Other Internal Products** What to explore \* Is this change **specific to one product or is it company-wide**? How does this metric vary across our other product offerings? *If the Fundraising feature on Facebook is seeing increased usage, is the swipe up to donate feature on Instagram (which Facebook owns) also seeing a similar uptick?* \* Are there **other metrics** that have also changed in addition to the one in question? *If the time spent on Uber is going down, is the number of cancellations by drivers also declining (implying people are spending less time on the app because they're having a more reliable experience)?*
        -   Solution examples
            -   If there is a metric change across our other features and products, it's likely a larger problem we should address with multiple teams and may need a Public Relations consultant. [*Elon + Twitter.*](https://www.cnbc.com/2021/01/29/elon-musks-tweets-are-moving-markets.html#:~:text=He%20infamously%20tweeted%20last%20year,cryptocurrencies%20for%20a%20while%20now.)
    -   **Platform** What to explore \* Mobile vs Desktop? \* Mac vs Windows? \* Android vs iOS?
        -   Solution examples
            -   If there was a positive change in our metric on a specific platform (e.g. iOS) and coincides with an (iOS) update we released, we would want to do a retrospective to determine **what about that update was favorable so we can double down on it.** Alternatively, if the metric change was negative, we may want to **reconsider and even roll back the update.**
            -   If the change was due to a change in the platform experience **(e.g. app store placement, ratings)** we may want to seek advice from our marketing team since this is a top of the funnel problem
            -   If users are showing astrong preference for a specific platform, we want to make sure that the experience of the preferred platform is up to par. We also need to make sure our platform-specific monetization strategies are switching to follow the trend. [*Facebook's ad model was initially tied to the desktop app only and had to be expanded as mobile became the platform of preference.*](https://blog.hubspot.com/marketing/history-facebook-adtips-slideshare)
    -   **Industry & Competitors** What to explore \* When our decline began, **was there a new competitor or category that emerged?** [*Did the number of users listening to Apple podcasts go down when Clubhouse came on to the scene?*](https://www.vulture.com/2021/02/does-clubhouse-mean-bad-things-for-podcasting.html) \* Have competitors changed their offering lately? \* Is the category as a whole declining?
        -   Solution examples
            -   If the category is shifting as a whole, we should begin looking at larger-scale changes to the app. *What [Kodak](https://www.forbes.com/sites/chunkamui/2012/01/18/how-kodak-failed/?sh=ad644166f27a) should have done.*
            -   If there's a new competitor taking our market share, we can begin with reactivation campaigns on churned users. We may also want to conduct user research to understand the gap between our offering and those of our competitors
    -   **Cannibalization**
        -   What to explore
            -   Are **other products or features** in our offering experiencing **growth** in the face of our **decline** or vice versa?
            -   Have we **released a new feature that is drawing users away from our old features?** If so, can we fully attribute the release of the new feature with the decline in the metric of our feature in question? *When Facebook released reactions, did the number of comments on a post go down because people found it easier to press a react button instead of writing a comment?*
        -   Solution examples
            -   Cannibalization may not necessarily be a bad thing. We need to determine whether this shift in user interest across our features is favorable by determining whether the new features align better with the goals of the business.
            -   Cannibalization may also be an indication of but it is indicative of a change in user behavior. In which case we may want to consider if perhaps our core metrics need to change as user behaviors change. *If users care more about watching Instagram stories than engaging with the Instagram feed we may want to optimize for retention (because the ephemeral nature of stories is more likely to motivate users to keep coming back to the platform) instead of time spent on the app.*
            -   We can also look at ways to bridge the two features together to create a more unified platform.
    -   **Segmentation** What to explore How does this metric **vary by user type**: \* Age, sex, education \* Power users versus casual users \* New users versus existing users How does this metric vary by **different attributes of the product:** \* *If the time spent watching YouTube videos is going down, is it across longer videos or shorter clips? Is it only for DIY videos or interview tutorial content? Is the same number of people that started watching a video the same but a large chunk of them stop watching it halfway through?*
        -   Solution examples
            -   If the metric varies between new and existing users then maybe there is a overcrowding effect. *Reddit forums could hit a critical mass where new users feel lost and less likely to engage than existing users resulting in a drop in engagements per user*
            -   If users are dropping off at certain parts of the funnel then maybe the experience at that funnel step is broken. *While the same number of people are starting carts on Amazon there may be a drop in purchases if the payment verification system isn't working.*

## Outliers

-   Abnormalities due to likely data entry errors
    -   Example: store == "open" and sales == 0 or store == "closed" and sales \> 0
        -   potential sol'n: replace 0's (open) with mean sales and sales \>0 (closed) with 0s
-   Extreme counts in charts when grouping by a cat var
    -   Why is one category's count so low or so high?
        -   may need subject matter expert
    -   What can be done to increase or decrease that category's count?
-   Experiment with keeping or removing outliers while fitting baseline models

## Group Calculations

-   Variance of value by group
    -   Example: how sales vary between store types over a year
    -   important to standardize the value by group
        -   group_by(group), mutate(sales = scale(sales))
    -   Which vary wildly and which are more stable
-   rates by group
    -   Example: sales(\$) per customer
        -   group_by(group), mutate(sales_per_cust = sum(sales)/sum(customers)
-   Avg by Group(s)
    
    ```r         
    dat %>%
    select(cat1, cat2, num) %>%
    group_by(cat1, cat2) %>%
    summarize(freq = n(),
              avg_cont = mean(num))
    ```

## Categorical/Discrete Variables

-   Count number of rows per category level (or use skimr or DataExplorer)
    
    ```r         
    tbl %>% count(cat_var, sort = True)
    ```

-   Looking for how skewed data might be (only a few categories have most of the obs)
-   If levels are imbalanced, consider: `initial_split(data, strata = imbalanced_var)`
-   For cat vars with levels with too few counts, consider lumping together
    -   Levels with too few data will have large uncertainties about the effect and the bloated std.devs can cause some models to throw errors
-   Count NAs (or use skimr or DataExplorer)
    
    ```r         
    tbl %>%
      map_df(~ sum(is.na(.))) %>%
      gather(key = "feature", value = "missing_count") %>%
      arrange(desc(missing_count))
    ```

-   Vars with too many NAs, may need to be dropped or imputed

    -   Some models don't handle NAs

-   If the number of NAs is within tolerance and you decide to impute, you need to find out what kind of "missingness" you have before you choose the imputation method. Some cause issues with certain types of missingness. (e.g. mean and missing-not-at-random (MNAR))

-   Year variable
    
    ```r         
    data |>
        count(year) |>
        arrange(desc(year)) |>
        ggplot(aes(year, n)) +
        geom_line()
    ```

    -   Looking for skew.
    -   Is data older or more recent?

-   Free Text Sometimes these columns are just metadata (a url, product description, etc.), but other times they could have valuable information (e.g. customer feedback). If a column seems like it contains valuable information for your prediction task, you generate features from it text length, appearance/frequency of certain keywords, etc.
    -   Tokenize
        -   See below code for "Facetted bar by variable with counts of the values" and the use of `separate_rows` to manually tokenize
              more useful when the columns don't have stopwords
-   Visualize value counts for multiple variables
    -   Facetted bar by variable with counts of the values  
        ![](./_resources/EDA.resources/Screenshot%20(1370).png)
        
        ```r         
        categorical_variables <- board_games %>%
              # select all cat vars
              select(game_id, name, family, category, artist, designer, mechanic) %>%
              # "type" receives all colnames; "value" receives their values
              gather(type, value, -game_id, -name) %>%
              filter(!is.na(value)) %>%
              # Some values of vars are free text separated by commas; code makes each value into a separate row
              separate_rows(value, sep = ",") %>%
              arrange(game_id)
        categorical_counts <- categorical_variables %>%
              count(type, value, sort = TRUE)
        
        categorical_counts %>%
              # type is gathered colnames of the variables
              group_by(type) %>%
              # high cardinality variables, so only show top 10
              top_n(10, n) %>%
              ungroup() %>%
              mutate(value = fct_reorder(value, n)) %>%
              ggplot(aes(value, n, fill = type)) +
              geom_col(show.legend = FALSE) +
              facet_wrap(~ type, scales = "free_y") +
              coord_flip() +
              labs(title = "Most common categories")
        ```

        -   "type" has the names of the variables, "value" has the levels of the variable

## Continuous Variables

-   Does the variable have a wide range. (i.e. values across multiple magnitudes: 101 and 102 and ... etc.)
    -   If so, log the variable
-   Histogram - Check shape of distribution
    
    ```r         
    ggplot(aes(var)) +
        geom_histogram()
    ```

    -   Looking at skew. Is it roughly normal?
    -   Does filter(another_var \> certain_value (see below) help it look more normal?
    -   Is it multi-modal
        -   See [Regression, Other \>\> Multi-Modal](regression-other.qmd#sec-reg-other-multmod){style="color: green"}(visuals, tests, modelling, etc.)
        -   [{{]{style="color: goldenrod"}[gghdr](https://sayani07.github.io/gghdr/){style="color: goldenrod"}[}}]{style="color: goldenrod"} - Visualization of Highest Density Regions in ggplot2
        -   Interactions \>\> Outcome: Categorical \>\> Binary Outcome (pct_event) vs Discrete by Discrete (or binary in this case)
    -   Is the variable highly skewed
        -   If so, try:
            -   Changing units (min to hr),
            -   filter(some_var \> some_value)
            -   some combination of the above make more normal?
                -   Normality among predictors isn't necessary, but I think it improves fit or prediction somewhat
            -   log transformation may help some if the skew isn't too extreme
-   Q-Q plot to check fit against various distributions
    
    ```r         
    ggplot(data)+
        stat_qq(aes(sample = log_profit_rug_business))+
        stat_qq_line(aes(sample = log_profit_rug_business))+
        labs(title = 'log(profit) Normal QQ')
    ```

    -   A plot of the sample (or observed) quantiles of the given data against the theoretical (or expected) quantiles.
    -   See [article](https://towardsdatascience.com/qq-plotting-your-way-to-data-enlightenment-a-hitchhikers-guide-to-the-galaxies-of-distribution-398352c9199) for the math and manual code
    -   `stat_qq, stat_qq_line` default distributions are Normal
    -   ggplot::stat_qq [docs](https://ggplot2.tidyverse.org/reference/geom_qq.html#ref-examples) have some good examples on how to use q-q plots to test your data against different distributions using `MASS::fitdistr` to get the distributional parameter estimates. Available distributions: "beta", "cauchy", "chi-squared", "exponential", "gamma", "geometric", "log-normal", "lognormal", "logistic", "negative binomial", "normal", "Poisson", "t" and "weibull"
    -   Good fits
        -   normal distribution  
            ![](./_resources/EDA.resources/image.png)
    -   Bad fits
        -   Uniform data tested against a normal distibution  
            ![](./_resources/EDA.resources/image.1.png)
        -   Uniform data tested against an exponential distribution  
            ![](./_resources/EDA.resources/image.2.png)

-   Is the mean/median above or below any important threshold?
    -   e.g. CDC considers a BMI \> 30 as obese. Health Insurance charges rise sharply at this threshold
        -   Is there an important threshold value?
            -   1 value --\> split into a binary
            -   Multiple values --\> Multinomial
        -   Examples
            -   Binary
                -   Whether a user spent more than \$50 or didn't (See Charts \>\> Categorical Predictors vs Outcome)
                -   If user had activity on the weekend or not
            -   Multinomial
                -   Timestamp to morning/afternoon/ night,
                -   Order values into buckets of \$10--20, \$20--30, \$30+
    -   Empirical Cumulative Density function (ecdf)  
        ![](./_resources/EDA.resources/image.3.png)
        
        ```r         
        ggplot(aes(x = numeric_var, color = cat) +
            stat_ecdf()
        ```
        
        -   Shows the percentage of sample (y-axis) that are below a numeric_var value (x-axis)
        -   [{]{style="color: #990000"}[sfsmisc::ecdf.ksCI](https://cran.r-project.org/web/packages/sfsmisc/sfsmisc.pdf){style="color: #990000"}[}]{style="color: #990000"} - plots the ecdf and 95% CIs (see [Harrell](http://hbiostat.org/bbr/nonpar.html#sec-nonpar-ecdf) for details of the CI calculation)
        -   Can view alongside a table of group means to see if the different percentiles differ from the story of just looking at the mean.
            
            ```r         
            data %>%
                group_by(categorical_var) %>%
                summarize(mean(numeric_var))
            ```

## Correlation

-   Also see
    -   [Correlation, Association, and Distance](correlation-association-and-distance.html#sec-corrassdist){style="color: green"}
    -   Notebook \>\> Statistical Inference \>\> Correlation
    -   Interactions \>\> Outcome: numeric \>\> Correlation Heatmaps
-   [{]{style="color: #990000"}[correlationfunnel](https://business-science.github.io/correlationfunnel/){style="color: #990000"}[}]{style="color: #990000"} - Dancho's package; bins numerics, then dummies all character and binned numerics, then runs a pearson correlation vs the outcome variable. Surprisingly it's useful to use Pearson correlations for binary variables as long as you have a mix of 1s and 0s in each variable. (Cross-Validated [post](https://stats.stackexchange.com/a/103806))
    
    ```r         
    churn_df %>%
        binarize() %>%
        correlate(<outcome_var>) %>%
        plot_correlation_funnel()
    ```
    
    -   `correlate` returns a sorted? tibble in case you don't want the plot
    -   The funnel plot is a way of combining and ranking all the correlation plots into a less eye-taxing visual.
    -   Uses `stats::cor` for calculation so you can pass args to it and but changing the method (e.g. `method = c("pearson", "kendall", "spearman")` ) won't matter, since pearson and spearman (and probably kendall) will be identical for binary variables.
-   For binary vs. binary, also see [Correlation, Association, and Distance >> Discrete](correlation-association-and-distance.html#sec-corrassdist-disc){style="color: green"} \>\> Binary Similarity Measures and Cramer's V

-   Pairwise plots for patterns

    -   outcome vs predictor
    -   predictor vs predictor
        -   interactions
        -   multicollinearity
    -   correlation/association scores for linear relationships
    -   histograms for variations between categories

-   Linear

    -   [{greybox}]{style="color: #990000"} for testing correlation between different types of variables

-   Multicollinearity

    -   VIF (performance::check_collinearity(fit) or greybox::determ or vif(fit))
    -   Use PCA --- if only a few (depends on the number of variables) pc explain all or almost all of the variation, then you could have a multicollinearity problem

-   Nonlinear

    -   Scatterplots for non-linear patterns,
    -   Correlation metrics
    -   Also see [General Additive Models \>\> Diagnostics](generalized-additive-models-(gam).qmd#sec-gam-diag){style="color: green"} for a method of determining a nonlinear relationship for either continuous or categorical outcomes.

-   Categorical

    -   2-level x 2-level: Cramer's V
    -   2-level or multi-level x multi-level
        -   Chi-square or exact tests
    -   Levels vs Levels correlation
        -   Multiple Correspondence Analysis (MCA) (see bkmks \>\> Features \>\> Reduction)
    -   Binary outcome vs Numeric predictors
        
        ```r        
        # numeric vars should be in a long tbl. Use pivot longer to make two columns (e.g. metric (var names) value (value))
        
        numeric_gathered %>%
          group_by(metric) %>%
          # rain_tomorrow is the outcome; event_level says which factor level is the event your measuring
          roc_auc(rain_tomorrow, value, event_level = "second") %>%
          arrange(desc(.estimate)) %>%
          mutate(metric = fct_reorder(metric, .estimate)) %>%
          ggplot(aes(.estimate, metric)) +
          geom_point() +
          geom_vline(xintercept = .5) +
          labs(x = "AUC in positive direction",
              title = "How predictive is each linear predictor by itself?",
              subtitle = ".5 is not predictive at all; <.5 means negatively associated with rain, >.5 means positively associated")
        ```

        -   .5 is not predictive at all; \<.5 means negatively associated with rain, \>.5 means positively associated

-   Ordinal

    -   Polychoric

## Continuous Predictor vs Outcome

-   Misc
    -   if the numeric-numeric relation isn't linear, then the model will be misspecified: an influential variable may be overlooked or the assumption of linearity may produce a model that fails in important ways to represent the relationship.
    -   Also see [General Additive Models \>\> Diagnostics](generalized-additive-models-(gam).qmd#sec-gam-diag){style="color: green"} for a method of determining a nonlinear relationship for either continuous or categorical outcomes.
-   Numeric outcome
    -   Scagnostics ([paper](https://www.cs.uic.edu/~aanand/publications/INFOVIS05-scagnostics.pdf)) - metrics to examine numeric vs numeric relationships
        -   [{]{style="color: #990000"}[scagnostics](https://cran.r-project.org/web/packages/scagnostics/index.html){style="color: #990000"}[}]{style="color: #990000"}
        -   Scagnostics describe various measures of interest for pairs of variables, based on their appearance on a scatterplot. They are useful tool for discovering interesting or unusual scatterplots from a scatterplot matrix, without having to look at every individual plot
        -   Metrics: Outlying, Skewed, Clumpy, Sparse, Striated, Convex, Skinny, Stringy, Monotonic
            -   "Straight" (paper) seems to have been swapped for "Sparse" (package)
        -   Potential use cases
            -   Finding linear/nonlinear relationships
            -   Clumping or clustered patterns could indicate an interaction with a categorical variable
        -   Score Guide  
            ![](./_resources/EDA.resources/Screenshot%20(974).png)
            -   High value: Red
            -   Low value: Blue
            -   Couldn't find the ranges of these metrics in the paper or the package docs
            -   Shows how scatterplot patterns correspond to metric values
-   Categorical outcome
    -   For binary outcome, look for variation between numeric variables and each outcome level  
        ![](./_resources/EDA.resources/Screenshot%20(347).png)
        
        ```r         
        # numeric vars should be in a long tbl.
        # Use pivot longer to make two columns (e.g. metric (var names) value (value)) with the binary outcome (e.g rain_tomorrow) as a separate column
        numeric_gathered %>%
          ggplot(aes(value, fill = rain_tomorrow)) +
          geom_density(alpha = 0.5) +
          facet_wrap(~ metric, scales = "free")
        # + scale_x_log10()
        ```
              
        -   Separation between the two densities would indicate predictive value.
        -   If one of colored density is further to the right than the other then the interpretation would be:
            -   higher values of metric result in a greater probability of <outcome category of the right-most density>
        -   Normalize the x-axis with `rank_percentile(value)`  
            ![](./_resources/EDA.resources/Screenshot%20(349).png)
            
            ```r         
            numeric_gathered %>%
                mutate(rank = percent_rank(value)) %>%
                ggplot(aes(rank, fill = churned)) + 
                  geom_density(alpha = 0.5) + 
                  facet_wrap(~ metric, scales = "free")
            ```
            
            -   Not sure why you'd do this unless there was a reason to compare the separation of densities (i.e. strength of association with outcome) between the predictors.

    -   Estimated AUC for binary outcome \~ numeric predictor
        
        ```r         
        numeric_gathered <- train %>%
          mutate(rainfall = log2(rainfall + 1)) %>%
          gather(metric, value, min_temp, max_temp, rainfall, contains("speed"), contains("humidity"), contains("pressure"), contains("cloud"),        contains("temp"))
        
        numeric_gathered %>%
          group_by(metric) %>%
          # "rain_tomorrow" is a binary factor var
          # "second" says the event we want the probability for is the second level of the binary factor variable
          yardstick::roc_auc(rain_tomorrow, value, event_level = "second") %>%
          arrange(desc(.estimate)) %>%
          mutate(metric = fct_reorder(metric, .estimate)) %>%
          ggplot(aes(.estimate, metric)) +
          geom_point() +
          geom_vline(xintercept = .5) +
          labs(x = "AUC in positive direction",
              title = "How predictive is each linear predictor by itself?",
              subtitle = ".5 is not predictive at all; <.5 means negatively associated with rain, >.5 means positively associated")
        ```

## Interactions

### Misc

-   See [Regression, Interactions](regression-qmd#sec-reg-inter){style="color: green"} for details
-   Interpretation
    -   Significant Interactions - The lines of the graph cross or sometimes if they converge (if there's enough data/power)
        -   This pattern is a visual indication that the effects of one IV change as the second IV is varied.
    -   Non-Significant Interactions - Lines that are close to parallel.

-   3-way Categorical Interaction  
    ![](./_resources/EDA.resources/Screenshot%20(505).png)

    -   3 Way interaction of reputation, status and sample (country)
    -   Shows percent, so not 

-   Typical Format: outcome_mean vs pred_var by pred_var
    
    ```r         
    data %>% 
      group_by(pred1, pred2) %>% 
      summarize(out_mean = mean(outcome)) %>% 
      ggplot(aes(y = out_mean, x = pred1, color = pred2)+
        geom_point() +
        geom_line()
    ```

    -   May also need a "group = pred2" in the aes function

-   Outcome: Categorical
    -   Numeric vs Numeric by Cat Outcome
        -   **Scatter** with 45 degree line
            
            ```r         
            ggplot(aes(num_predictor1, num_predictor2, color = cat_outcome_var)) +
               geom_point() +
               geom_abline(color = "red")
            ```
    
            -   Look for groupings or other patterns wrt to cat var.
            -   Cat-var colored points above line skew more towards the higher y-var than x-var and vice versa for below the 45 degree line.
            -   Line also shows how linearly correlated the two num vars are.
            -   If clustering present, could indicate a good interaction pair with the numeric : cat_var
        -   **Scatter** with linear smooth (or loess)  
            ![](./_resources/EDA.resources/Screenshot%20(351).png)
            
            ```r         
            ggplot(aes(num_predictor1, num_predictor2)) +
               geom_point(alpha = 0.25) +
               geom_smooth(aes(color = cat_outcome_var), method = "lm")
            ```
            
            -   Produces a lm line for each outcome var category
            -   Looking for differing trends for ranges of values on the x-axis. A pattern for one line that is substantially different from the other line
            -   Example: At around 28, the blue line trend rises while the red line continues to slope downwards, and they actually cross to where at some threshold of x, the relationship is the opposite. So an interaction is likely present
    -   Binary Outcome (pct_event) vs Discrete by Discrete (or binary in this case)  
        ![](./_resources/EDA.resources/Screenshot%20(354).png)
        
        ```r         
        data %>%
            mutate(avg_trans_amt = total_trans_amt / total_trans_ct) %?%
            group_by(total_trans_ct = cut(total_trans_ct, c(0,30, 40, 50, 60, 80, Inf)),
                    avg_trans_amt = ifelse(avg_trans_amt >= 50, "> $50", "< $50") %>%
                    # use to figure out best cut point(s) that keeps the ribbon width small-ish on all lines
                    # avg_trans_amt = cut(avg_trans_amt, c(0, 50, 100, 130, Inf)) %>%   
            summarize(n = n(),
                      n_churned = sum(churned == "yes"),
                      pct_churned = n_churned/n,
                      low = qbeta(.025, n_churned + .5, n - n_churned + .5), 
                      high = qbeta(.975, n_churned + .5, n - n_churned + .5)) %>%
                arrange(desc(n)) %>%
            ggplot(aes(total_trans_ct, pct_churned, color = avg_trans_amt) +
            geom_point() +
            geom_line() +
            geom_ribbon(aes(ymin = low, ymax = high))           
        ```
        
        -   Interpretation:
            -   Clear alternating trend from about 0 to 40 on the x-axis says there's probably an interaction (at least with the binned versions of these variables) between total_trans_ct and avg_trans_amt.
                -   i.e. The relationship between transaction count and churned (binary outcome) (pct_churned) depends on the average transaction amount
        -   Example: The cut points for avg_trans_amt were chosen from its distribution
            -   The distribution was bi-modal and the 3 cutpoints were the 1st mode, point that splits both modal distributions, and the 2nd mode.
            -   [{Upsetr}]{style="color: #990000"} might be useful to examine bimodal structure and determine cutpoints based on categorical predictor values and not just outcome values
            -   [{gghdr}]{style="color: #990000"} - viz for multi-modal distribtutions
            -   Also see [Regression, Other \>\> Mult-Modal](regression-other.html#sec-reg-other-multmod){style="color: green"}
        -   Example of likely no interaction  
            ![](./_resources/EDA.resources/Screenshot%20(358).png)
            -   Blue and red lines move in unison. Same trend directions.
                -   There is separation, so the mean value of percent churn is different. Also, the slopes are different, so the rates of increase and decrease would be different. I'm not convinced. I'd like to see if an interaction term wouldn't be significant
                -   kaggle sliced s01e07 dataset - percent churn (y-axis), revolving balance bucketed (x-axis), color = total_transactions dicotomized. [DRob video](https://www.youtube.com/watch?v=oCGmh3NIJ7I) for the code.
-   Categorical vs Binary Outcome (pct_event) by Categorical
    -   Sliding Window Continuous vs Binary Outcome (Proportion of Event) by Categorical  
        ![](./_resources/EDA.resources/image.5.png)
        
        ```r         
        ggplot(z, aes(x=price, y=`Moving Proportion`, col=factor(class))) +
          geom_line() + guides(color=guide_legend(title='Class')) +
          xlab(hlab(price)) + ylab('Survival')
        ```
        
        -   "Moving Proportion" is the mean of the binary outcome (probability of an event) over a sliding window of "Total Price"
        -   "Total Price" should be sorted in ascending order and grouped by "Class" before the sliding window is applied
        -   Harrell uses a default window of 15 observations on either side of the target point, but says the results can be noisy. Recommends passing the results through a smoother
            -   So, might want to add a `geom_smooth` to the code chunk
            -   I might like to see the data points to see how many points at the ends of lines there are. Smoothed lines can be misleading on the boundaries.
    -   Sliding Window Continuous vs Binary Outcome (Proportion of Event) by 2 Categoricals  
        ![](./_resources/EDA.resources/image.6.png)
        
        ```r         
        ggplot(d, aes(x=age, y=`Moving Proportion`, col=factor(class))) +
          geom_smooth() +
          facet_wrap(~ sex) +
          ylim(0, 1) + xlab(hlab(age)) + ylab('Survival') +
          guides(color=guide_legend(title='Class'))
        ```

        -   Similar to above but grouped by 2 variables before the sliding window calculation.

    -   **Grouped Bar**  
        ![](./_resources/EDA.resources/Screenshot%20(345).png)
        
        ```r         
        summarize_churn <- function(tbl) {
            tbl %>%
                summarize(n = n(),
                          n_churned = sum(churned == "yes"),
                          pct_churned = n_churned/n,
                        # Jeffrey's Interval (Bayesian CI)
                          low = qbeta(.025, n_churned + .5, n - n_churned + .5), 
                          high = qbeta(.975, n_churned + .5, n - n_churned + .5)) %>%
                arrange(desc(n))
        }
        plot_categorical <- function(tbl, categorical, ...) {
            tbl %>%       
                ggplot(aes(pct_churned, [{{categorical}}]{style='color: goldenrod'}), ...) + 
                geom_col(position = position_dodge()) + 
                geom_errorbar(aes(xmin = low, xmax = high),
                              height = 0.2, color = red,
                              position = position_dodge(width = 1) +
                scale_x_continuous(labels = percent) +
                labs(x = "% in category that churned")
        }
        data %>%
            group_by(cat_var1, cat_var2) %>%
            summarize_churn() %>%
            plot_categorical(cat_var1, fill = cat_var2, group = cat_var2)
        ```

        -   Interpretation: Probably not an interaction variable. Pct Churned by education Level doesn't vary (much) by  Gender especially if you take the error bars into account
            -   Only for "college" do you see a flip in the relationship where females churn more than men, but it's still within the error bars.
-   Outcome: Continuous
    -   Numeric vs Numeric, Scatter with Smoother by a Categorical  
        ![](./_resources/EDA.resources/image.4.png)
        
        ```r         
        ggplot(w, aes(x=age, y=price, color=factor(class))) +
          geom_point() +
          geom_smooth() +
          scale_y_continuous(trans='sqrt') +
          guides(color=guide_legend(title='Class')) +
          hlabs(age, price)
        ```
        
        -   Continuous outcome has been transformed so that the lower values can be more visible
        -   "Class" == 1 ⨯ Age shows some variation but the other two classes do not seem to show much. Lookng at the scatter of red dots, I'm skeptical that variation being shown by the curve.
            -   Although the decent separation of the "Class" groups may be what indicates an informative interaction
    -   Continuous (DV) vs Categorical (IV) by Categorical (IV)  
        ![](./_resources/EDA.resources/Screenshot%20(499).png)
        -   Significant interaction effect (crossing)
            -   Variable A had no significant effect on participants in Condition B1 but caused a decline from A1 to A2 for those in Condition B2
    -   Correlation Heatmaps
        -   Filter data by different levels of a categorical, then note how correlations between numeric predictors and the numeric outcome change
        -   Example: PM 2.5 pollution (outcome) vs complete dataset and filtered for Wind Direction = NE
            -   Complete  
                ![](./_resources/EDA.resources/1-AdMrKIjcDnVHl3PXLfmVWg.png)
            -   Wind Direction = NE  
                ![](./_resources/EDA.resources/1-qk97V3pj37kpo1-NyF3cEA.png)
            -   Interpretation
                -   Temperature's correlation (potentially its predictive strength) would *lessen* if would be interacted with Wind Direction. So we do **NOT** want to interact wind direction and temperature
                    -   Article didn't show whether it increases with other directions
                -   Wind Strength's (cws) correlation with the outcome would *increase* if interacted with Wind Direction. So we do want to interacted wind direction and wind strength
                    -   For ML, I think you'd dummy the wind direction, then multiply windspeed times each of the dummies.
    -   Boxplot by Discrete (Binned) Continuous
        -   `pmin` can be similarily used as fct_lump (see below) but for discrete integer variables
            -   If the distribution of the discrete numeric is skewed to the right, then pmin will bin all integers larger than some number
                -   Most of the distribution are small integers and the rest will be binned into a sort of "other" category (e.g. 14)
            -   If the distribution is skewed to the left, `pmax` can be used similarily.  
                ![](./_resources/EDA.resources/Screenshot%20(332).png)
                
                ```r         
                data %>%
                   mutate(integer_var = pmin(integer_var, 14) %>%
                   ggplot(aes(int_var, numeric_outcome, group = int_var)) +
                   geom_boxplot()
                ```

                -   If all the medians line up then no relationship. A slope or nonlinear pattern shows relationship.

## Categorical Predictor vs Outcome

-   Numeric Outcome
    -   **Boxplot** by categorical
        -   `fct_reorder`  says order cat_var by a num_var
            -   \* make sure data is NOT grouped \*

```         
data %>%
    mutate(cat_var = fct_reorder(cat_var, numeric_outcome)) %>%
    ggplot(aes(numeric_outcome, cat_var)) +
    geom_boxplot()
```

-   If all the medians line up then no relationship. A slope or nonlinear shows relationship.

-   `fct_lump`  can be used to create an "other" group.

    -   Useful for cat_vars with too many levels which can muck-up a graph![](./_resources/EDA.resources/Screenshot%20(331).png)

```         
data %>%
    mutate(cat_var = fct_lump(cat_var, 8),
          cat_var = fct_reorder(cat_var, numeric_outcome)) %>%
    ggplot(aes(numeric_outcome, cat_var)) +
    geom_boxplot()
```

-   Says to keep the top 8 levels with the highest counts and put rest in "other".
    -   Also takes proportions. Negative values says keep lowest.
-   Boxplot by Categorical (Titanic5 dataset)![](./_resources/EDA.resources/newplot.png)
    -   Y-Axis is the "Class" categorical with 3 levels
    -   For ticket price, only class 1 shows any variation
    -   For Age, there's a clear trend but also considerable overlap between classes
-   Categorical outcome
    -   **Histograms** of cat_vars split by response_var 

```         
df %>%
    select(cat_vars) %>%
    pivot_longer(key, value = cat_vars, response_var) %>%
    ggplot(aes(value)) +
    geom_bar(fill = response_var) +
    facet_wrap( ~key, scales = "free")
```

-   Just looking for variation in the levels of the cat_var given response var. More variation = more likely to be a better predictor

-   Each facet will be a level of the response variable

-   Error Bar Plot

    -   binary outcome: group by cat predictors and calculate proportion of event

```         
# outcome variable is a binary for whether or not it rained on that day
group_binary_prop <- function(tbl) {
    ret <- tbl %>%
        # count of events for each category (successes)
        summarize(n_rain = sum(rain_tomorrow == "Rained"),
                  # count of rows for each category (trials)
                  n = n()) %>%
        arrange(desc(n)) %>%
        ungroup() %>%
        # probability of event for each category
        mutate(pct_rain = n_rain / n,
              # jeffreys interval
              # bayesian CI for binomial proportions
              low = qbeta(.025, n_rain + .5, n - n_rain + .5),
              high = qbeta(.975, n_rain + .5, n - n_rain + .5)) %>%
        # proportion of all events for each category
        mutate(pct = n_rain / sum(n_rain))
        # this was the original but this would just be proportion of the total data for each caategory
        # mutate(pct = n / sum(n))
    ret
}

# error bar plot
# cat vs probability of event w/CIs
train %>%
    # cat predictor
    group_by(location = fct_lump(location, 50)) %>%
    # apply custom function
    group_binary_prop() %>%
    mutate(location = fct_reorder(location, pct_rain)) %>%
    ggplot(aes(pct_rain, location)) +
    geom_point(aes(size = pct)) +
    geom_errorbarh(aes(xmin = low, xmax = high), height = .3) +
    scale_size_continuous(labels = percent, guide = "none", range = c(.5, 4)) +
    scale_x_continuous(labels = percent) +
    labs(x = "Probability of raining tomorrow",
      y = "",
      title = "What locations get the most/least rain?",
      subtitle = "Including 95% confidence intervals. Size of points is proportional to frequency")
```

-   this needs some tidyeval so it can generalize to other binary(?) outcome vars

-   simpler (uncommented) version

```         
summarize_churn <- function(tbl) {
    tbl %>%
        summarize(n = n(),
                  n_churned = sum(churned == "yes"),
                  pct_churned = n_churned/n,
                  low = qbeta(.025, n_churned + .5, n - n_churned + .5), 
                  high = qbeta(.975, n_churned + .5, n - n_churned + .5)) %>%
        arrange(desc(n))
}

plot_categorical <- function(tbl, categorical, ...) {
    tbl %>%       
        ggplot(aes(pct_churned, cat_pred), ...) +
        geom_col() +
        geom_errorbar(aes(xmin = low, xmax = high), height = 0.2, color = red) +
        scale_x_continuous(labels = percent) +
        labs(x = "% in category that churned")
}

data %>%
    group_by(cat_var) %>%
    summarize_churn() %>%
    plot_categorical(cat_var)
```

-   2 binned numerics vs binary outcome
    -   Segmentation Chart![](./_resources/EDA.resources/Screenshot%20(357).png)

```         
summarize_churn <- function(tbl) {
    tbl %>%
        summarize(n = n(),
                  n_churned = sum(churned == "yes"),
                  pct_churned = n_churned/n,
                  low = qbeta(.025, n_churned + .5, n - n_churned + .5), 
                  high = qbeta(.975, n_churned + .5, n - n_churned + .5)) %>%
        arrange(desc(n))
}

data %>%
    mutate(avg_trans_amt = total_trans_amt / total_trans_ct,
          total_transactions = ifelse(total_trans_ct >= 50,
                                        "> 50 Transactions",
                                        "< 50 Transactions"),
          avg_transaction = ifelse(avg_trans_amt >= 50,
                                      "> $50 Average",
                                      "< $50 Average")
    ) %>%
    group_by(total_transactions,avg_transaction) %>%
    summarize_churn() %>%
    ggplot(aes(total_transactions, avg_transaction)) +
    geom_tile(aes(fill = pct_churned)) +
    geom_text(aes(label = percent(pct_churned, 1))) +
    scale_fill_gradient2(low = "blue", high = "red", midpoint = 0.3) +
    labs(x = "How many transactions did the customer do?",
    y = "What was the average transaction size?",
    fill = "% churned",
    title = "Dividing customers into segments")
```

-   Each customer's spend is averaged and binned (\> or \< \$50)
-   Each customer's transaction count is binned (\> or \< 50)
-   The df is grouped by both binned vars, so you get 4 subgroups
    -   Proportions of each subgroup that falls into the event category of then binary variable (e.g. churn) are calculated
    -   Low and high quantiles for churn counts are calculated (typical calc of CIs for the proportions of binary variables)
        -   Used to add context of whether these are high proportions, low proportions, etc.

------------------------------------------------------------------------
