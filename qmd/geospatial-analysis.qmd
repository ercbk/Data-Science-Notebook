# Analysis {#sec-geo-anal .unnumbered}

## Misc {#sec-geo-anal-misc .unnumbered}

-   Also see
    -   [Domain Knowledge \>\> Epidemiology \>\> Disease Mapping](https://ercbk.github.io/Domain-Knowledge-Notebook/qmd/epidemiology.html#sec-epidemi-dismap){style="color: green"}
    -   [Mathematics, Statistics \>\> Multivariate \>\> Depth](mathematics-statistics.qmd#sec-math-statc-multiv-depth){style="color: green"}
        -   Outlier detection and robust mean calculation for multivariate geospatial and spatio-temperal data
-   Packages
    -   [{]{style="color: #990000"}[exactextractr](https://isciences.gitlab.io/exactextractr/){style="color: #990000"}[}]{style="color: #990000"} - Written in C++ to quickly and accurately summarize raster values over polygonal areas, commonly referred to as *zonal statistics*
        -   Has the traditional descriptive statistics and more
    -   [{]{style="color: #990000"}[sfhotspot](https://pkgs.lesscrime.info/sfhotspot/){style="color: #990000"}[}]{style="color: #990000"} ([Thread](https://bsky.app/profile/did:plc:d2kv3tpst3x3fkvpvbdkktva/post/3lvnsij4qg62w), [Intro](https://lesscrime.info/post/sfhotspot-1-0-0/))- Functions to identify and understand clusters of points (typically representing the locations of places or events)
        -   Built for novice users, by choosing reasonable default values and doing as much as possible for users behind the scenes. There's also a vignette to take more control for more experienced users.
-   Boundary Analysis
    -   The assessment of whether significant geographic boundaries are present and whether the boundaries of multiple variables are spatially correlated.
    -   Notes from [BoundaryStats: An R package to calculate boundary overlap statistics](https://www.biorxiv.org/content/10.1101/2024.10.20.619279v1)
    -   Packages
        -   {[BoundaryStats](https://cran.r-project.org/web/packages/BoundaryStats/index.html)} - Functions for boundary and boundary overlap statistics
    -   **Boundaries** are areas in which spatially distributed variables (e.g., bird plumage coloration, disease prevalence, annual rainfall) rapidly change over a narrow space.
    -   **Boundary Statistics**
        -   The length of the longest boundary
        -   The number of cohesive boundaries on the landscape
    -   **Boundary Overlap Statistics**
        -   The amount of direct overlap between boundaries in variables $A$ and $B$
        -   The mean minimum distance between boundaries in $A$ and $B$ (i.e. minimums are measured within $A$)
            -   For instance, the minimum distance between $\text{boundary}_{A,i}$ and $\text{boundary}_{A,j}$
        -   The mean minimum distance from boundaries in $A$ to boundaries in $B$
    -   Use Cases
        -   By identifying significant cohesive boundaries, researchers can delineate relevant geographic sampling units (e.g., populations as conservation units for a species or human communities with increased disease risk).
        -   Associations between the spatial boundaries of two variables can be useful in assessing the extent to which an underlying landscape variable drives the spatial distribution of a dependent variable.
        -   Identifying neighborhood effects on public health outcomes, including COVID-19 infection risk or spatial relationships between high pollutant density and increased disease risk.

## Terms {#sec-geo-anal-terms .unnumbered}

-   [**Areal**]{style="color: #009499"} (aka [**Lattice**]{style="color: #009499"}) [**Data**]{style="color: #009499"} - Data in a study region that is partitioned into a limited number of areas, with outcomes being aggregated or summarized within those areas (instead of at points). Examples include:
    -   Population density
    -   Disease rates
    -   Income levels
    -   Crime statistics
    -   Educational attainment
    -   Unemployment rates
-   [**Block Support**]{style="color: #009499"} - When the variable value summarizes all points in the geometry. (Also see **Point Support**)
    -   An aggregate; the feature is a single observation with a value that is associated with the entire geometry
    -   Examples
        -   Population, either as number of persons or as population density
        -   Other socio-economic variables, summarised by area
        -   Average reflectance over a remote sensing pixel
        -   Total emission of pollutants by region
        -   Bblock mean NO concentrations, such as obtained by block kriging over square blocks or by a dispersion model that predicts areal mean
-   [**Buffer**]{style="color: #009499"} - a zone around a geographic feature containing locations that are within a specified distance of that feature, the buffer zone. A buffer is likely the most commonly used tool within the proximity analysis methods. Buffers are usually used to delineate protected zones around features or to show areas of influence.
-   [**Catchment**]{style="color: #009499"} - The area inside any given polygon is closer to that polygon's point than any other. Refers to the area of influence from which a retail location, such as a shopping center, or service, such as a hospital, is likely to draw its customers. (also see [Retail](Retail) \>\> Catchment)
-   [**Data Fusion**]{style="color: #009499"} - The primary idea is to combine different types of spatial data. This can include:
    -   Remote Sensing Data: Satellite imagery (multispectral, hyperspectral, SAR, LiDAR), drone data, aerial photographs. These often provide wide coverage and different spectral/spatial resolutions.
    -   In-situ Data: Field measurements, sensor networks, ground surveys. These offer high accuracy at specific locations.
    -   GIS Databases: Vector data (points, lines, polygons), land use maps, elevation models.
    -   Socio-economic Data: Population density, demographic information.
    -   Temporal Data: Combining data from the same source over different time periods (e.g., monitoring deforestation over years).
-   [**Extensive Variables**]{style="color: #009499"} - Correspond to amounts, associated with a physical size (length, area, volume, counts of items). (Also see **Intensive Variables**)([source](https://r-spatial.org/book/05-Attributes.html#sec-extensiveintensive))
    -   [Example]{.ribbon-highlight}: Population Count
        -   It is associated with an area, and if that area is cut into smaller areas, the population count needs to be split too.
        -   Because population is *rarely uniform* over space, this does not need to be done proportionally to the smaller areas, but [the sum of the population count for the smaller areas needs to equal that of the total.]{.underline}
-   [**Identitiy Variable**]{style="color: #009499"} - When the associated geometry uniquely identifies the variableâ€™s value (there are no other geometries with the same value)
    -   [Example]{.ribbon-highlight}: An arbitrary point (or region) inside a county is still part of the county and must have the same value for *county name*, but it no longer identifies the (entire) geometry corresponding to that county
-   [**Intensive Variables**]{style="color: #009499"} - Variables that do NOT have values proportional to support: if the area is split, values may vary but *on average* remain the same. (Also see **Extensive Variables**)([source](https://r-spatial.org/book/05-Attributes.html#sec-extensiveintensive))
    -   [Example]{.ribbon-highlight}: Population Density
        -   If an area is split into smaller areas, population density is not split similarly: the *sum* of population densities for the smaller areas is a meaningless measure, as opposed to [the *average* of the population densities which will be similar to the density of the total area.]{.underline}
-   [**Point Support**]{style="color: #009499"} - When the variable value applies to every point (Also see **Block Support**)
    -   The attribute value is valid everywhere in or over the geometry; we can think of the feature as consisting of an infinite number of points that all have this attribute value
    -   Examples
        -   Land use for a land use polygon
        -   Rock units or geologic strata in a geological map
        -   Soil type in a soil map
        -   Elevation class in an elevation map that shows elevation as classes
        -   Climate zone in a climate zone map
-   [**Spatial Functional Data**]{style="color: #009499"} - Data comprising curves or functions that are recorded at each spatial location.

## Descriptive {#sec-geo-anal-desc .unnumbered}

-   Average elevation for areas ([source](https://dewey.dunnington.ca/slides/rspatial2025/#/sf-for-bigger-data-st_join))

    ``` r
    pacman::p_load(
      sf,
      dplyr,
      purrr,
      geo
    )

    # Read the CRS of the source
    elevation_crs <- st_layers("data/ns-water_elevation.fgb")$crs[[1]]

    # Transform the bounds to the CRS of the source
    bounds_poly <- bounds_lonlat |>
      st_transform(elevation_crs) |>
      st_as_sfc()

    # Read just the data you need
    elevation <- st_read(
      "data/ns-water_elevation.fgb",
      wkt_filter = st_as_text(bounds_poly)
    )

    lakes <- read_sf("data/ns-water_water-poly.fgb")
    # filter lakes and convert crs
    lakes <- lakes |>
      filter(st_intersects(lakes, 
                           bounds_poly[[1]], 
                           sparse = FALSE)) |>
      st_transform(elevation_crs)

    ######### methods for calculating mean elevation #########

    # 1.
    # long way
    # lakes$mean_elev <- lakes$geometry |>
    #   map_dbl(~{
    #     elev_is_relevant <- st_intersects(elevation, .x, sparse = FALSE)
    #     mean(elevation$ZVALUE[elev_is_relevant])
    #   })

    # 2.
    lakes |>
      mutate(row_id = row_number()) |>
      st_join(elevation, join = st_intersects) |>
      group_by(row_id) |>
      summarise(mean_elev = mean(ZVALUE.y))

    # 3.
    index <- geos_strtree(elevation)
    lakes$geometry |>
      as_geos_geometry() |>
      map_dbl(~{
        elevation_candidates <- 
          elevation[geos_strtree_query(index, .x)[[1]]]

        elevations <- 
          elevation_candidates[geos_prepared_intersects(elevation_candidates, .x)]

        mean(geos_z(elevations))
        })
    ```

    -   Finds the average elevation for some lakes
    -   The "long way" takes about about 223 sec
    -   The sf join way takes about 10 sec
    -   The geos way takes about 2.5 sec
        -   `geos_strtree` creates a spatial index which speeds things up

## Proximity Analysis {#sec-geo-anal-proxanal .unnumbered}

-   [Example]{.ribbon-highlight}: Basic Workflow
    -   Data: Labels, Latitude, and Longitude

        ![](_resources/Geospatial-Analysis.resources/prox-baswkflw-dat-1.png){.lightbox width="314"}

    -   Create Simple Features (sf) Object

        ``` r
        customer_sf <- 
          customer_table %>%
            sf::st_as_sf(coords = c("longitude", "latitude"),
                         crs = 4326)
        ```

        -   Merges the [longitude]{.var-text} and [latitude]{.var-text} columns into a [geometry]{.var-text} column and transforms the coordinates in that column according to projection (e.g. `crs = 4326`)

    -   View points on a map

        ![](_resources/Geospatial-Analysis.resources/prox-baswkflw-map-1.png){.lightbox width="432"}

        ``` r
        mapview::mapview(customer_sf)
        ```

    -   Create Buffer Zones

        ![](_resources/Geospatial-Analysis.resources/prox-baswkflw-buff-1.png){.lightbox width="432"}

        ``` r
        customer_buffers <- 
          customer_sf %>%
            sf::st_transform(26914) %>%
            sf::st_buffer(5000)

        mapview::mapview(customer_buffers)
        ```

        -   Most of projections use meters, and based on the size of the circles as related to the size of Denton, TX, I'm guessing the radius of each circle is 5000m. Although, that still looks a little small.

    -   Create Isochrones

        ![](_resources/Geospatial-Analysis.resources/prox-baswkflw-isoc-1.png){.lightbox width="432"}

        ``` r
        customer_drivetimes <- 
          customer_sf %>%
            mapboxapi::mb_isochrone(time = 10, 
                                    profile = "driving", 
                                    id_column = "name")

        mapview::mapview(customer_drivetimes)
        ```

        -   10 minutes drive-time from each location
        -   [time]{.arg-text} (minutes): The maximum time supported is 60 minutes. Reflects traffic conditions for the date and time at which the function is called.
            -   If reproducibility of isochrones is required, supply an argument to the [depart_at]{.arg-text} argument.
        -   [depart_at]{.arg-text}: Specifying a time makes it a time-aware isochrone. Useful for modeling peak business hours or rush hour traffic, etc.
            -   e.g. Adding [depart_at = "2024-01-27T17:30"]{.arg-text} to the isochrone above gives you a 10-minute driving isochrone with predicted traffic at 5:30pm tomorrow

    -   Add Demographic Data

        ![](_resources/Geospatial-Analysis.resources/prox-baswkflw-demdat-1.png){.lightbox width="432"}

        ``` r
        denton_income <- 
          tidycensus::get_acs(
            geography = "tract",
            variables = "B19013_001",
            state = "TX",
            county = "Denton",
            geometry = TRUE
          ) %>%
            select(tract_income = estimate) %>%
            sf::st_transform(st_crs(customer_sf))

        customers_with_income <- customer_sf %>%
          sf::st_join(denton_income)

        customers_with_income
        ```

        -   Adds median income estimate according to the census tract each person lives in.

        -   Joins on the [geometry]{.var-text} variable
-   [Circular Buffer Approach]{.underline}
    -   Notes from [GIS-based Approaches to Catchment Area Analyses of Mass Transit](https://proceedings.esri.com/library/userconf/proc09/uc/papers/pap_1072.pdf)
    -   The simplest and most common used approach to make catchment areas of a location is to consider the Euclidean distance from the location.
    -   Due to limitations (See below), it's best suited for overall analyses of catchment areas.
    -   Often the level of detail in the method has been increased by dividing the catchment area into different rings depending on the distance to the station.
        -   [Example]{.ribbon-highlight}: By applying weights for each ring it is possible to take into account that the expected share of potential travelers at a train station will drop when the distance to the stop is increased.\
            ![](_resources/Geospatial-Analysis.resources/prox-circ-catch-1.png){.lightbox width="432"}\
    -   Limitation: Does not take the geographical surroundings into account.
        -   [Example]{.ribbon-highlight}: In most cases, the actual walking distance to/from a location is longer than the Euclidean distance since there are natural barriers like rivers, buildings, rail tracks etc.
            -   This limitation is often coped with by applying a detour factor that reduces the buffer distance to compensate for the longer walking distance.
            -   However, in cases where the length of the detours varies considerably within the location's surroundings, this solution is not very precise.
            -   Furthermore, areas that are separated completely from a location, e.g. by rivers, might still be considered as part of the location's catchment area
    -   Use Case: Ascertain Travel Potential to Determine Potential Station Locations
        -   Every 50m along the proposed transit line, calculate the travel potential for that buffer area

            -   Using the travel demand data for that buffer area, calculate travel potential

        -   Travel Potential Graph

            ![](_resources/Geospatial-Analysis.resources/prox-circ-trav-pot-1.png){.lightbox width="432"}

            -   Left side represents the transit line.
            -   Right Side
                -   Y-Axis are locations where buffer areas were created.
                -   X-Axis: [Travel Potential]{.var-text}
                    -   Not sure if that is just smoothed line with a point estimate of Travel Potential at each location or how exactly those values are calculated.
                        -   50m isn't a large distance so maybe all the locations aren't shown on the Y-Axis and the number of calculations produces an already, mostly, smooth line on it's own.
                    -   Partitioning a buffer zone into rings or some kind of interpolation could provided more granular estimates around the central buffer location.
