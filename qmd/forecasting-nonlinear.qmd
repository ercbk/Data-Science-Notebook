# Forecasting, Nonlinear

TOC

* Misc
* EDA
* Variational Mode Decomposition (VMD) Based Time Delay Neural Network Model (TDNN)
* Taken's Embedding




Misc

* Gaps in the time variable can be a problem if you are trying to interpolate between those gaps. (see bkmk, method = "reml" + s(x, m = 1))
* Packages
	* TIme Series [Task View](http://cran.r-project.org/web/views/TimeSeries.html) "Nonlinear Time Series Analysis"
	* [{nonlinearTseries}]{style='color: #990000'}
	* [{]{style='color: #990000'}[probcast](https://github.com/jbrowell/ProbCast){style='color: #990000'}[}]{style='color: #990000'} which has function wrappers around gams, gamlss, and boosted gamlss models from {mgcv}, {mboost}, {gamlss}, etc. for use in forecasting. Supports high-dimensional dependency modeling based on Gaussian Copulas ([paper](http://www.jethrobrowell.com/uploads/4/5/4/0/45405281/probcast___pmaps2020.pdf), [use case](https://forecasting.svetunkov.ru/en/2023/05/09/probabilistic-forecasting-of-hourly-emergency-department-arrivals/))
* Copulas
	* Also see [Correlation, Association, and Distance](Correlation, Association, and Distance) >> Nonlinear >> Copulas
	* [TUTORIAL julia, copulas + ARMA model, example w/exonential distribution - ARMA Forecasting for Non-Gaussian Time-Series Data Using Copulas | by Sarem Seitz | Jun, 2022 | Towards Data Science](https://towardsdatascience.com/arma-forecasting-for-non-gaussian-time-series-data-using-copulas-45a3a28f69e5)
	* Issues
		* When the size of the observed time-series becomes very large.
			* In that case, the unconditional covariance matrix will scale poorly and the model fitting step will likely become impossible.
			* Potential Solution: [Implicit Copulas](https://arxiv.org/pdf/2109.04718.pdf) which define a Copula density through a chain of conditional densities
		* MLE for distributions where the derivatives of their cdfs becomes complex
			* Exponental distribution's is simple (used in article)
			* See article for potential solutions



EDA

* Chaotic nature of the time series is obvious (e.g. frequent, unexplainable shocks that can't be explained by noise)
	* Create an artificial data set using a gaussian dgp and compare it to the observed data set
		* For details see R >> Documents >> Time Series >> nonlinear-time-series-analysis-2ed-kantz-schreiber (pg6 and Ch.4 sect 7.1)
			* Takes the range of values, mean, and variance from the observed distribution and generates data
			* Then data is filtered so that the power spectum is the same
			* "Phase Portraits" are used to compare the datasets.



Seasonal Trend Decomposition using LOESS (STL) - Extreme Learning Machine (ELM)

* Hybrid univariate forecasting model for complex series (non-stationary, non-linear)
* The univariate series is decomposed into subseries using STL and each subseries is forecast using ELM, then those subseries forecasts are ensembled for the final forecast
	* Each subseries is simpler and stationary



Variational Mode Decomposition (VMD) Based Time Delay Neural Network Model (TDNN)

* Hybrid univariate forecasting model for complex series (non-stationary, non-linear)
* The univariate series is decomposed into "modes" using VMD and each mode is forecast using TDNN, then those mode forecasts are recombined for the final forecast
	* The modes are generated by Intrinsic Mode Functions (IMFs)
		* Orthogonal to each other, stationary, and non-linear
	* Think the recombination method is simply to sum the forecasts
* Misc
	* [{]{style='color: #990000'}[vmdTDNN](https://cran.r-project.org/web/packages/vmdTDNN/index.html){style='color: #990000'}[}]{style='color: #990000'}
		* useR [video](https://www.youtube.com/watch?v=B8rjfZECSeg&list=PL77T87Q0eoJhayMV5-dRZHiGPqJVM1WnB&index=9) (1st talk) (paper is paywalled)
* The number of modes you choose is very important
* Methods for choosing the number of modes
	* Central Frequency Method (CFM)
	* Signal Difference Average (SDA)



Taken's Embedding

* A Dynamic Systems Model that transforms the time series into space where the dimensions are determined by multiples of lags of the time series. This transformation removes the autocorrelation between the data points and allows it to be forecasted.
	* Kind of like a SVM
* Misc
	* [{nonlinearTseries}]{style='color: #990000'}
* Parameters
	* **d** or **τ** - Called the time delay, this will tell us how many time lags each axis of the phase space will represent

```
# tau (time delay) estimation based on the average mutual information function
tau.ami = timeLag(ts, technique = "ami", 
                  lag.max = 100, do.plot = T)
```

* **m** - Called the embedding dimension, this parameter will tell us the dimension of the phase space

```
# m (embedding dimension) uses the tau estimation
emb.dim = estimateEmbeddingDim(ts, time.lag = tau.ami,
                              max.embedding.dim = 15)
```

* Estimated using Cao’s algorithm

* Phase Space Embedding Matrix ![](./_resources/Forecasting,_Nonlinear.resources/1-gLSfAY43eOYZAATisoUOlA.png)
	* where f(t) is the univariate time series
* Build the Taken's model

```
tak = buildTakens(ts,embedding.dim = emb.dim, time.lag = tau.ami)
```















