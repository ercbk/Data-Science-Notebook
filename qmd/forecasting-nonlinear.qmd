# Nonlinear {#sec-fcast-nlin .unnumbered}

## Misc {#sec-fcast-nlin-misc .unnumbered}

-   Gaps in the time variable can be a problem if you are trying to interpolate between those gaps. (see bkmk, `method = "reml" + s(x, m = 1)`)
-   Packages
    -   Time Series [Task View](http://cran.r-project.org/web/views/TimeSeries.html) "Nonlinear Time Series Analysis"
    -   [{]{style="color: #990000"}[aplms](https://cran.r-project.org/web/packages/aplms/index.html){style="color: #990000"}[}]{style="color: #990000"} - Additive Partial Linear Models with Symmetric Autoregressive Errors
        -   Set of tools for fitting the additive partial linear models with symmetric autoregressive errors of order p, or APLMS-AR(p).
        -   Enables the modeling of a time series response variable using linear and nonlinear structures of a set of explanatory variables, with nonparametric components approximated by natural cubic splines or P-splines.
        -   Also accounts for autoregressive error terms with distributions that have lighter or heavier tails than the normal distribution
            -   Error Distributions: normal, generalized normal, Student's t, generalized Student's t, power-exponential, and Cauchy distributions
    -   [{]{style="color: goldenrod"}[EristroPy](https://zblanks.github.io/eristropy/){style="color: goldenrod"}[}]{style="color: goldenrod"} ([Paper](https://arxiv.org/html/2405.06112v1)) - Bayesian optimization of Sample Entropy's hyperparameters
    -   [{]{style="color: #990000"}[EstemPMM](https://cran.r-project.org/web/packages/EstemPMM/index.html){style="color: #990000"}[}]{style="color: #990000"} - Implements the Polynomial Maximization Method ('PMM') for parameter estimation in linear and time series models when error distributions deviate from normality.
        -   The 'PMM2' variant achieves lower variance parameter estimates compared to ordinary least squares ('OLS') when errors exhibit significant skewness.
        -   Includes methods for linear regression, 'AR'/'MA'/'ARMA'/'ARIMA' models, and bootstrap inference.
    -   [{]{style="color: #990000"}[giancarlo-verse](https://rpubs.com/giancarlo_vercellino){style="color: #990000"}[}]{style="color: #990000"} - Giancarlo is building a lot of wonderfully complex model packages, so I'm just going to link his R-Pubs page which has intros to these packages.
        -   [{]{style="color: #990000"}[wired](https://cran.r-project.org/web/packages/wired/index.html){style="color: #990000"}[}]{style="color: #990000"} - Weighted Adaptive Prediction with Structured Dependence
    -   [{]{style="color: #990000"}[nonlinearTseries](https://cran.r-project.org/web/packages/nonlinearTseries/){style="color: #990000"}[}]{style="color: #990000"} ([Vignette](https://cran.r-project.org/web/packages/nonlinearTseries/vignettes/nonlinearTseries_quickstart.html)) - Facilitates the computation of the most-used nonlinear statistics/algorithms including generalized correlation dimension, information dimension, largest Lyapunov exponent, sample entropy and Recurrence Quantification Analysis (RQA), among others. Basic routines for surrogate data testing are also included.
    -   [{]{style="color: #990000"}[probcast](https://github.com/jbrowell/ProbCast){style="color: #990000"}[}]{style="color: #990000"} - Has function wrappers around gams, gamlss, and boosted gamlss models from {mgcv}, {mboost}, {gamlss}, etc. for use in forecasting. Supports high-dimensional dependency modeling based on Gaussian Copulas ([paper](http://www.jethrobrowell.com/uploads/4/5/4/0/45405281/probcast___pmaps2020.pdf), [use case](https://forecasting.svetunkov.ru/en/2023/05/09/probabilistic-forecasting-of-hourly-emergency-department-arrivals/))
    -   [{]{style="color: #990000"}[tsDyn](https://cran.r-project.org/web/packages/tsDyn/index.html){style="color: #990000"}[}]{style="color: #990000"}
        -   AR: standard linear AR (auto-regressive)
        -   SETAR: self-exciting threshold AR
        -   LSTAR: Logistic smooth transition AR
        -   NNET: neural-network
        -   AAR: additive AR
-   Resources
    -   [Temporal autocorrelation in GAMs and the mvgam package](https://ecogambler.netlify.app/blog/autocorrelated-gams/)
    -   Nonlinear Time Series Analysis, Kantz, Schreiber (See R \>\> Documents \>\> Time Series)
-   Copulas
    -   Also see [Association, Copulas](association-copulas.qmd#sec-assoc-cop){style="color: green"}
    -   [TUTORIAL julia, copulas + ARMA model, example w/exonential distribution - ARMA Forecasting for Non-Gaussian Time-Series Data Using Copulas \| by Sarem Seitz \| Jun, 2022 \| Towards Data Science](https://towardsdatascience.com/arma-forecasting-for-non-gaussian-time-series-data-using-copulas-45a3a28f69e5)
    -   Issues
        -   When the size of the observed time-series becomes very large.
            -   In that case, the unconditional covariance matrix will scale poorly and the model fitting step will likely become impossible.
            -   Potential Solution: [Implicit Copulas](https://arxiv.org/pdf/2109.04718.pdf) which define a Copula density through a chain of conditional densities
        -   MLE for distributions where the derivatives of their cdfs becomes complex
            -   Exponental distribution's is simple (used in article)
            -   See article for potential solutions

## Piecewise Linear {#sec-fcast-nlin-stlelm .unnumbered}

-   Simple approach that manually adds a knot at a specified location

-   Resources

    -   [Piecewise linear trends](https://robjhyndman.com/hyndsight/piecewise-linear-trends/) by Hyndman

-   [Example]{.ribbon-highlight}: [{fable}]{style="color: #990000"} ([source](https://otexts.com/fpp3/nonlinear-regression.html#example-boston-marathon-winning-times))

    ``` r
    boston_men <- boston_marathon |>
      filter(Year >= 1924) |>
      filter(Event == "Men's open division") |>
      mutate(Minutes = as.numeric(Time)/60)

    fit_trends <- boston_men |>
      model(
        linear = TSLM(Minutes ~ trend()),
        exponential = TSLM(log(Minutes) ~ trend()),
        piecewise = TSLM(Minutes ~ trend(knots = c(1950, 1980)))
      )
    fc_trends <- fit_trends |> forecast(h = 10)
    ```

-   [Example]{.ribbon-highlight}: ([source](https://ramikrispin.github.io/r-ladies-rome-workshop/05_forecasting_with_lm.html#piecewise-linear-trend))\

    ::: {layout-ncol="2"}
    ![Linear](_resources/Forecasting,_Nonlinear.resources/piec-ex1-1.png){.lightbox group="piec-ex1" width="332"}

    ![Piecewise](_resources/Forecasting,_Nonlinear.resources/piec-ex1-2.png){.lightbox group="piec-ex1" width="332"}
    :::

    ::: panel-tabset
    ## Linear Model

    ``` r
    ts1 <-  # <1>
      ts1 |> 
      dplyr::filter(index > 1986) |> 
      dplyr::mutate(trend = seq_len(dplyr::n()))
    head(ts1)
    # A tsibble: 6 x 4 [1Y]
    #>   index       y series_id trend
    #>   <int>   <int> <chr>     <int>
    #> 1  1987 7904858 SCA           1
    #> 2  1988 8113034 SCA           2
    #> 3  1989 8313776 SCA           3
    #> 4  1990 8497848 SCA           4
    #> 5  1991 8634774 SCA           5
    #> 6  1992 8680613 SCA           6

    md1 <- lm(y ~ trend, data = ts1)
    fit1 <- 
      predict(object = md1, 
              newdata = ts1,  
              interval = "confidence", 
              level = 0.95)
    ts1$fit1 <- fit1[, 1]

    plot_ly() |>
      add_lines(x = ts1$index, 
                y = ts1$y, 
                type = "scatter", 
                mode = "lines", 
                name = "Actual") |> 
      add_lines(x = ts1$index, 
                y = ts1$fit1, 
                mode = "lines", 
                line = list(color = "black", 
                            dash = "dash"), 
                name = "Fitted") 
    ```

    1.  Removes a 0 value for [1986]{.arg-text} and adds a [trend]{.var-text} variable which is just a row index.

    ## Piecewise Model

    ``` r
    s <- ts1$trend[which(ts1$index == 2008)] # <1>
    ts1$trend2 <- pmax(0, ts1$trend - s) # <2>
    ts1[(s-5):nrow(ts1), ] 
    #> # A tsibble: 21 x 5 [1Y]
    #>    index        y series_id trend trend2
    #>    <int>    <int> <chr>     <int>  <dbl>
    #>  1  2003  9803311 SCA          17      0
    #>  2  2004  9957412 SCA          18      0
    #>  3  2005 10124433 SCA          19      0
    #>  4  2006 10329224 SCA          20      0
    #>  5  2007 10439220 SCA          21      0
    #>  6  2008 10515162 SCA          22      0
    #>  7  2009 10510950 SCA          23      1
    #>  8  2010 10542584 SCA          24      2
    #>  9  2011 10625190 SCA          25      3
    #> 10  2012 10681916 SCA          26      4
    #> 11  2013 10754908 SCA          27      5
    #> 12  2014 10781720 SCA          28      6
    #> 13  2015 10969597 SCA          29      7
    #> 14  2016 10916368 SCA          30      8
    #> 15  2017 11004853 SCA          31      9
    #> 16  2018 11025789 SCA          32     10
    #> 17  2019 11112094 SCA          33     11
    #> 18  2020 11186350 SCA          34     12
    #> 19  2021 11232552 SCA          35     13
    #> 20  2022 11280329 SCA          36     14
    #> 21  2023 11355756 SCA          37     15


    md2 <- 
      lm(y ~ trend + trend2, data = ts1)
    fit2 <- 
      predict(object = md2, 
              newdata = ts1,  
              interval = "confidence", 
              level = 0.95)

    ts1$fit2 <- fit2[, 1]

    plot_ly() |>
      add_lines(x = ts1$index, 
                y = ts1$y, 
                type = "scatter", 
                mode = "lines", 
                name = "Actual") |>
      add_lines(x = ts1$index, 
                y = ts1$fit2, 
                mode = "lines", 
                line = list(color = "black", 
                            dash = "dash"), 
                name = "Fitted") 
    ```

    1.  This is a yearly time series, so the [index]{.var-text} values are years. [2008]{.arg-text} is where we want to place the knot to account for the change in trend.
    2.  `pmax` chooses greatest value between zero and the expression. This results in an index starting with the value after the knot location.
    :::

## STL-ELM {.unnumbered}

-   Packages
    -   [{]{style="color: #990000"}[stlELM](https://cran.r-project.org/web//packages//stlELM/index.html){style="color: #990000"}[}]{style="color: #990000"} - Hybrid Forecasting Model Based on STL Decomposition and ELM
-   Papers
    -   [STL-ELM: A Decomposition-Based Hybrid Model for Price Forecasting of Agricultural Commodities](https://link.springer.com/article/10.1007/s40009-022-01169-9)
-   Seasonal Trend Decomposition using LOESS (STL) - Extreme Learning Machine (ELM)
-   Hybrid univariate forecasting model for complex series (non-stationary, non-linear)
-   The univariate series is decomposed into subseries using STL and each subseries is forecast using ELM, then those subseries forecasts are ensembled for the final forecast
    -   Each subseries is simpler and stationary

## VMD-TDNN {#sec-fcast-nlin-vmdtdnn .unnumbered}

-   Variational Mode Decomposition (VMD) Based Time Delay Neural Network Model (TDNN)
-   Hybrid univariate forecasting model for complex series (non-stationary, non-linear)
-   The univariate series is decomposed into "modes" using VMD and each mode is forecast using TDNN, then those mode forecasts are recombined for the final forecast
    -   The modes are generated by Intrinsic Mode Functions (IMFs)
        -   Orthogonal to each other, stationary, and non-linear
    -   Think the recombination method is simply to sum the forecasts
-   Misc
    -   [{]{style="color: #990000"}[vmdTDNN](https://cran.r-project.org/web/packages/vmdTDNN/index.html){style="color: #990000"}[}]{style="color: #990000"}
        -   useR [video](https://www.youtube.com/watch?v=B8rjfZECSeg&list=PL77T87Q0eoJhayMV5-dRZHiGPqJVM1WnB&index=9) (1st talk) (paper is paywalled)
-   The number of modes you choose is very important
-   Methods for choosing the number of modes
    -   Central Frequency Method (CFM)
    -   Signal Difference Average (SDA)

## Taken's Embedding {#sec-fcast-nlin-tknemb .unnumbered}

-   A Dynamic Systems Model that transforms the time series into space where the dimensions are determined by multiples of lags of the time series. This transformation removes the autocorrelation between the data points and allows it to be forecasted.

    -   Kind of like a SVM

-   Misc

    -   [{nonlinearTseries}]{style="color: #990000"}

-   Parameters

    -   **d** or **τ** - Called the time delay, this will tell us how many time lags each axis of the phase space will represent

        ``` r
        # tau (time delay) estimation based on the average mutual information function
        tau.ami = timeLag(ts, technique = "ami", 
                          lag.max = 100, do.plot = T)
        ```

    -   **m** - Called the embedding dimension, this parameter will tell us the dimension of the phase space

        ``` r
        # m (embedding dimension) uses the tau estimation
        emb.dim = estimateEmbeddingDim(ts, time.lag = tau.ami,
                                      max.embedding.dim = 15)
        ```

        -   Estimated using Cao's algorithm

-   Phase Space Embedding Matrix\
    ![](./_resources/Forecasting,_Nonlinear.resources/1-gLSfAY43eOYZAATisoUOlA.png)

    -   Where f(t) is the univariate time series

-   Build the Taken's model

    ``` r
    tak = buildTakens(ts,embedding.dim = emb.dim, time.lag = tau.ami)
    ```
