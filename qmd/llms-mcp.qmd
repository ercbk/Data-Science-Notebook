# Model Context Protocol (MCP) {#sec-llms-mcp .unnumbered}

-   Allows LLMS to more easily integrate with external tools
    -   It establishes a standard interface for APIs to communicate to LLMs. This way all types of APIs and their individual patterns can be integrated into an LLM app without too much hassle.
    -   Without MCP\
        ![](_resources/LLM-MCP.resources/wo-mcp-1.webp){.lightbox width="382"}
        -   You have build integration for each application and tool
    -   With MCP\
        ![](_resources/LLM-MCP.resources/w-mcp-1.webp){.lightbox width="382"}
        -   Interactions are standardized.
-   Notes from [MCP (Model Context Protocol): Simply explained in 5 minutes](https://read.highgrowthengineer.com/p/mcps-simply-explained?utm_source=multiple-personal-recommendations-email&utm_medium=email&triedRedirect=true)
-   Packages
    -   [{]{style="color: #990000"}[mcptools](https://posit-dev.github.io/mcptools/){style="color: #990000"}[}]{style="color: #990000"} - Allows MCP-enabled tools like Claude Desktop, Claude Code, and VS Code GitHub Copilot can run R code *in the sessions you have running* to answer your questions
        -   Works well with [{btw}]{style="color: #990000"}
    -   [{]{style="color: #990000"}[mcpr](https://mcpr.opifex.org/){style="color: #990000"}[}]{style="color: #990000"} - Enables R applications to expose capabilities (tools, resources, and prompts) to AI models through a standard JSON-RPC 2.0 interface. It also provides client functionality to connect to and interact with MCP servers
    -   [{]{style="color: goldenrod"}[fastapi_mcp](https://fastapi-mcp.tadata.com/getting-started/welcome){style="color: goldenrod"}[}]{style="color: goldenrod"} - Exposes FastAPI endpoints as Model Context Protocol (MCP) tools with Auth (i.e. takes an existing FastAPI application and essentially “turning it into” an MCP server)
    -   [{]{style="color: #990000"}[plumber2mcp](https://arman.aksoy.org/plumber2mcp/){style="color: #990000"}[}]{style="color: #990000"} - Takes a plumber API and exposes its endpoints as MCP utilities (Same as [{fastapi.mcp}]{style="color: goldenrod"})
        -   By adding MCP support to your Plumber API, you make your R functions available as:
            -   Tools: AI assistants can call your API endpoints directly

            -   Resources: AI assistants can read documentation, data, and analysis results

            -   Prompts: AI assistants can use pre-defined templates to guide interactions
-   Resources
    -   [Docs](https://modelcontextprotocol.io/introduction)
    -   [Model Context Protocol servers](https://github.com/modelcontextprotocol/servers) - Links to official mcp servers and community-based servers
-   Servers
    -   [R Econometrics MCP Server](https://github.com/gojiplus/rmcp/)
-   Using MCP servers rather than the cloud service CLI tools (e.g. BigQuery CLI) provides better security control over what LLM products (e.g. Claude Code) can access, especially for handling sensitive data that requires logging or has potential privacy concerns.
-   Protocol\
    ![](_resources/LLM-General.resources/mcp-protocol-1.png){.lightbox width="532"}
    -   **MCP Client:** Various clients and apps you use, like Cursor, know how to talk using the “MCP Protocol.”
    -   **MCP Servers:** Providers like Sentry, Slack, JIRA, Gmail, etc. set up **adapters** around their APIs that follow the MCP Protocol.
        -   They convert a message like “Get me the recent messages in the #alerts channel” to a request that can be sent to the Slack API
-   Server File(s) Components
    -   Defines a set of tools for the MCP Server to implement
    -   Creates the server to listen for incoming requests
    -   Defines a \`switch\` case that receives the tool call and calls the underlying external API, like the Slack API.
    -   Wire up transport between Client and Server
        -   Allows the MCP client and server to communicate more simply than standard HTTP requests. Instead, they can read from standard IO when communicating.
