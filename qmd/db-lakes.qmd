# Lakes  {#sec-db-lakes .unnumbered}


## Misc  {#sec-db-lakes-misc .unnumbered}

-   Data is stored in structured format or in its raw native format without any transformation at any scale.

    -   Handling both types allows all data to be centralized which means it can be better organized and more easily accessed.

-   Optimal for fit for bulk data types such as server logs, clickstreams, social media, or sensor data.

-   lower storage costs due to their more open-source nature and undefined structure

-   Hadoop

    -   traditional format for data lakes

-   Object Storage Systems

    -   Examples
        -   Amazon S3
        -   Microsoft Azure Data Lake Storage (ADLS)
    -   cloud data lakes provide organizations with additional opportunities to simplify data management by being accessible everywhere to all applications as needed
    -   organized as collections of files within directory structures, often with multiple files in one directory representing a single table.
        -   Pros: highly accessible and flexible
        -   Metadata Catalogs are used to answer these questions:
            -   What is the schema of a dataset, including columns and data types
            -   Which files comprise the dataset and how are they organized (e.g., partitions)
            -   How different applications coordinate changes to the dataset, including both changes to the definition of the dataset and changes to data
        -   Hive Metastore (HMS) and AWS Glue Data Catalog are two popular catalog options
            -   contain the schema, table structure and data location for datasets within data lake storage
    -   Issues:
        -   does not coordinate data changes or schema evolution between applications in a transactionally consistent manner.
            -   Creates the necessity for data staging areas and this extra layer makes project pipelines brittle

-   Apache Iceberg

    -   open source table format
    -   Features
        -   Transactional consistency between multiple applications where files can be added, removed or modified atomically, with full read isolation and multiple concurrent writes
        -   Full schema evolution to track changes to a table over time
        -   Time travel to query historical data and verify changes between updates
        -   Partition layout and evolution enabling updates to partition schemes as queries and data volumes change without relying on hidden partitions or physical directories
        -   Rollback to prior versions to quickly correct issues and return tables to a known good state
        -   Advanced planning and filtering capabilities for high performance on large data volumes
        -   the full history is maintained within the Iceberg table format and without storage system dependencies
    -   supports common industry-standard file formats, including Parquet, ORC and Avro
    -   supported by major data lake engines including Dremio, Spark, Hive and Presto

-   Comparison\
    ![](./_resources/DB,_Engineering.resources/Screenshot%20(487).png)
