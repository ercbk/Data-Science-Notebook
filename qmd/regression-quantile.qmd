# Quantile {#sec-reg-quant .unnumbered}

## Misc {#sec-reg-quant-misc .unnumbered}

-   Resources

    -   Handbook of Quantile Regression - Koenker ([{quantreg}]{style="color: #990000"} book) (see R \>\> Documents \>\> Regression)

-   Packages

    -   [{]{style="color: #990000"}[quantregRanger](https://cran.r-project.org/web/packages/quantregRanger/quantregRanger.pdf){style="color: #990000"}[}]{style="color: #990000"} - uses Ranger to fit quantile RFs
        -   In [{tidymodels}]{style="color: #990000"}, `quantreg = TRUE` tells ranger that you're estimating quantiles rather than averages. Also `predict(airquality, type = 'quantiles')`
    -   [{]{style="color: #990000"}[grf](https://grf-labs.github.io/grf/reference/quantile_forest.html){style="color: #990000"}[}]{style="color: #990000"} - generalized random forest
    -   [{]{style="color: #990000"}[quantreg](https://cran.r-project.org/web/packages/quantreg/index.html){style="color: #990000"}[}]{style="color: #990000"} - Estimation and inference methods for models for conditional quantile functions: Linear and nonlinear parametric and non-parametric (total variation penalized) models for conditional quantiles of a univariate response.
    -   [{]{style="color: #990000"}[partykit](https://cran.r-project.org/web/packages/partykit/index.html){style="color: #990000"}[}]{style="color: #990000"} - conditional inference trees; model-based recursive partitioning trees
        -   [{]{style="color: #990000"}[bonsai](https://bonsai.tidymodels.org/){style="color: #990000"}[}]{style="color: #990000"}: tidymodels partykit conditional trees, forests; successor to treesnip - Model Wrappers for Tree-Based Models
    -   [{{]{style="color: goldenrod"}[quantile-forest](https://github.com/zillow/quantile-forest){style="color: goldenrod"}[}}]{style="color: goldenrod"} - Zillow's sklearn compatible quantile forest
    -   [{{]{style="color: goldenrod"}[skgarden](https://scikit-garden.github.io/examples/QuantileRegressionForests/){style="color: goldenrod"}[}}]{style="color: goldenrod"} - Extension for sklearn tree and forest models. Produces online training models called Mondrian Forests ([paper](https://arxiv.org/abs/1406.2673)). Has a quantile random forest flavor.

-   For quantiles \> 0.80, see quantile models in [Extreme Value Theory (EVT)](extreme-value-theory-(evt).qmd#sec-evt){style="color: green"})

-   [Harrell](http://hbiostat.org/bbr/nonpar.html#sec-nonpar-ecdf): To characterize an entire distribution or in other words, have a "high degree of confidence that no estimated quantile will be off by more than a probability of 0.01, n = 18,400 will achieve this.

    -   For example with n = 18,400, the sample 0.25 quantile (first quartile) may correspond to population quantiles 0.24-0.26.

    -   To achieve a \$\pm\$0.1 MOE requires n = 180, and to have \$\pm\$0.05 requires n = 730 (see table)

        ``` r
               n   MOE
        1     20 0.294
        2     50 0.188
        3    100 0.134
        4    180 0.100
        5    250 0.085
        6    500 0.060
        7    730 0.050
        8    750 0.049
        9   1000 0.043
        10  2935 0.025
        11  5000 0.019
        12 10000 0.014
        13 18400 0.010
        ```

-   Harrell has a pretty cool text effect to display quantile values in his {HMisc::describe} that uses [{gt}]{style="color: #990000"} under the hood (See [EDA \>\> Packages](eda-general.qmd#sec-eda-gen-pkgs){style="color: green"} \>\> HMisc)

    ![](./_resources/Regression,_Quantile.resources/Screenshot%20(1434).png){width="532"}

    -   Histogram is a sparkline

## Diagnostics {#sec-reg-quant-diag .unnumbered}

-   Mean Integrated Squared Error (MISE)
