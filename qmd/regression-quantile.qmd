# Quantile {#sec-reg-quant .unnumbered}

## Misc {#sec-reg-quant-misc .unnumbered}

-   Resources

    -   Handbook of Quantile Regression - Koenker ([{quantreg}]{style="color: #990000"} book) (see R \>\> Documents \>\> Regression)

-   Packages

    -   [{]{style="color: #990000"}[quantregRanger](https://cran.r-project.org/web/packages/quantregRanger/quantregRanger.pdf){style="color: #990000"}[}]{style="color: #990000"} - uses Ranger to fit quantile RFs
        -   In [{tidymodels}]{style="color: #990000"}, `quantreg = TRUE` tells ranger that you're estimating quantiles rather than averages. Also `predict(airquality, type = 'quantiles')`
    -   [{]{style="color: #990000"}[grf](https://grf-labs.github.io/grf/reference/quantile_forest.html){style="color: #990000"}[}]{style="color: #990000"} - generalized random forest
    -   [{]{style="color: #990000"}[quantreg](https://cran.r-project.org/web/packages/quantreg/index.html){style="color: #990000"}[}]{style="color: #990000"} - Estimation and inference methods for models for conditional quantile functions: Linear and nonlinear parametric and non-parametric (total variation penalized) models for conditional quantiles of a univariate response.
    -   [{]{style="color: #990000"}[partykit](https://cran.r-project.org/web/packages/partykit/index.html){style="color: #990000"}[}]{style="color: #990000"} - conditional inference trees; model-based recursive partitioning trees
        -   [{]{style="color: #990000"}[bonsai](https://bonsai.tidymodels.org/){style="color: #990000"}[}]{style="color: #990000"}: tidymodels partykit conditional trees, forests; successor to treesnip - Model Wrappers for Tree-Based Models
    -   [{{]{style="color: goldenrod"}[quantile-forest](https://github.com/zillow/quantile-forest){style="color: goldenrod"}[}}]{style="color: goldenrod"} - Zillow's sklearn compatible quantile forest. Compared to other python implementations, optimized for training and inference speed, enabling it to scale to millions of samples with a runtime that is orders of magnitude faster than less-optimized solutions. It also allows specifying prediction quantiles after training, permitting a trained model to be reused to estimate conditional quantiles as needed.
        -   Out-of-Bag Scoring: OOB scoring can be used to obtain unbiased estimates of prediction errors and quantile-specific metrics without the need for additional validation datasets.
        -   Quantile Rank Calculation: Provide a measure of relative standing for each data point in the distribution. Allows you to compare and rank observations based on their position within the quantile distribution, providing valuable insights for various applications, such as risk assessment and anomaly detection.
        -   Proximity and Similarity Estimation: Quantifies the similarity between pairs of observations based on their paths through the forest. Useful for clustering, anomaly detection, and identifying influential observations.
    -   [{{]{style="color: goldenrod"}[skgarden](https://scikit-garden.github.io/examples/QuantileRegressionForests/){style="color: goldenrod"}[}}]{style="color: goldenrod"} - Extension for sklearn tree and forest models. Produces online training models called Mondrian Forests ([paper](https://arxiv.org/abs/1406.2673)). Has a quantile random forest flavor.

-   For quantiles \> 0.80, see quantile models in [Extreme Value Theory (EVT)](extreme-value-theory-(evt).qmd#sec-evt){style="color: green"})

-   [Harrell](http://hbiostat.org/bbr/nonpar.html#sec-nonpar-ecdf): To characterize an entire distribution or in other words, have a "high degree of confidence that no estimated quantile will be off by more than a probability of 0.01, n = 18,400 will achieve this.

    -   For example with n = 18,400, the sample 0.25 quantile (first quartile) may correspond to population quantiles 0.24-0.26.

    -   To achieve a \$\pm\$0.1 MOE requires n = 180, and to have \$\pm\$0.05 requires n = 730 (see table)

        ``` r
               n   MOE
        1     20 0.294
        2     50 0.188
        3    100 0.134
        4    180 0.100
        5    250 0.085
        6    500 0.060
        7    730 0.050
        8    750 0.049
        9   1000 0.043
        10  2935 0.025
        11  5000 0.019
        12 10000 0.014
        13 18400 0.010
        ```

-   Harrell has a pretty cool text effect to display quantile values in his {HMisc::describe} that uses [{gt}]{style="color: #990000"} under the hood (See [EDA \>\> Packages](eda-general.qmd#sec-eda-gen-pkgs){style="color: green"} \>\> HMisc)

    ![](./_resources/Regression,_Quantile.resources/Screenshot%20(1434).png){.lightbox width="532"}

    -   Histogram is a sparkline

## Diagnostics {#sec-reg-quant-diag .unnumbered}

-   Mean Integrated Squared Error (MISE)
