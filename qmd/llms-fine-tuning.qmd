# Fine Tuning {#sec-nlp-fintun .unnumbered}

## Misc {#sec-nlp-fintun-misc .unnumbered}

-   Papers

    -   [The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities](https://arxiv.org/abs/2408.13296)

-   Resources

    -   [minhub](https://github.com/mlverse/minhub) - A collection of minimal implementations of deep learning models inspired by minGPT. Each model is designed to be self-contained in a single file with no external dependencies, making them easy to copy and integrate into your own projects.

        -   These models are particularly suitable for educational purposes, experimentation, and as a starting point for more complex implementations
        -   Supports loading weights from pre-trained models available in the Hugging Face model hub
        -   These seem like candidates as base models for fine tuning

-   [Tuning an LLM]{.underline}

    -   Notes from:
        -   [Hacker's Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU) (Howard)
    -   Stages
        -   **LM Pre-Training** - Trained on a large corpus (e.g. much of the internet) to predict the next word in a sentence or to fill in a word in a sentence
        -   **LM Fine-Tuning** - Trained on a specific task (e.g. solve problems, answer questions). Instruction Tuning is often used. OpenOrca is an example of a Q&A dataset to train a LM to answer questions. Still predicting the next word, like in Pre-Training, but more target-based on a specific task.
        -   **Classifier Fine-Tuning** - Reinforcement Learning from Human Feedback (RLHF)is often used. The LLM being trained gives a few answers to a question and then a human or better LLM will pick which one is best.
    -   Pre-Trained LLMs are ones that are typically the open source ones being released and available for download
        -   They will need to be Fine-Tuned, but not necessarily Classifier Fine-Tuned. Often times, LM Fine-Tuning is enough.

-   Workflow Example ([paper](https://huyenchip.com/2023/04/11/llm-engineering.html))\
    ![](./_resources/NLP,_Fine_Tuning.resources/image.png){.lightbox width="532"}

-   [Raschka - An introduction to the core ideas and approaches to Finetuning Large Language Models - by Sebastian Raschka](https://magazine.sebastianraschka.com/p/finetuning-large-language-models?utm_source=post-email-title&publication_id=1174659&post_id=115943216&isFreemail=true&utm_medium=email)

-   With ChatGPT, you can have it answer questions from context that contains thousands of documents.\
    ![](./_resources/NLP,_Fine_Tuning.resources/image.1.png){.lightbox width="532"}

    -   Store all these documents as small chunks of text (allowable size of the context window) in a database.
    -   Create embeddings of documents and question
    -   The documents of relevance can then be found by computing similarities between the question and the document chunks. This is done typically by converting the chunks and question into word embedding vectors, and computing cosine similarities between chunks and question, and finally choosing only those chunks above a certain cosine similarity as relevant context.
    -   Finally, the question and context can be combined into a prompt as below, and fed into an LLM API like ChatGPT: `prompt=f"Answer the question. Context: {context}\n Question: {question}"`
