# Decomposition {#sec-decomp .unnumbered}

## Misc {#sec-decomp-misc .unnumbered}

-   Also see [EDA, Time Series \>\> Seasonality](eda-time-series.qmd#sec-eda-ts-seas){style="color: green"}
    -   Presents details about Daily Seasonal Adjustment (DSA)
-   Packages
    -   [{]{style="color: #990000"}[dsp](https://github.com/drkowal/dsp/tree/master){style="color: #990000"}[}]{style="color: #990000"} ([paper](https://academic.oup.com/jrsssb/article/81/4/781/7048377?login=false#396338018)) - MCMC implementation for Bayesian trend filtering (BTF) with dynamic horseshoe processes as the prior (penalty)
        -   Dynamic Shrinkage Processes (DSPs) extend popular global-local shrinkage priors, such as the horseshoe prior for sparse signals, to the time series setting by allowing the shrinkage behavior to depend on the history of the shrinkage process.
        -   DSPs are used as the prior on the 1st/2nd differences, which produces curve estimates and credible bands that are highly adaptive to both rapidly- and slowly-changing features
        -   Implementations for the (static) horseshoe (HS) prior and a Normal-Inverse-Gamma (NIG) prior
    -   [{]{style="color: #990000"}[genlasso](https://cran.r-project.org/web/packages/genlasso/index.html){style="color: #990000"}[}]{style="color: #990000"} - Trend filtering of any given polynomial order
    -   [{]{style="color: #990000"}[jumps](https://cran.r-project.org/web/packages/jumps/index.html){style="color: #990000"}[}]{style="color: #990000"} - Hodrick-Prescott Filter with Jumps
        -   The original HP filter extracts a smooth trend from a time series, and our version allows for a small number of automatically identified jumps (i.e. changepoints).
    -   [{]{style="color: #990000"}[SSAforecast](https://cran.r-project.org/web/packages/SSAforecast/index.html){style="color: #990000"}[}]{style="color: #990000"} - Singular spectrum analysis (SSA) decomposes a time series into interpretable components like trends, oscillations, and noise without strict distributional and structural assumptions.
    -   [{]{style="color: #990000"}[TrendLSW](https://cran.r-project.org/web/packages/TrendLSW/index.html){style="color: #990000"}[}]{style="color: #990000"} ([Vignette](https://arxiv.org/abs/2406.05012)) - Wavelet Methods for Analyzing Nonstationary Time Series
        -   Allows users to simulate time series with first and second order nonstationarity, as well as estimate relevant quantities of interest, such as the trend and wavelet spectrum associated to time series. (i.e. smoothing for trends and spectral estimation)
        -   Notes from on the vignette and wavelets, in general, are in `scrapsheet.qmd` in the repo.
-   There are two approaches to noise reduction: filtering algorithms and smoothing algorithms. In filtering algorithms, signal points are fed sequentially, therefore only the current and the previous points are used to get rid of noise at the current point. Smoothing algorithms assume that the entire signal has been received, and all signal points, both previous and subsequent, are used to get rid of noise at the current point.
-   Low Pass FIlter
    -   Dampens higher frequencies in the data and allows lower frequencies to "pass" through.

        ![](_resources/forecasting-decomposition.resources/low-pass-filter-1.png){.lightbox width="432"}

        -   A smoother version of the original data
-   High Pass FIlter
    -   Dampens low frequencies and allows high frequencies to pass

        ![](_resources/forecasting-decomposition.resources/high-pass-filter-1.png){.lightbox width="432"}

        -   Looks like a series of residuals with the trend removed
-   Matching Filter
    -   Original series with extreme changepoints

        ![](_resources/forecasting-decomposition.resources/matching-filter-raw-1.png){.lightbox width="432"}

    -   Matching filter indicates the changepoints with peaks in the filtered series

        ![](_resources/forecasting-decomposition.resources/matching-filter-1.png){.lightbox width="432"}

## Seasonal Adjusted Forecasting {#sec-decomp-saf .unnumbered}

-   The seasonality is extracted from the time series using STL. The extracted seasonal time series and the seasonally adjusted time series are forecast separately. Both forecasts are then added back together to produce the final forecast.

    -   A seasonal naive method is commonly used to forecast the seasonal component.
    -   Not sure how you would combine the uncertainty (i.e PIs)

-   Packages

    -   [{]{style="color: #990000"}[seasonal](https://github.com/christophsax/seasonal){style="color: #990000"}[}]{style="color: #990000"} - Full-featured R-interface to X-13ARIMA-SEATS, the newest seasonal adjustment software developed by the United States Census Bureau.

    -   [{]{style="color: #990000"}[feasts::X_13ARIMA_SEAT](https://feasts.tidyverts.org/reference/X_13ARIMA_SEATS.html){style="color: #990000"}[}]{style="color: #990000"}

-   [Example]{.ribbon-highlight}

    ``` python
    from statsmodels.tsa.api import STL
    from sktime.forecasting.naive import NaiveForecaster

    # fitting the seasonal decomposition method
    series_decomp = STL(yt, period=period).fit()

    # adjusting the data
    seas_adj = yt - series_decomp.seasonal

    # forecasting the non-seasonal part
    forecaster = make_reduction(estimator=RidgeCV(),
                                strategy='recursive',
                                window_length=3)

    forecaster.fit(seas_adj)

    seas_adj_pred = forecaster.predict(fh=list(range(1, 13)))

    # forecasting the seasonal part
    seas_forecaster = NaiveForecaster(strategy='last', sp=12)
    seas_forecaster.fit(series_decomp.seasonal)
    seas_preds = seas_forecaster.predict(fh=list(range(1, 13)))

    # combining the forecasts
    preds = seas_adj_pred + seas_preds
    ```

## Seasonal Trend Decomposition using LOESS (STL) {#sec-decomp-stl .unnumbered}

-   Packages
    -   [{]{style="color: #990000"}[feasts::STL](https://feasts.tidyverts.org/reference/STL.html){style="color: #990000"}[}]{style="color: #990000"}
-   Time series get decomposed into trend-cycle (T), seasonal (S), and remainder (R) components
    -   Yt = Tt + St + Rt, where t = 1,2,...,N
-   LOESS smoothes a time series by:
    -   Weights are applied to the neighborhood of each point which depend on the distance from the point
    -   A polynomial regression is fit at each data point with points in the neighborhood as explanatory variables
-   Components are additive
-   Entails two recursive procedures: inner loop and outer loop
    -   Each iteration updates the trend-cycle and seasonal components
    -   Inner Loop is iterated until there's a robust estimate of the trend and seasonal component
    -   The outer loop is only iterated if outliers exist among the data points
    -   Inner Loop Procedure
        1.  Detrending
            -   Initially occurs by subtracting an initial trend component (?) from the original series
        2.  Subseries smoothing
            -   12 monthly subseries are separated and collected
            -   Each is smoothed with LOESS
            -   Re-combined to create the initial seasonal component
        3.  Low-Pass filtering of smoothed seasonal component
            -   Seasonal component passed through a 3x12x12 moving average.
            -   Result is again smoothed by LOESS (length = 13) in order to detect any trend-cycle in it.
        4.  Detrending of smoothed subseries
            -   Result of low-pass filtering is subtracted from seasonal component in step 2 to get the final seasonal component
        5.  De-seasonalization
            -   Final seasonal component is subtracted from the original series
        6.  Trend smoothing
            -   LOESS is applied to deseasonalized series to get the final trend component
    -   Outer Loop procedure
        -   Final trend and seasonal components are subtracted from the original series to get the remainder/residual series
        -   The final trend and seasonal components are tested for outlier points
        -   A weight is calculated and used in the next iteration of the Inner Loop to down-weight the outlier points.
