# Relational {#sec-db-rel .unnumbered}

## Misc {#sec-db-rel-misc .unnumbered}

-   Also see [SQL \>\> R](sql.qmd#sec-sql-r){style="color: green"}

-   Packages

    -   [{]{style="color: #990000"}[dbplyr](https://dbplyr.tidyverse.org/){style="color: #990000"}[}]{style="color: #990000"}
        -   `compute` stores results in a remote temporary table
        -   `collect` retrieves data into a local tibble.
        -   `collapse` doesn't force computation, but instead forces generation of the SQL query.
            -   sometimes needed to work around bugs in dplyr's SQL generation.
    -   [{]{style="color: #990000"}[dm](https://cynkra.github.io/dm/){style="color: #990000"}[}]{style="color: #990000"}
        -   Can join multiple tables from a db, but keeps the meta info such as table names, primary and foreign keys, size of original tables etc.
    -   [{]{style="color: #990000"}[dbx](https://github.com/ankane/dbx){style="color: #990000"}[}]{style="color: #990000"} - Convenience functions for insert, update, upsert, and delete
        -   Easy parameterization
        -   High performance batch operations
        -   Date and time support
        -   Works well with auto-incrementing primary keys
        -   Connection Pooling
        -   Connects with DBI, so can also use with [{dbplyr}]{style="color: #990000"}
        -   Supports Postgres, MySQL, MariaDB, SQLite, SQL Server, and more

-   Tools

    -   [whodb](https://github.com/clidey/whodb) - A lightweight next-gen data explorer - Postgres, MySQL, SQLite, MongoDB, Redis, MariaDB, Elastic Search, and Clickhouse with Chat interface

-   Relational databases do not keep all data together but split it into multiple smaller tables. That separation into sub-tables has several advantages:

    -   All information is stored only once, avoiding repetition and conserving memory
    -   All information is updated only once and in one place, improving consistency and avoiding errors that may result from updating the same value in multiple locations
    -   All information is organized by topic and segmented into smaller tables that are easier to handle

-   Optimized for a mix of read and write queries that insert/select a small number of rows at a time and can handle up to 1TB of data reasonably well.

-   The main difference between a "relational database" and a "data warehouse" is that the former is created and optimized to "record" data, whilst the latter is created and built to "react to analytics".

-   Types

    -   Embedded aka In-Process (see [Databases, Engineering \>\> Terms](db-engineering.qmd#sec-db-eng-terms){style="color: green"}): DuckDB (analytics) and SQLite (transactional)
    -   Server-based: postgres, mysql, SQL Server
        -   Mix of transactional and analytical
        -   Distributed SQL (database replicants across regions or hybrid (on-prem + cloud)
            -   mysql, postgres available for both in AWS Aurora (See below)
            -   postgres available using [yugabytedb](https://www.yugabyte.com/)
            -   SQL Server on Azure SQL Database
            -   Cloud Spanner on GCP

-   Apache Avro

    -   Row storage file format unlike parquet
    -   A single Avro file contains a JSON-like schema for data types and the data itself in binary format
    -   4x *slower* reading than csv but 1.5x *faster* writing than csv
    -   1.7x *smaller* file size than csv

-   Wrapper for db connections (e.g. `con_depA <- connect_databaseA(username = ..., password = ...)` )

    ``` r
    # ... other stuff including code for "connect_odbc" function

    # connection attempt loop
    while(try < retries) {
        con <- connect_odbc(source_db = "<database name>"
                            username = username,
                            password = password)
        if(class(con) == "NetexxaSQL") {
            try <- retries + 1
        } else if (!"NetezzaSQL" %in% class(con) & try < retries {
            warning("<database name> connection failed. Retrying...")
            try <- try + 1
            Sys.sleep(retry_wait)
        } else {
            try <- try + 1
            warning("<database name> connection failed")
        }
    }
    ```

    -   Guessing "NetezzaSQL" is some kind of error code for a failed connection to the db

## Comparisons {#sec-db-rel-comp .unnumbered}

-   SQLite vs DuckDB

    -   SQLite
        -   Row data storage
        -   Good for transactional processing
        -   Each row represented in a table is stored as an array on disk
        -   Easy to update individual rows
    -   DuckDB
        -   Columnar data storage
        -   Good for analytics
        -   Each column is stored as a chunked array on disk and in memory
            -   Memory locality

            -   Column compression
        -   Faster queries for reading

-   SQLite vs MySQL as transactional dbs ([article](https://towardsdatascience.com/mysql-vs-sqlite-ba40997d88c5))

    -   SQLite:
        -   Embedded, size \~600KB
        -   Limited data types
        -   Being self-contained, other clients on a network would not have access to the database (no multi-users) unlike with MySQL
        -   No built-in authentication that is supported
        -   Multiple processes are able to access the database at the same time, but making changes at the same time is not something supported
        -   Use Cases
            -   Data being confined in the files of the device is not a problem
            -   Network access to the db is not needed
            -   Applications that will minimally access the database and not require heavy calculations
    -   MySQL:
        -   Opposites of the sqlite stuff
        -   Size \~600MB
        -   Supports replication and scalability
        -   Security is a large; built-in features to keep unwanted people from easily accessing data
        -   Use cases
            -   Transactions are more frequent like on web or desktop applications
            -   If network capabilities are a must
            -   Multi-User access and therefore security and authentication
            -   Large amounts of data

-   Benchmarks

    -   Example
        -   Data

            -   \~54,000,000 rows and 6 columns
            -   10 .rds files with gz compression is 220MB total,
                -   If they were .csv, 1.5 GB
            -   SQLite file is 3 GB
            -   DuckDB file is 2.5 GB
            -   Arrow creates a structure of directories, 477 MB total

        -   Operation: read, filter, group_by, summarize

        -   Results

            ```         
            ##  format          median_time mem_alloc
            ##  <chr>              <bch:tm> <bch:byt>
            ## 1 R (RDS)              1.34m    4.08GB
            ## 2 SQL (SQLite)          5.48s    6.17MB
            ## 3 SQL (DuckDB)          1.76s  104.66KB
            ## 4 Arrow (Parquet)      1.36s  453.89MB
            ```
    -   Tradional relational db solutions balloon up the file size
        -   SQLite 2x, DuckDB 1.66x (using csv size)
    -   [ClickBench — a Benchmark For Analytical DBMS](https://benchmark.clickhouse.com/)

## Brands {#sec-db-rel-brands .unnumbered}

-   MySQL

    -   Installation [docs](https://dev.mysql.com/doc/mysql-getting-started/en/)
    -   Basic [intro](https://towardsdatascience.com/an-introduction-to-sql-4c9eb27995df)
    -   See SQL notebook

-   SQLite

    -   Packages
        -   [{RSQLite}]{style="color: #990000"}
    -   Resources
        -   [The Querynomicon](https://lessonomicon.github.io/querynomicon/)
        -   [Everyone Is Wrong About SQLite](https://dev.to/shayy/everyone-is-wrong-about-sqlite-4gjf)
            -   Overview of features and issues.
    -   Tools
        -   datasette.io: See [Big Data \>\> Larger Than Memory \>\> Programs](#sec-db-rel){style="color: green"}
        -   [sqlime](https://github.com/nalgeon/sqlime): Online SQLite playground
        -   [SQL Studio](https://github.com/frectonz/sql-studio) - Explorer with dashboard-like UI
            -   SQL Database Explorer \[SQLite, libSQL, PostgreSQL, MySQL/MariaDB, DuckDB, ClickHouse\]
            -   Overview page with common metadata.
            -   Tables page with each table's metadata, including the disk size being used by each table.
            -   Infinite scroll rows view.
            -   A custom query page that gives you more access to your db.
        -   [SQLite Browser](https://sqlitebrowser.org/)
            -   DB browser with spreadsheet-like interface that's designed for people who want to create, search, and edit SQLite database files
            -   All OSs supported
        -   [litecli](https://github.com/dbcli/litecli) - CLI tool for SQLite databases that has auto-completion and syntax highlighting
        -   [Litestream](https://litestream.io/) - Enables streaming backups
        -   [LiteFS](#0) - Provides distributed access
        -   [CR-SQLite](https://github.com/vlcn-io/cr-sqlite) - Allows the use of CRDTs to avoid needing conflict resolution when merging changesets
            -   CRDT ([wiki](https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type)) - In distributed computing, a conflict-free replicated data type (CRDT) is a data structure that is replicated across multiple computers in a network, with the following features:
                1.  The application can update any replica independently, concurrently and without coordinating with other replicas.
                2.  An algorithm (itself part of the data type) automatically resolves any inconsistencies that might occur.
                3.  Although replicas may have different state at any particular point in time, they are guaranteed to eventually converge.
    -   Extensions
        -   [sqlite-vec](https://github.com/asg017/sqlite-vec) ([intro](https://alexgarcia.xyz/blog/2024/sqlite-vec-stable-release/index.html)) - A vector similarity search extension written entirely in C with no dependencies
        -   [sqlite-rembed](https://github.com/asg017/sqlite-rembed): A SQLite extension for generating text embeddings from remote APIs (OpenAI, Nomic, Ollama, llamafile...)

-   [Cloud SQL](https://cloud.google.com/sql/docs/introduction) - Google service to provide hosting services for relational dbs (see [Databases, BigQuery \>\> Misc](db-bigquery.qmd#sec-db-bigq-misc){style="color: green"}). Can use postgres, mysql, etc. on their machines.

    -   [Cloud SQL Insights](https://cloud.google.com/blog/products/databases/get-ahead-of-database-performance-issues-with-cloud-sql-insights) - good query optimization tool

-   [AWS RDS](https://aws.amazon.com/rds/) for db instances (see [Database, postgres \>\> AWS RDS](db-postgres.qmd#sec-db-pstgr-rds){style="color: green"})

    -   Available: Amazon Aurora, MySQL, MariaDB, postgres, Oracle, Microsoft SQL Server
    -   RDS (Relational Database Service)
        -   Benefits over hosting db on EC2: AWS handles scaling, availability, backups, and software and operating system updates

-   [AWS Aurora](http://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_Aurora.html) - MySQL- and PostgreSQL-compatible enterprise-class database

    -   Starting at \<\$1/day.
    -   Supports up to 64TB of auto-scaling storage capacity, 6-way replication across three availability zones, and 15 low-latency read replicas.
    -   [Create MySQL and Postgres instances using AWS Cloudformation](https://towardsdatascience.com/create-mysql-and-postgres-instances-using-aws-cloudformation-d3af3c46c22a)
