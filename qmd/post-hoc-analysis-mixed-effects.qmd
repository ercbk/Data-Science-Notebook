# Mixed Effects {#sec-phoc-mixeff .unnumbered}

## Misc {#sec-phoc-mixeff-misc .unnumbered}

-   Also see [Post-Hoc Analysis, general](post-hoc-analysis-general.qmd#sec-phoc-gen){style="color: green"}

## Tukey Test {#sec-phoc-mixeff-tukey .unnumbered}

-   Difference in effects

-   [Example]{.ribbon-highlight}: Is there a statistically significant difference between the estimated effects of the categories of the fixed effect, "Season" Data from [Multilevel Modeling and Effects Statistics for Sports Scientists in R](https://ryan-curtis.netlify.app/post/multilevel-modeling-and-effects-statistics-for-sports-scientists-in-r/)

    ::: panel-tabset
    ## [{multcomp}]{style="color: #990000"}

    ``` r
    library(multcomp)
    # pairwise comparisons
    fit_tukey <- glht(fit, linfct=mcp(Season="Tukey"))
    summary(fit_tukey)
    ## 
    ## Simultaneous Tests for General Linear Hypotheses
    ## 
    ## Multiple Comparisons of Means: Tukey Contrasts
    ## 
    ## 
    ## Fit: lmer(formula = Distance ~ Season + (1 | Athlete), data = data)
    ## 
    ## Linear Hypotheses:
    ##                            Estimate Std.  Error z value Pr(>|z|)   
    ## Postseason - Inseason == 0        36.71   90.08   0.408    0.911   
    ## Preseason - Inseason == 0       1166.00   90.08  12.944   <1e-05 ***
    ## Preseason - Postseason == 0     1129.29  110.32  10.236   <1e-05 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## (Adjusted p values reported -- single-step method)
    ```

    ## [{emmeans}]{style="color: #990000"}

    ``` r
    emmeans(fit, specs = pairwise ~ Season)
    ## $emmeans
    ##  Season    emmean  SE   df lower.CL upper.CL
    ##  Inseason    5104 137 20.8     4818    5389
    ##  Postseason  5140 151 30.6     4831    5449
    ##  Preseason   6270 151 30.6     5961    6579
    ## Degrees-of-freedom method: kenward-roger 
    ## Confidence level used: 0.95 
    ## $contrasts
    ##  contrast               estimate    SE  df t.ratio p.value
    ##  Inseason - Postseason     -36.7  90.1 978  -0.408 0.9125 
    ##  Inseason - Preseason    -1166.0  90.1 978 -12.944 <.0001 
    ##  Postseason - Preseason  -1129.3 110.3 978 -10.236 <.0001 
    Degrees-of-freedom method: kenward-roger 
    P value adjustment: tukey method for comparing a family of 3 estimates
    ```
    :::

    -   Interpretation
        -   There is NOT a difference between the effect that Postseason has on Distance and the effect that Inseason has on Distance.
        -   There is a difference with between the other two pairs of categores
        -   Estimated mean distance given season type
            -   I'm not sure these estimates are appropriate in this situation since the Season variable is inherently unbalanced.
            -   Also see emmeans [Post-Hoc Analysis, emmeans](post-hoc-analysis-emmeans.qmd#sec-phoc-emmeans){style="color: green"}

## Cohen's D {#sec-phoc-mixeff-cohensd .unnumbered}

-   Standardized difference in means given a grouping variable

-   [Generally recommended to use $g_{\text{rm}}$ or $g_{\text{av}}$]{.underline}

    -   Standard practice is use whichever one is closer to $d_s$ , because it helps make the result comparable with between-subject studies.

    -   Appropriate Version Per Use Case

        | Use                                                                                                          | Version          |
        |--------------------------------------------------------------------------------------------------------------|------------------|
        | Independent groups, power analyses where $\sigma_\text{pop}$ is known or $\sigma$ is calculated with $n$     | $d_{\text{pop}}$ |
        | Independent groups, power analyses where $\sigma_\text{pop}$ is unknown or $\sigma$ is calculated with $n-1$ | $d_s$            |
        | Independent groups, corrects for small sample bias; report for use in meta-analyses                          | $g$              |
        | Independent groups, when treatment might affect SD                                                           | $\Delta$         |
        | Correlated groups; generally recommended over $g_{\text{rm}}$                                                | $g_{\text{av}}$  |
        | Correlated groups; more conservative than $g_{\text{av}}$                                                    | $g_{\text{rm}}$  |
        | Correlated groups; power analyses                                                                            | $d_z$            |

-   Notes from: [Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs](https://pure.tue.nl/ws/files/3835042/1236489301722996.pdf) (Lakens)

-   Can be used to compare effects across studies, even when the dependent variables are measured in different ways

    -   [Examples]{.ribbon-highlight}

        -   When one study uses 7-point scales to measure dependent variables, while the other study uses 9-point scales

        -   When completely different measures are used, such as when one study uses self-report measures, and another study used physiological measurements.

-   The bias-corrected version is known as **Hedges' g**, and in the r family of effect sizes, the correction for eta squared (η2) is known as omega squared (ω2)

-   Guidelines

    -   Range: 0 to $\infty$

    -   Cohen (1992)

        -   \|d\| \< 0.2 "negligible"
        -   \|d\| \< 0.5 "small"
        -   \|d\| \< 0.8 "medium"
        -   otherwise "large"

    -   Others: [Automated Interpretation of Indices of Effect Size](https://easystats.github.io/effectsize/articles/interpret.html)

    -   Values should not be interpreted rigidly

        -   e.g. Small effect sizes can have large consequences, such as an intervention that leads to a reliable reduction in suicide rates with an effect size of d = 0.1.

    -   The only reason to use these benchmarks is when the findings are extremely novel, and cannot be compared to related findings in the literature.

-   [Two groups of Independent Observations (Between-Subjects)]{.underline}

    $$
    \begin{align}
    d_s &= \frac{\bar X_1 - \bar X_2}{\sqrt{\frac{(n_1-1)SD^2_1 + (n_2-1)SD^2_2}{n_1 + n_2 - 2}}}\\
    &= t\;\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\\
    & \approx \frac{2t}{\sqrt{N}}
    \end{align}
    $$

    -   Where the denominator is the pooled standard deviation

    -   $t$ is the t-value of two-sample t-test

    -   Typically used in an a priori power analysis for between-subjects designs

    -   **Hedges' g** (bias-corrected)

        $$
        g_s = d_s \times \left(1-\frac{3}{4(n_1 + n_2) - 9}\right)
        $$

        -   I think the same correction is used for all types of Cohen's d
        -   The difference between Hedges's g~s~ and Cohen's d~s~ is very small, especially in sample sizes above 20

    -   Interpretation: A percentage of the standard deviation. Best to relate it to other effect sizes in the literature and it's practical consequences if possible.

        -   e.g. $d_s = 0.5$ says the difference in means is half a standard deviation.

    -   Whenever standard deviations differ substantially between groups, Glass's $\Delta$ should also be reported

-   [One Sample or Correlated Samples (Within-Subjects)]{.underline}

    $$
    \begin{align}
    d_z &= \frac{M_{\text{diff}}}{\sqrt{\frac{\sum(X_{\text{diff}} - M_{\text{diff}})^2}{N-1}}}\\
    &= \frac{t}{\sqrt{n}}
    \end{align}
    $$

    -   $M_{\text{diff}}$ is the difference between the mean (M) of the difference scores and the comparison value, $\mu$ (e.g. 0)

    -   $X_{\text{diff}}$ are the difference scores (i.e. the difference between the repeated measurements)

    -   Therefore, the demominator is the SD of the difference scores

    -   $t$ is the t-value of a paired samples t-test

-   [Repeated Measures (Within-Subjects)]{.underline}

    $$
    d_{\text{rm}} = \frac{M_{\text{diff}}\cdot \sqrt{2(1-r)}}{\sqrt{\text{SD}_1^2 + \text{SD}_2^2 - (2\cdot r\cdot \text{SD}_1 \cdot \text{SD}_2)}}
    $$

    -   $r$ is the correlation between measurements

    -   Alternative

        $$
        d_{\text{av}} = \frac{M_{\text{diff}}}{\frac{\text{SD}_1 + \text{SD}_2}{2}}
        $$

        -   Ignores the correlation between measures

    -   If it is believe that the intervention/treatment affected the SD after the intervention, then it is advised to only use either (pre-treatment) $\text{SD}_1$ (recommended) or (post-treatment) $\text{SD}_2$ and report which one is used. The calculated effect is then known as **Glass's** $\boldsymbol{\Delta}$

-   [Example]{.ribbon-highlight}: Distance (outcome), Season (Grouping variable)

    -   Comparing Distance means given Season (3 levels) type

    -   Data from [Multilevel Modeling and Effects Statistics for Sports Scientists in R](https://ryan-curtis.netlify.app/post/multilevel-modeling-and-effects-statistics-for-sports-scientists-in-r/)

    ::: panel-tabset
    ## [{effsize}]{style="color: #990000"}

    Another package, [{effectsize}]{style="color: #990000"}, is similar in that its formula arg only allows for grouping variables with only 2 levels

    -   May have other features though, since it's part of the easystats suite.

    ``` r
    library(effsize)
    effsize::cohen.d(preseason_data$Distance, inseason_data$Distance)
    ## 
    ## Cohen's d
    ## 
    ## d estimate: 0.9157833 (large)
    ## 95 percent confidence interval:
    ##    lower    upper 
    ## 0.7493283 1.0822383
    ```

    -   Season is a categorical fixed effect with 3 levels
    -   Other Available Arguments: [hedges.correction]{.arg-text}, [pooled]{.arg-text}, [paired]{.arg-text}, \[within\]{{.arg-text}}, [noncentral]{.arg-text}

    ## [{rstatix}]{style="color: #990000"}

    ``` r
    library(rstatix)
    data %>% 
      rstatix::cohens_d(Distance ~ Season, ci = TRUE)

    #>     .y.        group1     group2    effsize     n1     n2   conf.low conf.high magnitude 
    #> *  <chr>       <chr>      <chr>       <dbl>   <int>  <int>    <dbl>    <dbl> <ord>     
    #> 1 Distance   Inseason  Postseason   -0.0317    600    200     -0.18     0.13  negligible
    #> 2 Distance   Inseason   Preseason    -0.877    600    200     -1.06    -0.71       large     
    #> 3 Distance Postseason   Preseason    -0.884    200    200     -1.09    -0.68       large
    ```

    -   Same types of arguments as {effsize} are available and also bootstrap CIs
    -   Magnitude (interpretation) by Cohen's (1992) guidelines
    :::

## Common Language Effect Size

$$
Z = \frac{|X_1 - X_2|}{\sqrt{\frac{\text{SD}_1^2 +\text{SD}_2^2}{2}}}
$$

-   The CL effect size e is the percentage associated with the upper tail probability of this Z-Score
-   AKA *Probability of Superiority*
-   Converts the effect size into a percentage
-   Interpretation
    -   Between-Subjects: The probability that a randomly sampled person from one group will have a higher observed measurement than a randomly sampled person from the other group
    -   Within-Subjects: The probability that an individual has a higher value on one measurement than the other.

## Eta Squared

-   Notes from: [Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs](https://pure.tue.nl/ws/files/3835042/1236489301722996.pdf) (Lakens)

-   Measures the proportion of the variation in Y that is associated with membership of the different groups defined by X, or the sum of squares of the effect divided by the total sum of squares

-   eta squared is an uncorrected effect size estimate that estimates the amount of variance explained based on the sample, and not based on the entire population.

-   partial eta squared (η2p) to improve the comparability of effect sizes between studies, which expresses the sum of squares of the effect in relation to the sum of squares of the effect and the sum of squares of the error associated with the effect.

-   Although η2p is more useful when the goal is to compare effect sizes across studies, it is not perfect, because η2p differs when the same two means are compared in a within-subjects design or a between-subjects design.

-   An $\eta^2$ of 0.13 means that 13% of the total variance can be accounted for by group membership.

-   Eta Squared

    $$
    \eta^2 = \frac{\text{SS}_{\text{effect}}}{\text{SS}_{\text{total}}}
    $$

    -   $\text{SS}_{\text{effect}}$ and $\text{SS}_{\text{total}}$ are obtained from the ANOVA results

    -   The correction for eta squared ($\eta^2$) is known as omega squared ($\omega^2$). Still biased but less biased. The difference is typically small, and the bias decreases as the sample size increases.

        $$
        \begin{align}
        \omega^2 &= \frac{\operatorname{df}_{\text{effect}}(\operatorname{MS_{\text{effect}}}-\operatorname{MS_{\text{error}}})}{\operatorname{SS_{\text{total}}} + \operatorname{MS_{\text{error}}}} \quad \text{(between-subjects)} \\
        \omega^2 &= \frac{\operatorname{df}_{\text{effect}}(\operatorname{MS_{\text{effect}}}-\operatorname{MS_{\text{error}}})}{\operatorname{SS_{\text{total}}} + \operatorname{MS_{\text{subjects}}}} \quad \text{(within-subjects)} \\
        \end{align}
        $$

-   Partial Eta Squared

    $$
    \begin{align}
    \eta_p^2 &= \frac{\operatorname{SS_{\text{effect}}}}{\operatorname{SS_{\text{effect}}} + \operatorname{SS_{\text{error}}}} \quad \text{(fixed and measured variables)}\\
    \eta_p^2 &= \frac{F \times \operatorname{df}_{\text{effect}}}{F \times \operatorname{df}_{\text{effect}} + \operatorname{df}_{\text{error}}} \quad \text{(fixed variables)}
    \end{align} 
    $$

    -   Bias-Lessened

        $$
        \omega_p^2 = \frac{\operatorname{df}_{\text{effect}}(\operatorname{MS_{\text{effect}}}-\operatorname{MS_{\text{error}}})}{\operatorname{df}_{\text{effect}} \times  \operatorname{MS_{\text{effect}}} + (N - \operatorname{df}_{\text{effect}}) \times \operatorname{MS_{\text{error}}}}
        $$

        -   Same equation whether it's for between-subject designs and within-subject designs

-   Recommend researchers report η2G and/or η2p, at least until generalized omega-squared is automatically provided by statistical software packages

    -   For designs where all factors are manipulated between participants, η2p and η2G are identical, so either effect size can be reported. For within-subjects designs and mixed designs where all factors are manipulated, η2p can always be calculated from the F-value and the degrees of freedom using formula 13, but η2G cannot be calculated from the reported results,and therefore I recommend reporting η2G for these designs
    -   supplementary spreadsheet provides a relatively easy way to calculate η2G for commonly used designs. For designs with measured factors or covariates, neither η2p nor η2G can be calculated from the

-   Appropriate Version Per Use Cases

    | Use Case                                                                                             | Version    | Less Biased Version |
    |------------------------------------------------------------------------------------------------------|------------|---------------------|
    | Comparisons within a single study                                                                    | $\eta^2$   | $\omega^2$          |
    | Power analyses, and for comparisons of effect sizes across studies with the same experimental design | $\eta_p^2$ | $\omega_p^2$        |
    | Meta-Analyses to compare across various experimental designs                                         | $\eta_G^2$ | $\omega_G^2$        |

-   Guidelines

    -   Cohen's benchmarks were developed for comparisons between unrestricted populations (e.g., men vs. women), and using these benchmarks when interpreting the η2p effect size in designs that include covariates or repeated measures is not consistent with the onsiderations upon which the benchmarks were based.

        -   Although $\eta_G^2$ can be compared using these guidelines, it is preferable to compare effect sizes with those in the literature.
