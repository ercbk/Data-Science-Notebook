# Workflow {#sec-bayes-wkflw .unnumbered}

## Misc {#sec-bayes-wkflw-misc .unnumbered}

-   Also see [Model Building, Concepts \>\> Misc](model-building-concepts.qmd#sec-modbld-misc){style="color: green"} \>\> Regression Workflow
-   Notes from
    -   [Bayesian Workflow](http://www.stat.columbia.edu/~gelman/research/unpublished/Bayesian_Workflow_article.pdf) (Gelman, Vehtari) (arXiv [link](https://arxiv.org/abs/2011.01808))
-   Resources
    -   Vehtari Video: [On Bayesian Workflow](https://www.youtube.com/watch?v=ppKpwtGy8KQ&ab_channel=Generable) (2022) (Based on the paper, but I haven't watched it, yet)
    -   [Nabiximols treatment efficiency](https://users.aalto.fi/~ave/casestudies/Nabiximols/nabiximols.html): Vehtari's example of applyijng his workflow in the context of comparing continuous and discrete observation models.
    -   [Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis](https://arxiv.org/abs/2404.01688) (Haven't read yet)
-   Current Checklist
    -   Check convergence diagnostics
    -   Do posterior predictive checking
    -   Check residual plots
    -   Model comparison (if prediction)
-   Analysis Checklist ([Thread](https://vis.social/@robertGrant/109743940709993385))
    -   A suitably flexible Bayesian regression adjustment model,
    -   Chosen by cross-validation/LOO,
    -   Including Gaussian processes for the unit-level effects over time (and space/network if relevant),
    -   Imputation of missing data, and
    -   Informative priors for biases in the data collection process.
-   Discrete Parameters
    -   Models with discrete parameters arise in a range of statistical motifs including hidden Markov models, finite mixture models, and generally in the presence of unobserved categorical data
    -   HMC cannot operate on models containing discrete parameters. HMC relies on gradient information to guide its exploration of the parameter space. Discrete parameters don't have well-defined gradients.
        -   Using HMC would require marginalization of the likelihood to remove these discrete dimensions from the sampling problem (i.e. integrating out discrete variables).
            -   This can result in loss of information
            -   Depending on the number of discrete parameters, it can be computationally instensive or intractable.
            -   The direct relationship between discrete parameters and the data is obscured.
            -   Potentially requiring more samples to achieve the same level of accuracy due to slower mixing
            -   Can be complex and error-prone for intricate models
    -   [{]{style="color: #990000"}[nimbleHMC](https://cran.r-project.org/web/packages/nimbleHMC/index.html){style="color: #990000"}[}]{style="color: #990000"} ([JOSS](https://joss.theoj.org/papers/10.21105/joss.06745)) can perform HMC sampling of hierarchical models that also contain discrete parameters. It allows for HMC sampling operating alongside discrete samplers.
        -   A workflow for a problem with discrete parameters should consist of testing combinations of samplers in order to optimize MCMC efficiency
        -   [{nimbleHMC}]{style="color: #990000"} allows you to mix-and-match samplers from a large pool of candidates.
        -   Efficiency is measured by Effective Sample Size (ESS) (See [Diagnostics, Bayes \>\> Convergence \> Metrics \>\> Autocorrelation Metrics](diagnostics-bayes.qmd#sec-diag-bay-conv-autoc){style="color: green"})
        -   [{]{style="color: #990000"}[compareMCMCs](https://cran.r-project.org/web/packages/compareMCMCs/index.html){style="color: #990000"}[}]{style="color: #990000"} ([JOSS](https://joss.theoj.org/papers/10.21105/joss.03844)) - Compares MCMC Efficiency from 'nimble' and/or Other MCMC Engines
            -   Built-in metrics include two methods of estimating effective sample size (ESS), posterior summaries such as mean and common quantiles, efficiency defined as ESS per computation time, rate defined as computation time per ESS, and minimum efficiency per MCMC.
