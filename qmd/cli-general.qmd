# General {#sec-cli-gen .unnumbered}

## Misc {#sec-cli-gen-misc .unnumbered}

-   Resources
    -   [Data Science at the Command Line](https://jeroenjanssens.com/dsatcl/)
-   Tools
    -   [direnv](https://github.com/direnv/direnv) - Augments existing shells with a new feature that can load and unload environment variables depending on the current directory
-   `ctrl-r`shell command history search
    -   [McFly](https://github.com/cantino/mcfly) - intelligent command history search engine that takes into account your working directory and the context of recently executed commands. McFly's suggestions are prioritized in real time with a small neural network
-   Path to a folder that's above root folder:
    -   1 level up: `../desired-folder`
    -   2 levels up: `../../desired-folder`

## R {#sec-cli-gen-r .unnumbered}

-   Misc

    -   The "shebang" line starting `#!` allows a script to be run directly from the command line without explicitly passing it through `Rscript` or `r`. It's not required but is a helpful convenience on Unix-like systems.

        ``` r
        #! /usr/bin/env Rscript --vanilla
        ```

-   Resources

    -   [Invoking R from the command line](https://colinfay.me/intro-to-r/appendix-b-invoking-r.html) for using `R` and `R CMD`

-   Packages

    -   [{]{style="color: #990000"}[ps](https://ps.r-lib.org/index.html){style="color: #990000"}[}]{style="color: #990000"} - List, Query, Manipulate System Processes
    -   [{]{style="color: #990000"}[fs](https://fs.r-lib.org/){style="color: #990000"}[}]{style="color: #990000"} - A cross-platform, uniform interface to file system operations
        -   Navarro deep dive, [For fs](https://blog.djnavarro.net/posts/2024-10-06_fs/)
    -   [{]{style="color: #990000"}[littler](https://eddelbuettel.github.io/littler/){style="color: #990000"}[}]{style="color: #990000"} - A scripting and command-line front-end for GNU R

-   `Rscript` need to be on `PATH`

-   Run R (default version) in the shell:

    ``` powershell
    RS
    # or 
    rig run
    ```

    -   `RS` might require [{rig}]{style="color: #990000"} to be installed
    -   To run a specific R version that's already installed: `R-4.2`

-   Run an R script:

    ``` powershell
    Rscript "path\to\my-script.R"
    # or
    rig run -f <script-file>
    ```

-   Evaluate an R expression:

    ``` powershell
    Rscript -e <expression> 
    # or 
    rig run -e <expression>
    ```

-   Run an R app: `rig run <path-to-app>`

    -   Plumber APIs
    -   Shiny apps
    -   Quarto documents (also with embedded Shiny apps)
    -   Rmd documents (also with embedded Shiny apps)
    -   Static web sites

-   Make an R script pipeable (From [link](https://livefreeordichotomize.com/posts/2019-06-04-using-awk-and-r-to-parse-25tb/index.html#piping-to-r))

    ``` bash
    parallel "echo 'zipping bin {}'; cat chunked/*_bin_{}_*.csv | ./upload_as_rds.R '$S3_DEST'/chr_'$DESIRED_CHR'_bin_{}.rds"
    ```

    ``` r
    #!/usr/bin/env Rscript
    library(readr)
    library(aws.s3)

    # Read first command line argument
    data_destination <- commandArgs(trailingOnly = TRUE)[1]

    data_cols <- list(SNP_Name = 'c', ...)

    s3saveRDS(
      read_csv(
            file("stdin"), 
            col_names = names(data_cols),
            col_types = data_cols 
        ),
      object = data_destination
    )
    ```

    -   By passing `readr::read_csv` the function, `file("stdin")`, it loads the data piped to the R script into a dataframe, which then gets written as an .rds file directly to s3 using {aws.s3}.

-   Killing a process

    ``` r
    system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE)
    ```

-   Starting a process in the background

    ``` r
    # start MLflow server
    sys::exec_background("mlflow server")
    ```

-   Delete an opened file in the same R session

    -   You \*\*MUST\*\* unlink it before any kind of manipulation of object

        -   I think this works because readr loads files lazily by default

    -   [Example]{.ribbon-highlight}:

        ``` r
        wisc_csv_filename <- "COVID-19_Historical_Data_by_County.csv"
        download_location <- file.path(Sys.getenv("USERPROFILE"), "Downloads")
        wisc_file_path <- file.path(download_location, wisc_csv_filename)
        wisc_tests_new <- readr::read_csv(wisc_file_path)
        # key part, must unlink before any kind of code interaction
        # supposedly need recursive = TRUE for Windows, but I didn't need it
        # Throws an error (hence safely) but still works
        safe_unlink <- purrr::safely(unlink)
        safe_unlink(wisc_tests_new)

        # manipulate obj
        wisc_tests_clean <- wisc_tests_new %>%
              janitor::clean_names() %>%
              select(date, geo, county = name, negative, positive) %>%
              filter(geo == "County") %>%
              mutate(date = lubridate::as_date(date)) %>%
              select(-geo)
        # clean-up
        fs::file_delete(wisc_file_path)
        ```

-   Find out which process is locking or using a file

    -   Open Resource Monitor, which can be found
        -   By searching for Resource Monitor or resmon.exe in the start menu, or
        -   As a button on the Performance tab in your Task Manager
    -   Go to the CPU tab
    -   Use the search field in the Associated Handles section
        -   type the name of file in the search field and it'll search automatically
        -   35548

## Python {#sec-cli-gen-py .unnumbered}

-   Notes from [Python's many command-line utilities](https://www.pythonmorsels.com/cli-tools/)

    -   Lists and describes *all* CLI utilities that are available through Python's standard library

-   Linux utilities through Python in CLI\

    | Command | Purpose | More |
    |------------------|------------------|------------------------------------|
    | `python3.12 -m uuid` | Like `uuidgen` CLI utility | [Docs](https://docs.python.org/3/library/uuid.html#command-line-usage) |
    | `python3.12 -m sqlite3` | Like `sqlite3` CLI utility | [Docs](https://docs.python.org/3/library/sqlite3.html#command-line-interface) |
    | `python -m zipfile` | Like `zip` & `unzip` CLI utilities | [Docs](https://docs.python.org/3/library/zipfile.html#command-line-interface) |
    | `python -m gzip` | Like `gzip` & `gunzip` CLI utilities | [Docs](https://docs.python.org/3/library/gzip.html#command-line-interface) |
    | `python -m tarfile` | Like the `tar` CLI utility | [Docs](https://docs.python.org/3/library/tarfile.html#command-line-interface) |
    | `python -m base64` | Like the `base64` CLI utility |  |
    | `python -m ftplib` | Like the `ftp` utility |  |
    | `python -m smtplib` | Like the `sendmail` utility |  |
    | `python -m poplib` | Like using `curl` to read email |  |
    | `python -m imaplib` | Like using `curl` to read email |  |
    | `python -m telnetlib` | Like the `telnet`utility |  |

    -   `uuid` and `sqlite3` require version 3.12 or above.

-   Code Utilities\

    | Command | Purpose | More |
    |------------------|------------------|------------------------------------|
    | `python -m pip` | Install third-party Python packages | [Docs](https://docs.python.org/3/installing/index.html) |
    | `python -m venv` | Create a virtual environment | [Docs](https://docs.python.org/3/library/venv.html) |
    | `python -m pdb` | Run the Python Debugger | [Docs](https://docs.python.org/3/library/pdb.html) |
    | `python -m unittest` | Run `unittest` tests in a directory | [Docs](https://docs.python.org/3/library/unittest.html#command-line-interface) |
    | `python -m pydoc` | Show documentation for given string | [Docs](https://docs.python.org/3/library/pydoc.html) |
    | `python -m doctest` | Run doctests for a given Python file | [Docs](https://docs.python.org/3/library/doctest.html) |
    | `python -m ensurepip` | Install `pip` if it's not installed | [Docs](https://docs.python.org/3/library/ensurepip.html#command-line-interface) |
    | `python -m idlelib` | Launch Python's IDLE graphical REPL | [Docs](https://docs.python.org/3/library/idle.html) |
    | `python -m zipapp` | Turn Python module into runnable ZIP | [Docs](https://docs.python.org/3/library/zipapp.html#command-line-interface) |
    | `python -m compileall` | Pre-compile Python files to bytecode | [Docs](https://docs.python.org/3/library/compileall.html) |

## AWK {#sec-cli-gen-awk .unnumbered}

![](./_resources/CLI.resources/DeLcVfSWAAAw6OZ.jpeg){.lightbox width="632"}

-   Misc

    -   Resources
        -   [Docs](https://www.gnu.org/software/gawk/manual/gawk.html)
        -   [Awk - A Tutorial and Introduction](https://www.grymoire.com/Unix/Awk.html)

-   Print first few rows of columns 1 and 2

    ``` awk
    awk -F, '{print $1,$2}' adult_t.csv|head
    ```

-   Filter lines where no of hours/ week (13th column) \> 98

    ``` awk
    awk -F, ‘$13 > 98’ adult_t.csv|head
    ```

-   Filter lines with "Doctorate" and print first 3 columns

    ``` awk
    awk '/Doctorate/{print $1, $2, $3}' adult_t.csv
    ```

-   Random sample 8% of the total lines from a .csv (keeps header)

    ``` awk
    'BEGIN {srand()} !/^$/ {if(rand()<=0.08||FNR==1) print > "rand.samp.csv"}' big_fn.csv
    ```

-   Decompresses, chunks, sorts, and writes back to S3 (From [link](https://livefreeordichotomize.com/posts/2019-06-04-using-awk-and-r-to-parse-25tb/index.html))

    ``` awk
    # Let S3 use as many threads as it wants
    aws configure set default.s3.max_concurrent_requests 50

    for chunk_file in $(aws s3 ls $DATA_LOC | awk '{print $4}' | grep 'chr'$DESIRED_CHR'.csv') ; do

            aws s3 cp s3://$batch_loc$chunk_file - |
            pigz -dc |
            parallel --block 100M --pipe  \
            "awk -F '\t' '{print \$1\",...\"$30\">\"chunked/{#}_chr\"\$15\".csv\"}'"

            # Combine all the parallel process chunks to single files
            ls chunked/ |
            cut -d '_' -f 2 |
            sort -u |
            parallel 'cat chunked/*_{} | sort -k5 -n -S 80% -t, | aws s3 cp - '$s3_dest'/batch_'$batch_num'_{}'

            # Clean up intermediate data
            rm chunked/*
    done
    ```

    -   Uses [pigz](https://linux.die.net/man/1/pigz) to parallelize decompression
    -   Uses GNU Parallel ([site](https://www.gnu.org/software/parallel/), [docs](https://www.gnu.org/software/parallel/man.html), [tutorial1](https://jeroenjanssens.com/dsatcl/chapter-8-parallel-pipelines#introducing-gnu-parallel), [tutorial2](https://www.gnu.org/software/parallel/parallel_tutorial.html#gnu-parallel-tutorial)) to parallelize chunking (100MB chunks in 1st section)
    -   Chunks data into smaller files and sorts them into directories based on a chromosome column (I think)
    -   Avoids writing to disk

## Vim {#sec-cli-gen-vim .unnumbered}

-   Command-line based text editor
-   Common Usage
    -   Edit text files while in CLI
    -   Logging into a remote machine and need to make a code change there. vim is a standard program and therefore usually available on any machine you work on.
    -   When running `git commit`, by default git opens vim for writing a commit message. So at the very least you'll want to know how to write, save, and close a file.
-   Resources
    -   [The minimum vi(m) you need to know](https://freedium.cfd/https://medium.com/@tigerasks/the-minimum-vi-m-you-need-to-know-18ed06a2132d)
    -   [Vim Visual Cheat Sheet](https://hamwaves.com/vim.tutorial/en/index.html)
    -   [Vim Cheatsheet](https://devhints.io/vim)
-   2 modes: Navigation Mode; Edit Mode
    -   When Vim is launched you're in Navigation mode
    -   Press [i]{.arg-text} to start edit mode, in which you can make changes to the file.
    -   Press [Esc]{.arg-text} key to leave edit mode and go back to navigation mode.
-   Commands
    -   `x` deletes a character
    -   `dd` deletes an entire row
    -   `b` (back) goes to the previous word
    -   `n` (next) goes to the next word
    -   `:wq` saves your changes and closes the file
    -   `:q!` ignores your changes and closes the file
    -   `h` is $\leftarrow$
    -   `j` is $\downarrow$
    -   `k` is $\uparrow$
    -   `l` (i.e. lower L) is $\rightarrow$
