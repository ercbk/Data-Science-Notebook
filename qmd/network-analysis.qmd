# Network Analysis {#sec-netanal .unnumbered}

## Misc {#sec-netanal-misc .unnumbered}

-   Analysis Questions
    -   At a given moment in time:
        -   Who is connected to whom? Who is not connected?
        -   Where, and who are the hubs?
        -   Where and about what are the clusters? Are there silos?
    -   Changes over time:
        -   Are new connection forming?
        -   Are new patterns of connectivity forming?
        -   How was our network before and after the introduction of an activity?
-   Issues with Statistics
    -   They are unable to leverage node features at all. All nodes with the same values for these summary statistics are indistinguishable from each other.
    -   There is no learnable component in the production of these features. We cannot fit a custom objective or train them jointly with a downstream task.

## Terms {#sec-netanal-terms .unnumbered}

-   [**Centrality**]{style="color: #14adff"}
    -   Measures, abstractly, how important a given graph is to the connectivity of the overall graph
    -   higher for nodes which lie in paths that efficiently connect many nodes to each other.
    -   Types:
        -   **Betweenness** - Nodes with high betweenness centrality tend to be the "crossroads" between nodes, i.e. when seeking to connect with another node that isn't immediately adjacent, it will typically involve a node with high betweeness centrality.
            -   These nodes are important in keeping the network connected
        -   **Closeness** - Nodes with high closeness centrality have quick access to many other nodes. These nodes have the shortest distance, in network terms, to all other nodes.
            -   These nodes are important in spreading information to all other nodes as quickly as possible.
-   [**Clusters**]{style="color: #14adff"}
    -   **Cluster Clique** - a cluster that has at least one node that's connected to another node outside of the cluster
    -   **Cluster Silo** - a cluster that has no node connected to any other node outside of the cluster
-   [**Clustering coefficient**]{style="color: #14adff"}
    -   Measures the density of a node's local portion of the graph.
    -   Nodes who have neighbors that are all connected to each other will have a higher clustering coefficient
-   [**Degree**]{style="color: #14adff"} - total edges a given node has.
-   [**Edge**]{style="color: #14adff"}- connection between two nodes. Depending on the type of connection, the edge can have a direction.
-   [**Edge Bundling**]{style="color: #14adff"} - visually bundle together similar edges to reduce the visual clutter within a graph
-   [**Multiplexity**]{style="color: #14adff"} - The number of connections between two nodes
    -   Could be represented by the thickness, darkness, etc. of an edge between 2 nodes
    -   Nodes that have high multiplicity with each other typically form clusters

## Layouts/Algorithms {#sec-netanal-layalg .unnumbered}

-   **Spring**
    -   [Fruchterman-Reingold force-directed algorithm](https://en.wikipedia.org/wiki/Force-directed_graph_drawing)
        -   arranges the nodes so the edges have similar length and minimum crossing edges
-   **Random** - nodes positioned uniformly at random in the unit square
-   **Circular** - nodes on a circle
-   **Bipartite** - nodes in two straight lines
-   **Spectral** - nodes positioned using the eigenvectors of the graph Laplacian

## Node Embeddings {#sec-netanal-ndembd .unnumbered}

-   Learnable vectors of numbers that can be mapped to each node in the graph, allowing us to learn a unique representation for each node.
    -   Use as features in a downstream model.
-   Methods
    -   [DeepWalk](https://arxiv.org/pdf/1403.6652.pdf) and [Node2vec](https://arxiv.org/pdf/1607.00653.pdf) papers
        -   Use the concept of a random walk, which involves beginning at a given node and randomly traversing edges, to produce pairs of nodes that are nearby each other.
        -   Trained by maximizing the cosine similarity between nodes that co-occurred in random walks.
            -   This training objective leverages the [homophily assumption](https://en.wikipedia.org/wiki/Network_homophily), which states that nodes that are connected to each other tend to be similar to each other.
-   Issues with Embeddings
    -   They do not use node features at all. They assume that close-by nodes are similar without actually using the node features to confirm this assumption.
-   They rely on a fixed mapping from node to embedding (i.e. this is a transductive method).
    -   For dynamic graphs, where new nodes and edges may be added, the algorithm must be re-ran from scratch, and all node embeddings need to be recalculated. In real-world problems, this is quite a big issue, as most online platforms have new users signing up every day, and new edges being created constantly.

## Graph Convolutional Networks (GCN) {#sec-netanal-gcn .unnumbered}

-   Learns representations of nodes by learning a function that aggregates a node's neighborhood (the set of nodes connected to the original node), using both graph structure and node features.
    -   These representations are a function of a node's neighborhood and are not hardcoded per node (i.e. this is an inductive method), so changes in graph structure do not require re-training the model.
-   For unsupervised learning tasks, the method is similar to Node2vec/DeepWalk
-   Layers
    -   A layer takes a weighted average of the node features in the original node's neighborhood, and the weights are learned by training the network
    -   Adding layers produces aggregations that use more of the graph.
        -   The span of the subgraph used to produce a node's embedding is expanded by 1 hop.
