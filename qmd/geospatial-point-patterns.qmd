# Point Patterns {#sec-geo-ptpat .unnumbered}

## Misc {#sec-geo-ptpat-misc .unnumbered}

-   Notes from [Ch.9](https://paezha.github.io/spatial-analysis-r/point-pattern-analysis-i.html), An Introduction to Spatial Data Analysis and Statistics: A Course in R
-   Packages
    -   [{]{style="color: #990000"}[spatstat](https://cran.r-project.org/web/packages/spatstat/index.html){style="color: #990000"}[}]{style="color: #990000"} - Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests
-   Resources
    -   Spatial Point Patterns: Methodology and Applications with R (R \>\> Documents \>\> Geospatial)
    -   [An Introduction to Spatial Data Analysis and Statistics: A Course in R](https://paezha.github.io/spatial-analysis-r/)

## Terms {#sec-geo-ptpat-terms .unnumbered}

-   [**Intensity**]{style="color: #009499"} - The *expected* number of events per unit area — conventionally denoted by $\lambda$. In most cases the process is not know, so its intensity cannot be directly measured.
-   [**Density**]{style="color: #009499"} - Empirical estimate of **Intensity** — $\hat \lambda = n / a$ , where $a$ is the area of the region
-   [**Quadrats**]{style="color: #009499"} - Cells of a gridded area representing subregions. Useful for analyzing how density varies across a region
    -   Rules of Thumb for choosing the number of quadrats
        -   Each quadrat should have a minimum of two events
        -   Formula based on the area (A) and number of events (N)\
            $$
            Q = \frac{2A}{N}
            $$

## Basics {#sec-geo-ptpat-bas .unnumbered}

-   [Example]{.ribbon-highlight}: Quadrats\
    [pic](https://paezha.github.io/spatial-analysis-r/point-pattern-analysis-i.html#quadrats-and-density-maps)

    ``` r
    data("PointPatterns", package = "isdas")
    summary(PointPatterns)
    ##        x                y                 Pattern  
    ##  Min.   :0.0169   Min.   :0.005306   Pattern 1:60  
    ##  1st Qu.:0.2731   1st Qu.:0.289020   Pattern 2:60  
    ##  Median :0.4854   Median :0.550000   Pattern 3:60  
    ##  Mean   :0.5074   Mean   :0.538733   Pattern 4:60  
    ##  3rd Qu.:0.7616   3rd Qu.:0.797850                 
    ##  Max.   :0.9990   Max.   :0.999808

    ggplot() +
      geom_bin2d(data = filter(PointPatterns, 
                               Pattern == "Pattern 1"),
                 aes(x = x, 
                     y = y),
                 binwidth = c(0.25, 
                              0.25)) +
        geom_point(data = filter(PointPatterns, 
                                 Pattern == "Pattern 1"), 
                 aes(x = x, 
                     y = y)) +
      scale_fill_distiller(palette = "RdBu") +
      coord_fixed()
    ```

    -   `geom_bin2d` is called to plot a map of counts of events in the space defined by the bins.
    -   [PointPatterns]{.var-text} contains [x]{.var-text}, [y]{.var-text} coordinates that range from 0 to 1 and a categorical variable Pattern indicating each of the four difffernt density patterns

-   [Example]{.ribbon-highlight}: spatstat preprocessing

    ``` r
    # define a window
    wnd <- owin(c(0,1), c(0,1)) 
    ppp1 <- as.ppp(PointPatterns, wnd)
    summary(ppp1)
    ## Marked planar point pattern:  240 points
    ## Average intensity 240 points per square unit
    ## 
    ## Coordinates are given to 16 decimal places
    ## 
    ## Multitype:
    ##           frequency proportion intensity
    ## Pattern 1        60       0.25        60
    ## Pattern 2        60       0.25        60
    ## Pattern 3        60       0.25        60
    ## Pattern 4        60       0.25        60
    ## 
    ## Window: rectangle = [0, 1] x [0, 1] units
    ## Window area = 1 square unit

    # plot a specific category of point
    plot(split.ppp(ppp1)$`Pattern 3`)
    ```

    -   The window defined in `owin` should define a region for analysis that is consistent with the pattern of interest
    -   `ppp` (plannar point pattern) is the fundamental spatstat object
    -   [frequency]{.arg-text} is the number of points in that region (e.g. [Pattern]{.var-text})
    -   [proportion]{.arg-text} is the proportion of points in that region to the overall dataset
    -   [intensity]{.arg-text} it the number of points divided by the area (1 x 1 = 1)

-   [Example]{.ribbon-highlight}: Get point counts for each quadrat by region/subregion

    ``` r
    quadratcount(split(ppp1),
                 nx = 4,
                 ny = 4)

    ## List of spatial objects
    ## 
    ## Pattern 1:
    ##             x
    ## y            [0,0.25) [0.25,0.5) [0.5,0.75) [0.75,1]
    ##   [0.75,1]          3          5          1        6
    ##   [0.5,0.75)        2          3          4        6
    ##   [0.25,0.5)        5          4          2        3
    ##   [0,0.25)          2          4          4        6
    ## 
    ## Pattern 2:
    ##             x
    ## y            [0,0.25) [0.25,0.5) [0.5,0.75) [0.75,1]
    ##   [0.75,1]         14          2          2        6
    ##   [0.5,0.75)        0          0          4        6
    ##   [0.25,0.5)        6          3          1        2
    ##   [0,0.25)          4          6          2        2
    ## 
    ## Pattern 3:
    ##             x
    ## y            [0,0.25) [0.25,0.5) [0.5,0.75) [0.75,1]
    ##   [0.75,1]          2         11          5        7
    ##   [0.5,0.75)        1          1          6        4
    ##   [0.25,0.5)        1         10          3        2
    ##   [0,0.25)          2          1          2        2
    ## 
    ## Pattern 4:
    ##             x
    ## y            [0,0.25) [0.25,0.5) [0.5,0.75) [0.75,1]
    ##   [0.75,1]          4          5          6        3
    ##   [0.5,0.75)        3          3          4        2
    ##   [0.25,0.5)        3          3          4        2
    ##   [0,0.25)          5          4          6        3
    ```

    -   [nx]{.arg-text} and [ny]{.arg-text} specify how many quadrats (i.e. cells) you want per row and per column respectively
    -   `split` divides the dataset by the region variable or event type

-   [Example]{.ribbon-highlight}: Toronto Fast Food\
    pic: ff-qct-1

    ``` r
    library(spatstat)
    library(sf)

    data("Fast_Food", package = "isdas")
    data("Toronto", package = "isdas")

    head(Fast_Food)
    #> Simple feature collection with 6 features and 1 field
    #> Geometry type: POINT
    #> Dimension:     XY
    #> Bounding box:  xmin: 620173 ymin: 4840698 xmax: 638544.7 ymax: 4853394
    #> Projected CRS: NAD83 / UTM zone 17N
    #>     Class                 geometry
    #> 1 Chicken POINT (635575.8 4853394)
    #> 2 Chicken POINT (636724.5 4842644)
    #> 3 Chicken POINT (622524.7 4840698)
    #> 4 Chicken POINT (638544.7 4846541)
    #> 5 Chicken POINT (627850.5 4843178)
    #> 6 Chicken   POINT (620173 4841782)
    head(toronto)
    #> Simple feature collection with 1 feature and 0 fields
    #> Geometry type: MULTIPOLYGON
    #> Dimension:     XY
    #> Bounding box:  xmin: 609550.5 ymin: 4826375 xmax: 651611.8 ymax: 4857439
    #> Projected CRS: NAD83 / UTM zone 17N
    #>                         geometry
    #> 1 MULTIPOLYGON (((609550.5 48...

    ppp_ff <- as.ppp(Fast_Food, as.owin(Toronto)) # <1>
    #> Marked planar point pattern: 614 points
    #> Multitype, with levels = Chicken, Hamburger, Pizza, Sub  # <2>
    #> window: polygonal boundary
    #> enclosing rectangle: [609550.5, 651611.8] x [4826375, 4857439] units

    qct_ff <- quadratcount(ppp_ff, nx = 3, ny = 3) # <3>
    table(qct_ff) # <4>
    #>   0   6  44  48  60  64  85 144 163 
    #>   1   1   1   1   1   1   1   1   1 

    plot(qct_ff)
    ```

    1.  To automatically create a window object using the boundaries from a sf object, [{sf}]{style="color: #990000"} needs to be loaded.
    2.  The categories in the [Class]{.var-text} variable are captured as levels
    3.  3 x 3 seems to be a good starting grid for regions such as a city if your data isn't too sparse
    4.  There is 1 quadrat with 0 points. Given that were using a 3 x3 grid, it's very small and probably located underneath the quadrat with 44 points.

## Tests {#sec-geo-ptpat-tests .unnumbered}

-   Quadrat-based Chi-Square Test

    -   A Pearson $\chi^2$ independence test that compares the empirical distribution of events by quadrats to the distribution of events as expected under the hypothesis that the underlying process is random.\
        $$
            \begin{align}
            &\chi^2 = \sum_i^Q r_i^2\\
            &\text{where} \;\; r_i = \frac{\text{observed}_i - \text{expected}_i}{\sqrt{\text{expected}_i}}
            \end{align}
            $$
    -   $r_i$ is the Pearson residual and $Q$ is the number of quadrats
    -   Issues
        -   Test results is affected by the chosen quadrat grid.
        -   Count-based so size of the quadrat matters. With irregular shaped quadrats (e.g. within a city boundary), it might be difficult to create a grid with roughly homogeneous counts.
        -   The test is *not* sensitive to the relative position of the events within the quadrats. So, there could be extreme clustering happening within the quadrats and the test might not reject the Null.

-   [Example]{.ribbon-highlight}: `quadrat.test using a ppp object`\
    pic: quadtest-fastfood-1

    ``` r
    q_test <- 
      quadrat.test(ppp_ff, 
                   nx = 3, 
                   ny = 3)
    q_test
    ## Warning: Some expected counts are small; chi^2 approximation may be inaccurate
    ##  Chi-squared test of CSR using quadrat counts
    ## 
    ## data:  Fast_Food.ppp
    ## X2 = 213.74, df = 8, p-value < 2.2e-16
    ## alternative hypothesis: two.sided
    ## 
    ## Quadrats: 9 tiles (irregular windows)
    ```

    -   All expected counts (assumes a uniform Poisson point process) should be greater than 5 which is why there's a warning.
        -   The docs of this function sound very much like the stuff in my Discrete Analysis notebook, so see that for further details.
        -   Options seem to be to use [method = "MonteCarlo"]{.arg-text} which relaxes the expected count \> 5 condition or using a smaller grid. My DA notebook also suggests Exact Tests if that's available for this sort of thing.
    -   p-value \< 0.05 suggests that this is *not* a CSR (completely spatially random — aka uniform Poisson point process) pattern
        -   If [lambda]{.arg-text} is provided then the Null is a Poisson point process with that $\lambda$ (i.e. intensity or probably also Poisson mean)
    -   Can also use `split.ppp(ppp_ff)` and have each point category tested.
    -   This function has methods for point patterns (class "ppp"), split point patterns (class"splitppp"), point process models (class "ppm" or "slrm"\`) and quadrat count tables (class "quadratcount").
    -   Plotting the object will display the quadrats, annotated by their observed and expected counts and the Pearson residuals.
    -   Pearson residuals can be extracted with `residuals`. They evidently aren't standardized, but if standardized, they can be treated as z-scores with values \> 1.96 indicating which quadrats are causing the rejection of the Null. (See [Regression, Diagnostics \>\> Residuals](diagnostics-regression.qmd#sec-diag-reg-res){style="color: green"} \>\> Standardized Residuals)

-   Kernel Density

    -   Each quadrat is treated as independent of the others in the window.

    -   There isn't a grid of quadrats but in essence, one that slides around the study area.

    -   it gives greater weight to events that are close to the center of the window, and less weight to events that are more distant from the center of the window

    -   The shape of the Gaussian kernel depends on the standard deviation, which controls how “big” the window is, or alternatively, how quickly the function decays. We will call the standard deviation the kernel bandwidth of the function.
