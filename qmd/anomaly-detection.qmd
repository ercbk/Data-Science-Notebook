# Anomaly Detection  {#sec-anomdet}


## Misc  {#sec-anomdet-misc}

-   Also see

    -   [Outliers](Outliers)
    -   bkmks
        -   Time Series \>\> Cleaning/Processing \>\> Outliers
        -   Business Applications \>\> Fraud/Anomaly Detection

-   From Sci Kit Learn ([link](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))![](./_resources/Anomaly_Detection.resources/image.3.png)

-   Common Questions *"I need to know why your model detected an anomaly. I need sound root cause analysis before I adjust my manufacturing process."* (see variable importance tracking)

    ```         
      _“Anomaly detection is not enough: when a model detects an anomaly, it’s already too late. I need prediction to justify investing time and effort into such an approach.”_ (see event rates)

      _“I need prescription: tell me what I should do to prevent a failure from happening.”_ (see variable importance tracking)
    ```

    Common Criticisms *"There are some false positives, I don't have time to investigate each event!"* (see event rates)

    ```         
      _“Your model only detects anomalies when they already_ _happened, it’s useless!”_ (see event rates)

      _“I have hundreds of sensors: when an anomaly is detected by your model, I still have to investigate my whole operations, I’m not saving any time here!”_ (see variable importance tracking)
    ```

-   Amazon Lookout for Equipment - managed service from AWS dedicated to anomaly detection

-   Any abnormal event visible in your time series will either be a:

    -   precursor event
    -   detectable anomaly (forewarning about a future event)
    -   a failure
    -   maintenance activity
    -   healing period while your industrial process recovers after an issue

-   Types

    -   Shocks - abrupt changes, spikes
    -   Level Shifts - can happen when a given time series shifts between range of values based on underlying conditions or operating modes.
        -   **Level** -- the average value for a specific time period
        -   If you want to consider all operating modes when detecting anomalies, you need to take care to include all of them in your training data
    -   Trending: a set of signals can change over time (not necessarily in the same direction).
        -   When you want to assess the condition of a process or of a piece of equipment, these trending anomalies will be great precursors events to search. They will help you build forewarning signals before actual failures may happen.

-   Use average event rates to filter out false positives and predict an upcoming event![](./_resources/Anomaly_Detection.resources/1-X1pTyyPhi0hl-CiIROWfeQ.png)

    -   Take action if  the event rate (i.e. rate of predicted events) starts to grow too large (allowing you to move from detecting to predicting)
        -   e.g. you can decide to only notify an operator after the daily event rate reaches at least 200 per day. This would allow you to only react to 3 events out of the 41 detected (aka predicted) during this period
    -   Use historical event data to calculate an event rate threshold
    -   By only reacting after a threshold predicted event rate has been reached, you filter out false positives (when scarce events are detected)

-   Track variable importance over time to narrow the field of potential causes of an event![](./_resources/Anomaly_Detection.resources/1--cpQNiLGOBxSWftqLA4fhQ.png)

    -   2 stacked column charts represent two anomalous events.
    -   Each color is a predictor variable (e.g. sensor) that was important to the prediction of the event.
        -   Only need to focus on a few (e.g. top five predictor variables)
    -   Use to examine false positives and actual events![](./_resources/Anomaly_Detection.resources/1-x9wbLjOpCCPq4DfEcvYLuw.png)
        -   For the false positive (left)
            -   the percentage of importance attributed the top 5 is much less than that for an actual event
            -   Red is less important and Yellow is more important than when there's an actual event

-   Rolling Spectral Entropy![](./_resources/Anomaly_Detection.resources/image.2.png)![](./_resources/Anomaly_Detection.resources/image.1.png)

    -   Spectral Entropy is the normalized (power) spectral density )(PSD)
    -   Misc
        -   Notes from [Anomaly Detection in Univariate Stochastic Time Series with Spectral Entropy](https://towardsdatascience.com/anomaly-detection-in-univariate-stochastic-time-series-with-spectral-entropy-834b63ec9343)
    -   Guidelines
        -   A series which has strong trend and seasonality (and so is easy to forecast) will have entropy close to 0.
            -   In the case of noisy time series, this indicates an anomaly.
        -   A series that is very noisy (and so is difficult to forecast) will have entropy close to 1.
    -   Example![](./_resources/Anomaly_Detection.resources/image.png)

```         
def spectral_entropy(x, freq, nfft=None):   
    _, psd = periodogram(x, freq, nfft = nfft)   
    # calculate shannon entropy of normalized psd
    psd_norm = psd / np.sum(psd)
    entropy = np.nansum(psd_norm * np.log2(psd_norm))
    return -(entropy / np.log2(psd_norm.size))

window = 200
nfft = None
df = pd.DataFrame(data=x, columns=['x'])
df['x_roll_se'] = df['x'].rolling(window).apply(lambda x: spectral_entropy(x,freq=100,nfft=nfft))
```

-   If the FFT size is not specified, we will use the window size

## Charts {#sec-anomdet-charts}

-   The goal to breakdown an anomaly (e.g. manufacturing process outage) into constituent parts (sensor readings).![](./_resources/Anomaly_Detection.resources/1-98b6-GxeBzVmrSQ6U3cvfg.png)
    -   By analyzing the sensor readings, you can potentially find the area causing the anomaly
    -   There also might be leading indicators that are predictive of an anomaly.
-   Often you're looking at many time series (e.g. a manufacturing process) when performing EDA for anomaly detection, and conventional time series charts are insufficient
-   Horizon Chart![](./_resources/Anomaly_Detection.resources/Screenshot%20(830).png)
    -   Hue (e.g. blue or red) represents values above or below a certain value
    -   Darkness/lightness of the color represents the extremeness of the value
        -   i.e. the darker the color the larger the magnitude of the y-axis value
    -   Vertical layers in the normal chart become horizontal layers of the horizon chart
        -   layer feature may provide more detail than the strip chart
-   Strip Chart
    -   Similar to horizon in that y-axis values get binned and represented by colors![](./_resources/Anomaly_Detection.resources/1-3jM_tlCOIRWb3d21SSUGHw.png)
    -   Example![](./_resources/Anomaly_Detection.resources/1-ifvTLRyv8SCBcOhPsOS21g.png)
        -   Colors
            -   Blue - low, Gold - medium, Red - high
        -   Columns of red indicate shocks (e.g. around 2022-11-15)
    -   Example![](./_resources/Anomaly_Detection.resources/1-hlMumRn0MBT6GMhJy6LPpA.png)
        -   Colors
            -   Blue - low, Gold - medium, Red - high
        -   Major color changes in color indicate trend/level shifts
            -   e.g. the change from a lot of red to a lot of blue after December 2017

## Isolation Forests  {#sec-anomdet-isofor}

-   Also see [Algorithms, ML](Algorithms,%20ML) \>\> Trees \>\> Isolation Forests
-   Used for anomaly detection. Algorithm related to binary search.
-   Notes from paper: https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf
-   The tree algorithm chooses a predictor at random for the root node. Then randomly chooses either the minimum or the maximum of that variable as the splitting value. The algorithm recursively subsamples like normal trees (choosing variables and split points in the same manner) until each terminal node has one data point or replicates of the same data point or preset maximum tree height is reached. Across the trees of a forest, anomalies with have a shorter average path length from root to terminal node.
    -   The algorithm is basically looking for observations with combinations of variables that have extreme values. The process of continually splitting subsamples of data will run out data points and be reduced to a single observation more quickly for an anomalous observation than a common observation.
    -   Makes sense. Picturing a tree structure, there shouldn't be too many observations with more that a few minimums/maximums of variable values. The algorithm weeds out these observations as it moves down the tree structure.
        -   Any or all of these wouldn't necessarily be global minimum/maximums since we're dealing with subsamples of variable values as we move down the tree.
    -   Paper has some nice text boxes with pseudocode that goes through the steps of the algorithm.
-   Anomaly scores range from 0 to 1. Observations with a shorter average path length will have a larger score.
    -   Anomaly score, ![](./_resources/Anomaly_Detection.resources/1373e2c7803ad93fd42ca71fbfab91a7.png)
        -   where E(h(xi)) is the average path length across the isolation forest for that observation
    -   ![](./_resources/Anomaly_Detection.resources/1396f45f8c10262487bd4922bc702bad.png)
        -   where H(i) is the Harmonic number, ![](./_resources/Anomaly_Detection.resources/bb4954c01ea80cf190ec5301a5c8bc4e.png)
    -   Guidelines
        -   The closer an observation's score is to 1 the more likely that it is an anomaly
        -   The closer to zero, the more likely the observation isn't an anomaly.
        -   Observations with scores around 0.5 means that the algorithm can't find a distinction.

## Autoencoders  {#sec-anomdet-autoenc}

-   An outlier is something that the autoencoder has not seen often during training, so it might have trouble finding a good encoding for them.
    -   An autoencoder tries to learn good encodings for a given dataset. Since most data points in the dataset are not outliers, the autoencoder will be influenced most by the normal data points and should perform well on them.
-   Misc
    -   Also see [Feature Reduction](Feature%20Reduction) \>\> Autoencoders
