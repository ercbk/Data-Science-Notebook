---
fig-cap-location: top
---

# Mixed Effects {#sec-econ-me-freq .unnumbered}

## Misc {#sec-econ-me-freq-misc .unnumbered}

-   Mixed Effects Model = Random Effects model = Multi-Level model = Hierarchical model
    -   I've placed this model under econometrics, but it's not considered an "econometrics" model given how widely it's utilized across many disiplines and the history of its development.
-   Bayesian
    -   Resources
        -   [Bayesian Generalized Linear Mixed Effects Models for Deception Detection Analyses](https://psyarxiv.com/fdh5b/)
            -   Paper that's an in-depth tutorial. Uses {brms}, {emmeans}, {parameters}
-   Advantages of a mixed model ($y \sim x + (x \;|\; g)$) vs a linear model with an interaction ($y \sim x \ast g$)
    -   From T.J. Mahr [tweet](https://twitter.com/tjmahr/status/1504124329319096323)
    -   Conceptual: Assumes participant means are drawn from the same latent population
    -   Computational: partial pooling / smoothing
    -   Both will have very similar parameter estimates when the data is balanced with few to no outliers
        -   linear least squares regression can overstate precision, producing t-statistics for each fixed effect that tend to be larger than they should be; the number of significant results in LLSR are then too great and not reflective of the true structure of the data
        -   Standard errors are underestimated in the interaction model though.
            -   Doesn't account for dependence in the repeated measure for each subject
        -   For unbalanced data w/some group categories having few data points or with outliers, the mixed effects model regularizes/shrinks/smooths the estimates to the overall group (i.e. population) mean
    -   Example of model formula interpretation\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/FLvupd_WYAQPIzA.png){.lightbox width="490"}
-   Packages
    -   [{]{style="color: #990000"}[lme4](https://cran.r-project.org/web/packages/lme4/index.html){style="color: #990000"}[}]{style="color: #990000"} - linear and generalized linear mixed-effects models; implemented using the 'Eigen' C++ library for numerical linear algebra and 'RcppEigen' "glue".
        -   Using [{]{style="color: #990000"}[lmerTest](https://cran.r-project.org/web/packages/lmerTest/index.html){style="color: #990000"}[}]{style="color: #990000"} will produce a summary of lme4 models with pvals and dofs for coefficients
    -   [{]{style="color: #990000"}[multilevelmod](https://multilevelmod.tidymodels.org/){style="color: #990000"}[}]{style="color: #990000"} - tidymodels wrapper for many mixed model packages.
    -   [{]{style="color: #990000"}[plm](https://cran.r-project.org/web/packages/plm/index.html){style="color: #990000"}[}]{style="color: #990000"} - linear models for panel data; including within/fixed effects, random effects, between, first-difference, nested random effects
    -   [{]{style="color: #990000"}[glmmTMB](https://glmmtmb.github.io/glmmTMB/){style="color: #990000"}[}]{style="color: #990000"} - for fitting generalized linear mixed models (GLMMs) and extensions
        -   Wide range of statistical distributions (Gaussian, Poisson, binomial, negative binomial, Beta ...) and zero-inflation.
        -   Fixed and random effects models can be specified for the conditional and zero-inflated components of the model, as well as fixed effects for the dispersion parameter.
    -   [{]{style="color: #990000"}[spaMM](https://cran.r-project.org/web/packages/spaMM/index.html){style="color: #990000"}[}]{style="color: #990000"} - Inference based on models with or without spatially-correlated random effects, multivariate responses, or non-Gaussian random effects (e.g., Beta).
-   Mixed Effects and repeated measures (aka longitudinal)
    -   **Mixed Effects Models** = Fixed Effects *and* Random Effects
        -   i.e. variation within the unit and between the units
    -   Harrell ([article](https://www.fharrell.com/post/re/))
        -   Says that Mixed Models models can capture within-subject correlation of repeated measures over very short time intervals but not over extended time intervals where autocorrelation comes into play
            -   Example of a short interval is a series of tests on a subject over minutes when the subject does not fatigue
            -   Example of a long interval is a typical longitudinal clinical trial where patient responses are assessed weekly or monthly
        -   He recommends a Markov model for longitudinal RCT data (see bkmks)
    -   Bartlett
        -   [Mixed model repeated measures (MMRM) in Stata, SAS and R](https://thestatsgeek.com/2020/12/30/mixed-model-repeated-measures-mmrm-in-stata-sas-and-r/)
            -   Tutorial; uses {nlme::gls}
-   [{tidymodels}]{style="color: #990000"} [workflows](https://multilevelmod.tidymodels.org/articles/multilevelmod.html#models-using-lmer-glmer-and-stan_glmer') (optional outputs: lmer, glmer, stan_glmer objects)

## Considerations {#sec-econ-me-freq-consid .unnumbered}

-   [Motivation for using a Random Effects model]{.underline}
    -   You think the little subgroups are part of some bigger group with a common mean effect
        -   e.g. Multiple observations of a single person, or multiple people in a school, or multiple schools in a district, or multiple varieties of a single kind of fruit, or multiple kinds of vegetable from the same harvest, or multiple harvests of the same kind of vegetable, etc.
    -   These subgroup means significantly *deviate* from the big group mean.
        -   i.e. We suspect there to be between-subject variance and not just within-subject variance (linear model).

            ::: {layout-ncol="2"}
            ![Within-Subject](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/consid-withinsub-1.png){.lightbox group="consid-var" width="432"}

            ![Between-Subject](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/consid-btsub-1.png){.lightbox group="consid-var" width="432"}
            :::

            -   The **Between-Subject Variance** isn't clearly depicted IMO. The Between-Subject Variance captures the differences between individual subjects or groups in their average responses or outcomes. It can be understood better by looking at the sample formula where the grand mean is subtracted from each subject's mean.

                $$
                \text{Between-Subject Variance} = \frac{\sum_{i=1}^{k} n_i (\bar{X}_i - \bar{X})^2}{k-1}
                $$

                -   $k$ is the number of groups or levels of the independent variable.
                    -   Denominator is a dof term.
                -   $n_i$ is the number of observations in the i^th^ group.
                -   $\bar X_i$ is the mean of the observations in the i^th^ group.
                -   $\bar X$ is the grand mean.
    -   These *deviations* follow a distribution, typically Gaussian.
        -   That's where the "random" in **random effects** comes in: we're assuming the *deviations* of subgroups from a parent follow the distribution of a *random* (Gaussian) variable
            -   The variation between subgroups is assumed to have a normal distribution with a 0 mean and constant variance (variance estimated by the model).
        -   GEEs are a semi-parametric option for panel data (See [Regression, Other \>\> Generalized Estimating Equations (GEE)](regression-other.qmd#sec-reg-other-gee){style="color: green"})
-   [Fixed Effects or Random Effects?]{.underline}
    -   If there's likely correlation between unobserved group/cases variables (e.g. individual talent) and treatment variable (i.e. E(α\|x) != 0) AND there's substantial variance between group units, then FE is a better choice (See [Econometrics, Fixed Effects \>\> One-Way Fixed Effects](econometrics-fixed-effects.qmd#sec-econ-fe-owfe){style="color: green"} \>\> Assumptions)
    -   If cases units change little, or not at all, across time, a fixed effects model may not work very well or even at all (SEs for a FE model will be large)
        -   **The FE model is for analyzing within-units variance**
    -   Do we wish to estimate the effects of variables whose values do not change across time, or do we merely wish to control for them?
        -   FE: these effects aren't estimated but adjusted for by explicitly including a separate intercept term for each individual (αi) in the regression equation
        -   RE: estimates these effects (might be biased if RE assumptions violated)
            -   **The RE model is for analyzing between-units variance**
    -   The amount of within-unit variation relative to between-unit variation has important implications for these two approaches
        -   [Article](https://www.r-bloggers.com/2022/06/fixed-effects-vs-random-effects-for-web-browsing-data-a-simulation/) with simulated data showed that within variation around sd \< 0.5 didn't detect the effect of explanatory variable but ymmv (depends on \# of units, observations per unit, N)
    -   Durbin--Wu--Hausman test ([{plm::phtest}]{style="color: #990000"})
        -   If H0 is not rejected, then both FE and RE are consistent but only RE is efficient. $\rightarrow$ use RE but if you have a lot of data, then FE is also fine.
        -   If H0 is rejected, then only FE is consistent $\rightarrow$ use FE
    -   ICC \> 0.1 is generally accepted as the minimal threshold for justifying the use of Mixed Effects Model (See [Diagnostics \>\> ICC](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-diag){style="color: green"})
-   [Pooling]{.underline}
    -   **Complete pooling** - Each unit is assumed to have the *same* effect
        -   [Example]{.ribbon-highlight}: County is the grouping variable and radon level is the outcome
            -   All counties are *alike*.
                -   i.e. all characteristics of counties that affect radon levels in houses have the statistically same effect across counties. Therefore, the variable has no information.
            -   Run a single regression to estimate the average radon level in the whole state.
                -   `lm(radon_level ~ predictors)`
                -   Note that "county" is NOT a predictor in this model
    -   **No pooling** - All units are assumed to have *independent* effects
        -   [Example]{.ribbon-highlight}: County is the grouping variable (although not a predictor in this case) and radon level is the outcome
            -   All counties are *different* from each other.
                -   i.e. there are no common characteristics of counties that affect radon levels in houses. Any characteristic a county has that affects radon levels is unique to that county.
            -   Run a regression for each county to estimate the average radon level for each county.
                -   `lm(radon_level ~ 0 + county + predictors`
                -   Using the "0 +" formula removes the common intercept which means each county will get it's own intercept
    -   **Partial pooling** - Each unit is assumed to have a different effect, but the [data for all of the observed units informs the estimates for each unit]{.underline}
        -   [Example]{.ribbon-highlight}: County is the grouping variable (random effect) and radon level is the outcome
            -   All counties are *similar* each other.
                -   i.e. all charcteristics of counties that affect radon levels in house have statistically varying effects sizes depending on the particular county
            -   Run a multi-level regression to share information across counties.
                -   `lmer(radon_level ~ predictors + (1 + predictor | county))`
        -   This can be a nice compromise between estimating an effect by completely pooling all groups, which masks group-level variation, and estimating an effect for all groups completely separately, which could give poor estimates for low-sample groups.
        -   If you have few data points in a group, the group's effect estimate will be based partially on the more abundant data from other groups. (2 min [video](https://www.youtube.com/watch?v=qMe7qwNMe-s))
            -   This is called **Regularization**. Subjects with fewer data points will have their estimates pulled to the grand mean more than subjects with more data points.
                -   The grand mean will be the [(Intercept)]{.arg-text} value in the Fixed Effects section of the `summary`.
            -   You can visualize the amount of regularization by comparing the conditional modes (see [Model Equation](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-modeq){style="color: green"} \>\> Conditional Modes) to the group means in the observed data.
                -   [Example]{.ribbon-highlight} ([link](https://jeanettemumford.org/MixedModelSeries/v4-introduction-to-regularization-in-mixed-models.html))\
                    ![](_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/cond-modes-obs-comp-3.png){.lightbox width="432"}

                    <details>

                    <summary>Code</summary>

                    ``` r
                    rt_lme_mod <- 
                      lmer(rt ~ 1 + (1|subid), 
                           dat)

                    comparison_dat <- 
                      dat |>
                      summarize(avg_rt = mean(rt), .by = subid) |> 
                      mutate(cond_modes = coef(rt_lme_mod)$subid[[1]]) |> 
                      tidyr::pivot_longer(
                        cols = c(avg_rt, cond_modes),
                        names_to = "type",
                        values_to = "estimate"
                      )

                    ggplot(comparison_dat,
                           aes(x = subid, y = estimate, color = type)) +
                      geom_point() +
                      scale_color_manual(values = c("#195198", "#BD9865")) +
                      geom_hline(yintercept = lme4::fixef(rt_lme_mod)[[1]]) + # overall intercept/grand mean
                      scale_x_continuous(breaks = seq(0 , 10, 1), 
                                         minor_breaks=seq(0, 10,1)) +
                      theme_notebook()
                    ```

                    </details>

                    -   The conditional modes (gold) are all closer to the horizontal line which represents the grand mean.
                    -   There are few data points for each of the first five subjects, so in general, they are *pulled* more than the last five subjects which have many more data points.
                        -   i.e. The differences between the observed means (blue) and conditional modes (gold) are greater in the first five subjects than the last five subjects
                        -   Points already close to the grand mean can't be *pulled* as much since they're already very close to the grand mean (e.g. subject 1)
        -   Partial pooling is typically accomplished through hierarchical models. Hierarchical models directly model the population of units. From a population model perspective, no pooling corresponds to infinite population variance, whereas complete pooling corresponds to zero population variance.
-   [Variable Assignment]{.underline}
    -   Questions ([article](https://rlbarter.github.io/Practical-Statistics/2017/03/03/fixed-mixed-and-random-effects/) has examples)
        -   Can the groups we see be considered the full population of possible groups we could see, or are they more like a random sample of a larger set of groups?
            -   Full Population: Fixed
            -   Random Sample: Random
        -   Do we want to estimate a coefficient for this grouping, or do we just want to account for the anticipated structure that the groups may impose on our observations?
            -   Y: Fixed
            -   N: Random
    -   **Fixed Effects** provide estimates of mean-differences or slopes.
        -   "Fixed" because they are effects that are constant for each subject/unit
        -   Should include within-subject variables (e.g. random effect slope variables) and between-subject variables (e.g. gender)
        -   Level One: variables measured at the most frequently occurring observational unit
            -   i.e. Vary for each repeated measure of a subject and vary between subjects
                -   In the dataset, these variables that (for the most part) have different values for each row
                -   Time-dependent if you have longitudinal data
            -   For a RE model, these are usually the adjustment variables
                -   e.g. Conditioning on a confounder
        -   Level Two: variables measured at the observational unit level
            -   i.e. Constant for each repeated measure of a subject but vary between each subject
            -   For a RE model, these are usually the treatment variables or variables of interest
                -   They should contain the information about the between-subject variation
            -   If a factor variable, it has levels which would not change in replications of the study
    -   **Random Effects** estimate of variation between and within subgroups
        -   Intercepts variables (e.g. [v1]{.arg-text} in [Specification and Notation](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-specnot){style="color: green"}) should be grouping variables (i.e. discrete or categorical) (e.g school, department)
        -   Slopes variables (e.g. [v2]{.arg-text} in [Specification and Notation](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-specnot){style="color: green"}) should be continuous within-subject variables (e.g time)
            -   These variables should also be included in the fixed effects
        -   Quantifies how much of the overall variation can be attributed to that particular variable.
            -   Example: the variation in beetle DAMAGE was attributable to the FARM at which the damage took place, so you'd cluster by FARM (`1|FARM`)
        -   If you want slopes to vary according to a variable, the variation of slopes between-units will be a random effect
            -   Usually a level 2 fixed effect variable
        -   If you want intercepts to vary according to a variable, the variation of intercepts between-units will be a random effect
            -   This will the unit/subject variable (e.g student id, store id) that has the repeated observations
        -   Typically categorical variables that we are *not* interested in measuring their effects on the outcome variable, but we do want to adjust for. This variation might capture effects of latent variables.
            -   This factor variable has levels which can be thought of as a sample from a larger population of factor levels (e.g. hockey players)
            -   [Example]{.ribbon-highlight}: 2 hockey players both averaged around 20 minutes per game last year (fixed variable). Predictions of the amount of points scored by just accounting for this fixed variable would produce similar results. But using PLAYER as a random variable will capture the impact of persistent characteristics that might not be observable elsewhere in the explanatory data. PLAYER can be thought of as a proxy for "offensive talent" in a way.
        -   If the values of the variable were chosen at random, then you should cluster by that variable (i.e. choose as the random variable)
            -   [Example]{.ribbon-highlight}: If you can rerun the study using different specific farms (i.e .different values of the FARM factor, see above) and still be able to draw the same conclusions, then FARM should be a random effect.
                -   However, if you had wanted to compare or control for these particular farms, then Farm would be "fixed."
                -   Say that there is nothing about comparing these specific fields that is of interest to the researcher. Rather, the researcher wants to generalize the results of this experiment to all fields. Then, FIELD would be "random."
        -   If the random effects are correlated with variables of interest (fixed effects), leaving them out could lead to biased fixed effects. Including them can help more reliably isolate the influence of the fixed effects of interest and more accurately model a clustered system.
        -   To see individual random effects: `lme4::ranef(lme_mod)` or `lme4::ranef(tidy_mod$fit)`

## Model Equation {#sec-econ-me-freq-modeq .unnumbered}

-   Notes from Video Playlist: [Mixed Model Series](https://www.youtube.com/playlist?list=PLB2iAtgpI4YEAUiEQ1ZnfMXY-yewNzn9z)

    -   Companion [resource](https://jeanettemumford.org/MixedModelSeries/index.html) to the videos. Contains more details, code, and references.

-   Also see the [BMLR Chapter 8](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8){style="color: green"} section for a similar description

-   It's useful to consider the model in two stages even though all the parameters are estimated at the same time (See Combined equation)

    -   If all subjects have the same number of observations, the 2-Stage approach and Mixed Model should have very similar results.

-   Issues with *only* using a 2-stage approach

    -   Not all random effects structures can be modelling using 2 stages
    -   The variance estimate in the 2^nd^ stage will be incorrect
    -   Mixed Effects models have built-in regularization.

-   2-stage model

    -   1^st^ Stage\
        $$
        Y_i = \beta_iZ_i + \epsilon_i, \quad \epsilon \sim \mathcal N (0, \sigma^2I_{n_i})
        $$
        -   $\beta_i Z_i$ is the slope and intercept times the design matrix for subject $i$
        -   $\epsilon$ is the within-subject error
        -   $\sigma^2I_{n_i}$ is the within-subject variance matrix which is just a diagonal matrix with $\sigma^2$s along the diagonal.
            -   In this case $\sigma^2$ is constant for all subjects. (i.e. the variance is pooled). Preferred method when you have small data which makes estimation of subject-level variance difficult. For
        -   $\beta_i$ says that there's a slope for each subject which makes sense if there's repeated measures
    -   2^nd^ Stage\
        $$
        \beta_i = \beta A_i + b_i, \quad b_i \sim \mathcal N (0, G)
        $$
        -   $\beta$ is a group parameter estimate (i.e. avarage intercept and average slope across all subjects)
        -   $A_i$ is a design matrix
            -   Typically an identity matrix unless it's a more complex model
        -   $b_i$ is the **random effect** between-subject error. Isn't actually a subject-level vector of residuals. It's an estimated distribution — typically Gaussian.
            -   $G$ is a 2 $\times$ 2 Covariance matrix (in this case). Same for all subjects.
                -   Upper-Left: Between-Subject Intercept Variance
                -   Bottom-Right: Between-Subject Slope Variance
                -   Upper-Right: Covariance between slope and intercept (i.e. a dependence between slope and intercept)
                    -   Same for Bottom-Left.
    -   Combined: $Y_i = \beta Z_i A_i + b_i Z_i + \epsilon_i$

-   Term Estimates

    ``` r
    library(lme4); library(Matrix)
    data("sleepstudy")
    # varying slopes and varying intercepts
    lmer_mod <- 
      lmer(Reaction ~ 1 + Days + (1 + Days | Subject),
           sleepstudy,
           REML = 0)
    summary(lmer_mod)

    #> Random effects:
    #>  Groups   Name        Variance Std.Dev. Corr
    #>  Subject  (Intercept) 565.48   23.780       
    #>           Days         32.68    5.717   0.08
    #>  Residual             654.95   25.592       
    #> Number of obs: 180, groups:  Subject, 18
    ```

    -   $\sigma^2$ is [Residual = 654.95]{.arg-text} (variance of the within-subject error)
    -   $G$
        -   [Subject (Intercept) = 565.52 (Variance)]{.arg-text} (Upper-Left: Between-Subject Intercept Variance)
        -   [Days = 32.48 (Variance)]{.arg-text} (Between-Subject Slope Variance)
        -   [Days = 0.08 (Corr)]{.arg-text} (Upper-Right: Covariance between slope and intercept)

-   Conditional Modes

    -   Subject (aka unit) based esimates (e.g. the average rating (response) for judge 5 (grouping variable)). The predicted value for subject $i$ from the mixed model.
    -   aka BLUPs (Best Linear Unbiased Predictor). Often see this terminology despised by academics though.
    -   Process
        -   Condition on Y to the distribution for $\beta$
        -   Use the *mode* of that distribution as a prediction for subject $i$'s $\beta$
            -   If it's a symmetric distribution, then the mode will equivalent the mean.
    -   Get conditional modes from model: `coef(lmer_mod)$grouping_var`
    -   Relationship to Means\
        $$
        \begin{align}
        &\hat\beta_i = W_i\hat\beta_i^{OLS}+(I_q-W_i)A_i\hat\beta \\
        &\text{where} \quad W_i= \frac{G}{G+\sigma^2(Z_i'Z_i)^{-1}}
        \end{align}
        $$
        -   The top equation shows that if the weight $W$ is large (e.g. $1$), then the OLS estimate (subject-level means) will be close the mixed effects estimate
        -   The bottom equation shows that if the Between-Subject Variance ($G$) is much larger than the Within-Subjects Variance ($\sigma^2$), then the weight will be large (i.e. close to $1$).

## Assumptions {#sec-econ-me-freq-assum .unnumbered}

-   [No Time-Constant Unobserved Heterogeneity]{.underline}: $\mathbb{E}(\alpha_i\;|\;x_{it}) = 0$
    -   i.e. [No correlation between time-invariant valued, unobserved variables (aka random effect variable) and the explanatory variable of interest (e.g. treatment)]{.underline}

        -   [**Time-Invariant Valued, Unobserved Variables**]{style="color: #009499"}: Variables that are constant across time for each unit and explain variation *between-units*
            -   e.g. If random effect variable (aka clustering variable) is the individual, then the "time-invariant, unobserved" variable could be something latent like talent or something measureable like intelligence or socio-economic status. Whatever is likely to explain the variance between-units in relation to the response.

    -   The effect that these variables have must also be time-invariant

        -   e.g. The effect of gender on the outcome at time 1 is the same as the effect of gender at time 5
        -   If effects are time-varying, then an interaction of gender with time could be included

    -   It's not reasonable for this to be *exactly* zero in order to use a mixed effected model, but for situations where there's high correlation, this model should be avoided

    -   [Example]{.ribbon-highlight}: Violation\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/unnamed-chunk-21-1.png){.lightbox width="432"}

        -   Each group's x values get larger from left to right as each group's α (aka y-intercepts) for each unit get larger
            -   i.e. Mixed-Effects models fail in cases where there's very high correlation between group intercepts and x, together with large between-group variability compared to the within-group variability
        -   \*\*FE model would be better in this case
            -   Gelman has a [paper](file:///C:/Users/tbats/Documents/R/Documents/Regression/mixed%20effects/fitting-multilevel-models-when-predictors-group-effects-correlate-Bafumi-Gelman.pdf) that describes how a mixed effect model can be fit in this situation though
-   [No Time-Varying Unobserved Heterogeneity]{.underline}: $\mathbb{E}(\epsilon_{it}|x_{it}) = 0$
    -   i.e [No endogeneity (no correlation between the residuals and explanatory variable of interest)]{.underline}
    -   If violated, there needs to be explicit measurements of omitted time-invariant variables (see 1st assumption for definition) if they are thought to *interact* with other variables in the model.

## Specifications and Notation {#sec-econ-me-freq-specnot .unnumbered}

-   Every variable within the parentheses is for the random effects. Variables outside the parentheses are fixed effects.
-   [Varying Intercepts]{.underline}: `(1 | v1)`
    -   AKA [Random Intercepts]{.underline}, where each level of the random variable (our random effect) had an adjustment to the overall intercept

    -   [Example]{.ribbon-highlight}: Each [department]{.var-text} (random variable) has a different starting (intercepts) [salary]{.var-text} (outcome variable) for their faculty members (observations), while the annual rate (slope) at which salaries increase is consistent across the university (i.e. effect is constant between-[departments]{.var-text})\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/Screenshot%20(925).png){.lightbox width="332"}

        $$
        \widehat{\text{salary}}_i = \beta_{0 j[i]} + \beta_1 \cdot \text{experience}_i
        $$

        -   Where j\[i\] is the index for [department]{.var-text}
        -   This strategy allows us to capture variation in the starting [salary]{.var-text} (intercepts) of our faculty
-   [Varying Slopes]{.underline}: `(0 + v2| v1)`
    -   AKA [Random Slopes]{.underline}, which would allow the effect of the v2 to vary by v1

        -   i.e. v2 is a predictor whose effect varies according to the level of the grouping variable, v1.

    -   i.e. A slope for each level of the random effects variable

    -   [Example]{.ribbon-highlight}: faculty [salary]{.var-text} (outcome) increase at different rates (slopes) depending on the [department]{.var-text} (random variable).\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/Screenshot%20(926).png){.lightbox width="332"}

        $$
        \widehat{\text{salary}}_i = \beta_0 + \beta_{1 j[i]} \cdot \text{experience}_i
        $$

        -   Where j\[i\] is the index for [department]{.var-text}
        -   This strategy allows us to capture variation in the *change* (slopes) in [salary]{.var-text}
-   [Varying Slopes and Intercepts]{.underline}: `(1 + v2 | v1)` or just `(v2 | v1)` (See examples)
    -   See above for descriptions of each

    -   [Example]{.ribbon-highlight}: Each [department]{.var-text} (random variable) has a different starting (intercepts) [salary]{.var-text} (outcome variable) for their faculty members (observations), while the annual rate (slope) at which salaries increase varies depending on [department]{.var-text}\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/Screenshot%20(922).png){.lightbox width="332"}

        $$
        \widehat{\text{salary}}_i = \beta_{0 j[i]} + \beta_{1 j[i]} \cdot \text{experience}_i
        $$

        -   Where j\[i\] is the index for [department]{.var-text}
        -   See above for descriptions of each type of variation this strategy captures
-   [Nested effects]{.underline}
    -   e.g. Studying [test scores]{.var-text} (outcome variable) within [schools]{.var-text} (random variable) that are within [districts]{.var-text} (random variable)
    -   Notation: `(1 | v1 / v2)` says intercepts varying among v1 *and* v2 *within* v1.
        -   e.g. [schools]{.var-text} is v2 and [districts]{.var-text} is v1
    -   Unit IDs may be repeated within groups.
        -   [Example]{.ribbon-highlight}: `lme4::lmer(score ~ time  + (time | school/student_id))`
            -   The random effect at this level is the combination of [school]{.var-text} and [student_id]{.var-text}, which is unique.
            -   You can verify this by calling `ranef` on the fitted model. It'll show you the unique combinations of [student_ids]{.var-text} within [schools]{.var-text} used in the model.
    -   If you take the fixed effects values shown in `summary(model)` then add the `ranef(model)` values to them, that's what `coef(model)` gives.

## Strategy {#sec-econ-me-freq-strat .unnumbered}

-   Misc
    -   Also see
        -   [BMLR Ch 8 \>\> Model Building Workflow: Simple to Complex](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw){style="color: green"}
        -   [Model Building, Concepts \>\> Misc](model-building-concepts.qmd#sec-modbld-misc){style="color: green"}
    -   Begins with a saturated fixed effects model, determines variance components based on that, and then simplifies the fixed part of the model after fixing the random part.
-   Overall:
    -   EDA
    -   Fit some simple, preliminary models, in part to establish a baseline for evaluating larger models.
    -   Then, build toward a final model for description and inference by attempting to add important covariates, centering certain variables, and checking model assumptions.
-   Process
    -   EDA at each level (See [EDA, Multilevel, Longitudinal](eda-multilevel-longitudinal.qmd#sec-eda-multlong){style="color: green"})
    -   Examine models with no predictors to assess variability at each level
    -   Create Level One models: starting simple and adding terms as necessary (See [Considerations](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-consid){style="color: green"} \>\> Variable Assignment \>\> Fixed Effects )
    -   Create Level Two models: starting simple and adding terms as necessary (See [Considerations](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-consid){style="color: green"} \>\> Variable Assignment \>\> Fixed Effects)
        -   Beginning with the equation for the intercept term.
    -   Examine the random effects and variance components (See [Considerations](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-consid){style="color: green"} \>\> Variable Assignment \>\> Random Effects)
        -   Beginning with a full set of error terms and then removing covariance terms and variance terms where advisable
            -   e.g. When parameter estimates are failing to converge or producing impossible or unlikely values
        -   See [Specifications and Notation](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-specnot){style="color: green"} for different RE modeling strategies.

## Diagnostics {#sec-econ-me-freq-diag .unnumbered}

-   Also see

    -   [Diagnostics, Mixed Effects](diagnostics-mixed-effects.qmd#sec-diag-me){style="color: green"}
    -   [BMLR Ch.8 \>\> Model Building Workflow \>\> Unconditional Means](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-ri){style="color: green"} for an ICC example
    -   [Examples](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-examp){style="color: green"} \>\> Random Intercept-Only model for an ICC example

-   Check Degrees of Freedom (DOF) in Fixed Effects Estimates

    -   The degrees of freedom for the estimates should be close to the number of subjects (aka units)

    -   Large degrees of freedom in comparison to the number of subjects indicates a misspecification of the model. (e.g. 60 subjects and dofs are close to the number of observations)

        -   Degrees of Freedom that are less than then number of subjects are fine and could be due to substantially imbalanced numbers of observations among the subjects.

    -   Also papers should report the dofs.

    -   [Example]{.ribbon-highlight}

        ``` r
        library(lmerTest)
        data("sleepstudy")
        lmer_mod <- 
          lmer(Reaction ~ 1 + Days + (1 + Days | Subject),
               sleepstudy,
               REML = 0)
        summary(lmer_mod)

        #> Fixed effects:
        #>             Estimate Std. Error      df t value Pr(>|t|)    
        #> (Intercept)  251.405      6.632  18.001  37.907  < 2e-16 ***
        #> Days          10.467      1.502  18.000   6.968 1.65e-06 ***

        lmer_mod2 <- 
          lmer(Reaction ~ 1 + Days + (1 | Subject),
               sleepstudy,
               REML = 0)
        summary(lmer_mod2)
        #> Fixed effects:
        #>             Estimate Std. Error       df t value Pr(>|t|)    
        #> (Intercept) 251.4051     9.5062  24.4905   26.45   <2e-16 ***
        #> Days         10.4673     0.8017 162.0000   13.06   <2e-16 ***
        ```

        -   There are 18 subjects, so the first model is a well-specified model
        -   The dof spikes to [162]{.arg-text} for the [Days]{.var-text} fixed effect which is close to the number of total observations at 180. This indicates a misspecified model.
            -   The [24.4905]{.arg-text} is actually okay for the intercept.
        -   Note that you need to used {lmerTest} and not {lme4} to fit the model in order to get the dofs and pvals. Although there's probably a helper function in {lmerTest} since it loads {lme4} that will give the same results if you fit the model using {lme4}

-   **InterClass Coefficient (ICC)**: The proportion of variation that is between-cases\

    $$
    \rho = \frac{\sigma_0}{\sigma_0 + \sigma_\epsilon}
    $$

    -   Where $\sigma_0$ is the between-case variance and $\sigma_\epsilon$ is the within-case variance.

    -   1-ICC is the proportion of variation within cases

    -   Statistical power is a function of ICC ([article](https://www.rdatagen.net/post/2023-04-18-generating-variable-cluster-sizes-to-assess-power-in-cluster-randomize-trials/))\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/image.png){.lightbox width="432"}

        -   Both higher ICCs and cluster size variability lead to reduced power
        -   The dispersion parameter is a parameter used in the data simulation

    -   Guideline: ICC \> 0.1 is generally accepted as the minimal threshold for justifying the use of Mixed Effects Model

    -   [Example]{.ribbon-highlight}: [{sjPlot}]{style="color: #990000"}

        ``` r
        library(sjPlot)
        tab_model(lme_fit)
        ```

        -   Might need [{lmerTest}]{style="color: #990000"} loaded to get coefficient pvals
        -   Also calculates two R^2^ values
            -   Marginal: proportion of variance explained , by the fixed effects only
            -   Conditional: proportion of variance explained by the fixed effects and random effects

## Examples {#sec-econ-me-freq-examp .unnumbered}

-   [Example]{.ribbon-highlight}: One-Way Random Effects

    ``` r
    re1 <- plm(happiness ~ age, data = df,
              index = c("id", "wave"),
              effect = "individual", model = "random")

    summary(re1)
    ## Effects:
    ##                  var std.dev share
    ## idiosyncratic 0.03641 0.19081 0.096
    ## individual    0.34396 0.58648 0.904
    ## theta: 0.8394
    ## Coefficients:
    ##              Estimate Std. Error z-value  Pr(>|z|)   
    ## (Intercept)  6.933947  1.534054  4.5200 6.183e-06 ***
    ## age         -0.015621  0.031277 -0.4994    0.6175
    ```

    -   In Fixed effects, "id" is the *cases* variable and "wave" is the time variable, but I'm not sure if that's how they're referred to in a Mixed Effects model
        -   Maybe indexes are always required for panel data even if it isn't a FE model
    -   [effect = "individual"]{.arg-text}, [model = "random"]{.arg-text} specifies the model as a mixed effects model
    -   [idiosyncratic]{.arg-text} is the time-variant variance (within-cases, ε) variance
    -   [individual]{.arg-text} is the time-constant (between-cases, α) variance

-   [Example]{.ribbon-highlight}: [{lme4}]{style="color: #990000"}

    -   From <https://www.alexcernat.com/etimating-multilevel-models-for-change-in-r>
    -   [usl]{.var-text} is UK sociological survey data
        -   [logincome]{.var-text} is a logged income variable
        -   [pidp]{.var-text} is the person's id
        -   [wave0]{.var-text} is the time variable that's indexed at 0

    ::: panel-tabset
    ## Random Intercepts

    ``` r
    library(lme4)
    # unconditional means model (a.k.a. random effects model)
    m0 <- lmer(data = usl, logincome ~ 1 + (1 | pidp))

    # check results
    summary(m0)
    ## Linear mixed model fit by REML ['lmerMod']
    ## Formula: logincome ~ 1 + (1 | pidp)
    ##    Data: usl
    ## 
    ## REML criterion at convergence: 101669.8
    ## 
    ## Scaled residuals: 
    ##    Min      1Q  Median      3Q    Max 
    ## -7.2616 -0.2546  0.0627  0.3681  5.8845 
    ## 
    ## Random effects:
    ##  Groups  Name        Variance Std.Dev.
    ##  pidp    (Intercept) 0.5203  0.7213 
    ##  Residual            0.2655  0.5152 
    ## Number of obs: 52512, groups:  pidp, 8752
    ## 
    ## Fixed effects:
    ##            Estimate Std. Error t value
    ## (Intercept) 7.162798  0.008031  891.8
    ```

    -   0 covariates
    -   Interpretation
        -   Fixed effects:
            -   [(Intercept) = 7.162798]{.arg-text}, which is the grand mean
                -   Says that over all the time points and individuals, the estimated average log income is 7.162798
        -   Random effects:
            -   Everything that varies by [pidp]{.var-text}
            -   Between-case (or person, group, cluster, etc.) variance: [(Intercept) = 0.5203]{.arg-text}
            -   Within-case (or person, group, cluster, etc.) variance: [Residual = 0.2655]{.arg-text}
    -   ICC
        -   $\frac{0.520}{0.520 + 0.265} = 0.662$
        -   Says about 66% of the variation in [log income]{.var-text} comes between people while the remaining (\~ 34%) is within people.

    ## Random Intercepts

    ``` r
    library(lme4)
    # unconditional change model (a.k.a. MLMC)
    m1 <- lmer(data = usl, logincome ~ 1 + wave0 + (1 | pidp))

    summary(m1)
    ## Linear mixed model fit by REML ['lmerMod']
    ## Formula: logincome ~ 1 + wave0 + (1 | pidp)
    ##    Data: usl
    ## 
    ## REML criterion at convergence: 100654.8
    ## 
    ## Scaled residuals: 
    ##    Min      1Q  Median      3Q    Max 
    ## -7.1469 -0.2463  0.0556  0.3602  5.7533 
    ## 
    ## Random effects:
    ##  Groups  Name        Variance Std.Dev.
    ##  pidp    (Intercept) 0.5213  0.7220 
    ##  Residual            0.2593  0.5092 
    ## Number of obs: 52512, groups:  pidp, 8752
    ## 
    ## Fixed effects:
    ##            Estimate Std. Error t value
    ## (Intercept) 7.057963  0.008665  814.51
    ## wave0       0.041934  0.001301  32.23
    ## 
    ## Correlation of Fixed Effects:
    ##      (Intr)
    ## wave0 -0.375
    ```

    -   1 covariate

    -   Random Effect: Cases; Fixed Effect: Time

    -   [Interpretation]{.underline}

        -   Fixed effects:
            -   [(Intercept) = 7.057]{.arg-text}; the expected log income at the beginning of the study (wave 0).
            -   [wave0 = 0.0419]{.arg-text}
                -   The average rate of change with the passing of a [wave]{.var-text}.
                    -   I don't think this is a percentage. It's the same as a standard OLS regression interpretation.
                -   So after each [wave]{.var-text}, individual [log income]{.var-text} is expected to slowly increase by 0.041 on average.
        -   Random Effects
            -   Everything that varies by [pidp]{.var-text}
            -   Between-Case (or person, group, cluster, etc.) variance in log income: [(Intercept) = 0.5213]{.arg-text}
            -   Within-Case (or person, group, cluster, etc.) variance in log income: [Residual = 0.2593]{.arg-text}
            -   So this stuff is still very similar numbers as the random intercept-only model

    -   [Visualize Effect]{.underline}\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/unnamed-chunk-8-1.png){.lightbox width="432"}

        ``` r
        usl$pred_m1 <- predict(m1)
        usl %>% 
          filter(pidp %in% 1:5) %>% # select just five individuals
          ggplot(aes(wave, pred_m1, color = pidp)) +
          geom_point(aes(wave, logincome)) + # points for observed log income
          geom_smooth(method = lm, se = FALSE) + # linear line showing wave0 slope
          theme_bw() +
          labs(x = "Wave", y = "Logincome") + 
          theme(legend.position = "none")
        ```

        -   [wave]{.var-text} was indexed to 0 for the model but now [wave]{.var-text} starts at 1. He might've reverted wave to have a starting value of 1 for graphing purposes
        -   Lines show the small, positive, fixed effect slope for [wave0]{.var-text}
        -   Parallel lines means we assume the change in [log income]{.var-text} over time is the same for all the individuals
            -   i.e. We assume there is no between-case variation in the rate of change.

    ## Random Slopes and Intercepts

    ``` r
    library(lme4)
    # unconditional change model (a.k.a. MLMC) with re for change
    m2 <- lmer(data = usl, logincome ~ 1 + wave0 + (1 + wave0 | pidp))

    summary(m2)
    ## Linear mixed model fit by REML ['lmerMod']
    ## Formula: logincome ~ 1 + wave0 + (1 + wave0 | pidp)
    ##    Data: usl
    ## 
    ## REML criterion at convergence: 98116.1
    ## 
    ## Scaled residuals: 
    ##    Min      1Q  Median      3Q    Max 
    ## -7.8825 -0.2306  0.0464  0.3206  5.8611 
    ## 
    ## Random effects:
    ##  Groups  Name        Variance Std.Dev. Corr 
    ##  pidp    (Intercept) 0.69590  0.8342       
    ##          wave0       0.01394  0.1181  -0.51
    ##  Residual            0.21052  0.4588       
    ## Number of obs: 52512, groups:  pidp, 8752
    ## 
    ## Fixed effects:
    ##            Estimate Std. Error t value
    ## (Intercept) 7.057963  0.009598  735.39
    ## wave0       0.041934  0.001723  24.34
    ## 
    ## Correlation of Fixed Effects:
    ##      (Intr)
    ## wave0 -0.558
    ```

    -   Random Effect: outcome (i.e. intercept) by cases

    -   Time Effect by cases

    -   Fixed Effect: time

    -   [`(1 + wave0 | pidp)`]{.arg-text} - Says let both the intercept ("1") and [wave0]{.var-text} vary by [pidp]{.var-text} - Which means that average [log income]{.var-text} varies by person and the rate of change (slope) in [log income]{.var-text} over time ([wave0]{.var-text} fixed effect) varies by person.

    -   [Interpretation]{.underline}

        -   Fixed effects:
            -   [(Intercept) = 7.057963]{.arg-text}: The expected [log income]{.var-text} at the beginning of the study ([wave 0]{.var-text}).
            -   [wave0 = 0.0419]{.arg-text}
                -   The average rate of change with the passing of a [wave]{.var-text}.
                    -   I don't think this is a percentage. It's the same as a standard OLS regression interpretation.
                -   So after each wave, individual [log income]{.var-text} is expected to slowly increase by 0.041 on average.
        -   Random effects:
            -   Everything that varies by [pidp]{.var-text}
            -   Between-Case (or person, group, cluster, etc.) variance of [log income]{.var-text}:
                -   [(Intercept) = 0.69590]{.arg-text}
                -   How much average [log income]{.var-text} varies by person at the start of the study ([wave]{.var-text} = 0)
            -   Within-Case (or person, group, cluster, etc.) variance of [log income]{.var-text}:
                -   [Residual = 0.21052]{.arg-text}
                -   How much each person's [log income]{.var-text} varies in relation to her average [log income]{.var-text}
            -   Between-Case variance in the rates of change of [log income]{.var-text} over time
                -   [wave0 = 0.01394]{.arg-text}
                -   i.e. How much the fixed effect, [wave0]{.var-text}, slope varies by person

    -   [Visualize Effect]{.underline}\
        ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/unnamed-chunk-9-1.png){.lightbox width="432"}

        ``` r
        usl$pred_m2 <- predict(m2) 
        usl %>%  
          filter(pidp %in% 1:5) %>% # select just two individuals 
          ggplot(aes(wave, pred_m2, color = pidp)) + 
          geom_point(aes(wave, logincome)) + # points for observed logincome 
          geom_smooth(method = lm, se = FALSE) + # linear line based on prediction 
          theme_bw() + # nice theme 
          labs(x = "Wave", y = "Logincome") + # nice labels 
          theme(legend.position = "none")
        ```

        -   Different slopes for each person
    :::

-   [Example]{.ribbon-highlight}: Varying Slopes and Intercepts

    ``` r
    m_slope <- lmer(pp60 ~ position + toi + 
                    (1 + age | player),
                    data = df)
    ```

    -   We use this model if we wanted to incorporate an [age]{.var-text} variable into our model and we wanted the influence of that variable to vary by [player]{.var-text}, it would be incorporated like so, before the [\| player]{.arg-text}:

-   [Example]{.ribbon-highlight}: [{ggeffects}]{style="color: #990000"} Error Bar Plot\
    ![](./_resources/Econometrics,_Mixed_Effects,_Frequentist.resources/staticunnamed-chunk-6-1.png){.lightbox width="432"}

    ``` r
    library(ggeffects)
    library(ggplot2)
    # create plot dataframe
    # Has 95% CIs for fixed effects and lists random effects
    plot_data <- ggpredict(fit, terms = c("Season"))

    #create plot
    plot_data %>%
      #reorder factor levels for plotting
      mutate(x = ordered(x, levels = c("Preseason", "Inseason", "Postseason"))) %>%
      #use plot function with ggpredict objects
      plot() + 
      #add ggplot2 as needed
      theme_blank() + ylim(c(3000,7000)) + ggtitle("Session Distance by Season Phase")
    ```

    -   Description:
        -   Outcome: [Distance]{.var-text}
        -   Fixed Effect: [Season]{.var-text}
        -   Random Effect: [Athlete]{.var-text}

-   [Example]{.ribbon-highlight}: [{tidymodels}]{style="color: #990000"} Varying Intercepts

    ``` r
    lmer_spec <- 
      linear_reg() %>% 
      set_engine("lmer")

    tidy_mod <- 
      lmer_spec %>% 
      fit(pp60 ~ position + toi + (1 | player),
          data = df)

    tidy_mod
    ## parsnip model object
    ## 
    ## Linear mixed model fit by REML ['lmerMod']
    ## Formula: pp60 ~ position + toi + (1 | player)
    ##    Data: data
    ## REML criterion at convergence: 115.8825
    ## Random effects:
    ##  Groups  Name        Std.Dev.
    ##  player  (Intercept) 0.6423 
    ##  Residual            0.3452 
    ## Number of obs: 80, groups:  player, 20
    ## Fixed Effects:
    ## (Intercept)    positionF          toi 
    ##    -0.16546      1.48931      0.06254
    ```

## BMLR Chapter 8: Multilevel Models {#sec-econ-me-freq-bmlrch8 .unnumbered}

-   Beyond Multiple Linear Regression, [Chapter 8](https://bookdown.org/roback/bookdown-BeyondMLR/ch-multilevelintro.html): Introduction to Multilevel Models
-   [Variable Types]{.underline}
    -   Level One: variables measured at the most frequently occurring observational unit
        -   i.e. Variables that (for the most part) have different values for each row
        -   i.e. Vary for each repeated measure of a subject and vary between subjects
    -   Level Two: variables measured on larger observational units
        -   i.e. Constant for each repeated measure of a subject but vary between each subject
-   [Data Description in the Examples]{.underline}
    -   [na]{.var-text} (outcome) - Negative Affect (i.e. [Performance Anxiety]{.var-text})
    -   [large]{.var-text} - binary
        -   [large = 1]{.var-text} means the performance type is a Large Ensemble
        -   [large = 0]{.var-text} means the performance type is either a Solo or Small Ensemble
    -   [orch]{.var-text} - binary
        -   [orch = 1]{.var-text} means the instrument is Orchestral
        -   [orch = 0]{.var-text} means the instrument is either a Keyboard or it's Vocal
-   [Two-Stage Model]{.underline}
    -   The 2-stage model shows a clearer depiction of how a multi-level model is fit in principle
        -   2-stage model uses Ordinary Least Squares to fit a system of regression equations in stages
        -   The multi-level model fits a composite of that system of equations using Maximum Likelihood Estimation
    -   Process
        -   Level 1 models are fitted for each subject/unit
        -   Using the estimated level 1 intercepts and slopes as outcome variables, Level 2 intercept and slope models respectively are fit
        -   The errors from the Level 2 models are the random effects
    -   Issues
        -   Weights every subject the same regardless of the number of repeated observations
        -   Responds to missing individual slopes (i.e. subjects never exposed to treatment) by simply dropping those subjects
        -   Does not share strength effectively across subjects
    -   Specification
        -   Level 1

            $$
            Y_{ij} = a_i + b_i \text{large}_{ij} + \epsilon_{ij}
            $$

            -   $b_i$ is the fixed effect for subject/unit $i$ and observation $j$ (i.e. each subject has repeated observations)

        -   Level 2

            $$
            \begin{align}
            a_i &= \alpha_0 + \alpha_1 \text{orch}_i + u_i \\
            b_i &= \beta_0 + \beta_1 \text{orch}_i + v_i
            \end{align}
            $$

            -   $u_i$ and $v_i$ are the random effects for subject/unit $i$
            -   $a_i$ is the true (i.e. not estimated since no hat) mean of [performance anxiety]{.var-text} (outcome) when subject plays solos or small ensembles ([large = 0]{.var-text})
            -   $b_i$ is the true mean difference in [performance anxiety]{.var-text} (outcome) for subject~i~ between large ensembles and other performance types ([large]{.var-text} contrast)

### Multi-Level {#sec-econ-me-freq-bmlrch8-multlev .unnumbered}

-   [Process]{.underline}

    -   Level 1 and Level 2 equations have been combined through substitution then reduced into a composite model
    -   Parameters estimated through Maximum Likelihood Estimation

-   [Misc]{.underline}

    -   Error Distribution
        -   Correlation between parameters is accounted for using a multivariate normal distribution estimated through a variance-covariance matrix of the error terms (aka random effects) of each Level (see [link](https://bookdown.org/roback/bookdown-BeyondMLR/ch-multilevelintro.html#MVN) for details)
    -   Adding Level 1 variables to a model formula should change within-person variability ($\hat\sigma^2$ and $\hat\sigma$)
        -   Even without adding a Level 1 variable, *small* changes could occur due to numerical estimation procedures used in likelihood-based parameter estimates
    -   Optimization methods
        -   Usually very little difference between ML and REML parameter estimates
        -   Restricted Maximum Likelihood (REML) is preferable when the number of parameters is large or the primary interest is obtaining estimates of model parameters, either fixed effects or variance components associated with random effects
        -   Maximum Likelihood (MLE) should be used if nested fixed effects models are being compared using a likelihood ratio test, although REML is fine for nested models of random effects that have the same fixed effects.
    -   P-Values
        -   Can't be calculated because the exact distribution of the test statistics under the null hypothesis (no fixed effect) is unknown, primarily because the exact degrees of freedom is not known
        -   Rule of Thumb: t-values (ratios of parameter estimates to estimated standard errors) with absolute value above 2 indicate significant evidence that a particular model parameter is different than 0
        -   Packages that do report p-values of fixed effects typically using conservative assumptions, large-sample results, or approximate degrees of freedom for a t-distribution
            -   Using [{lmerTest}]{style="color: #990000"} will produce a summary of {lme4} with pvals for coefficients
        -   Parametric Bootstrap can be used to approximate the distribution of the likelihood test statistic and produce more accurate p-values by simulating data under the null hypothesis
    -   Model Comparison
        -   Pseudo-R^2^
            -   See below in Simple to Complex Model Building Workflow \>\>
                -   [Random Slopes and Intercepts Model (with 1 covariate)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi1){style="color: green"}
                -   [Random Slopes and Intercepts Model (with 2 covariates)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi2){style="color: green"}
        -   AIC, BIC
            -   See [Random Intercepts (with 2 covariates)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-ri2){style="color: green"}
        -   Likelihood Ratio Test (LR-Test)
            -   See [Random Slopes and Intercepts Model (with 3 covariates)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi3){style="color: green"}

-   [Composite Specification]{.underline}

    $$
    Y_{ij} = [\alpha_0 + \alpha_1 \text{orch}_i + \beta_0 \text{large}_{ij} + \beta_1 \text{orch}_i \text{large}_{ij}] + [u_i + v_i \text{large}_{ij} + \epsilon_{ij}]
    $$

    -   Composite model of level 1 and level 2 equations
    -   Random Slopes and Intercepts Model (with 2 covariates)
    -   Fixed Effects: $\alpha_0$, $\alpha_1$, $\beta_0$ and $\beta_1$
    -   $u_i + v_i \cdot \text{large}_{ij} + \epsilon_{ij}$ is the interesting part.
        -   This part has all the error terms and any variables in the Level 2 equations
        -   The first part is a typical regression with interaction terms.

-   [Interpretation]{.underline}

    -   See [Two-stage model](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8){style="color: green"} for definitions for $a_i$ and $b_i$
        -   Keyboardists and Vocalists ([orch~i~]{.var-text} [= 0]{.var-text})

            $$
            \begin{align}
            a_i &= \alpha_0 + u_i \\
            b_i &= \beta_0 + v_i
            \end{align}
            $$

        -   Orchestral Instrumentalists ([orch~i~]{.var-text} [= 1]{.var-text})

            $$
            \begin{align}
            a_i = (\alpha_0 + \alpha_1) + u_i \\
            b_i = (\beta_0 + \beta_1) + v_i
            \end{align}
            $$
    -   Mean Performance Anxiety (outcome) when:
        -   Keyboardists or Vocalists ([orch = 0]{.var-text}) play solos or small ensembles ([large = 0]{.var-text}): $\alpha_0$
        -   Keyboardists or vocalists ([orch = 0]{.var-text}) play large ensembles ([large = 1]{.var-text}): $\alpha_0 + \beta_0$
        -   Orchestral instrumentalists ([orch = 1]{.var-text}) play solos or small ensembles ([large = 0]{.var-text}): $\alpha_0 + \alpha_1\alpha_0 + \alpha_1$
        -   Orchestral instrumentalists ([orch = 1]{.var-text}) play large ensembles ([large = 1]{.var-text}): $\alpha_0 + \alpha_1 + \beta_0 + \beta_1$

-   [Model Summary]{.underline} (using `lmer4::lmer()`)

    ``` r
    #>     Linear mixed model fit by REML ['lmerMod'] 
    #> A)  Formula: na ~ orch + large + orch:large + (large | id) 
    #>         Data: music 
    #> B)  REML criterion at convergence: 2987 

    #> B2)      AIC      BIC  logLik deviance df.resid 
    #>         3007    3041    -1496    2991      489 

    #>     Random effects: 
    #>       Groups  Name        Variance Std.Dev. Corr 
    #> C)  id      (Intercept)    5.655   2.378         
    #> D)            large        0.452   0.672   -0.63 
    #> E)  Residual              21.807   4.670         
    #> F)  Number of obs: 497, groups:  id, 37 

    #>     Fixed effects: 
    #>                 Estimate Std. Error t value 
    #> G)  (Intercept)  15.930      0.641  24.83 
    #> H)  orch          1.693      0.945   1.79 
    #> I)  large        -0.911      0.845  -1.08 
    #> J)  orch:large   -1.424      1.099  -1.30
    ```

    -   Definitions
        -   **A**: How our multilevel model is written in R, based on the composite model formulation.
        -   **B**: Measures of model performance. Since this model was fit using REML, this line only contains the REML criterion.
        -   **B2**: If the model is fit with ML instead of REML, the measures of performance will contain AIC, BIC, deviance, and the log-likelihood.
        -   **C**: Estimated variance components ($\hat \sigma^2_u$ and $\hat \sigma_u$) associated with the intercept equation in Level Two. (between-unit variability)
        -   **D**: Estimated variance components ($\hat \sigma^2_v$ and $\hat \sigma_v$) associated with the large ensemble ([large = 1]{.var-text}) effect equation in Level Two. (Also between-unit variability but just for the slope)
            -   Also, in the "Corr" column, the estimated correlation ($\hat \rho_{uv}$) between the two Level Two error terms.
        -   **E**: Estimated variance components ($\hat \sigma^2$ and $\hat \sigma$ associated with the Level One equation. (within-unit variability)
        -   **F**: Total number of performances where data was collected (Level One observations = 497) and total number of subjects (Level Two observations = 37).
        -   **G**: Estimated fixed effect ($\hat \alpha_0$) for the intercept term, along with its standard error and t-value (which is the ratio of the estimated coefficient to its standard error).
        -   **H**: Estimated fixed effect ($\hat \alpha_1$) for the orchestral instrument ([orch = 1]{.var-text}) effect, along with its standard error and t-value.
        -   **I**: Estimated fixed effect ($\hat \beta_0$) for the large ensemble ([large = 1]{.var-text}) effect, along with its standard error and t-value.
        -   **J**: Estimated fixed effect ($\hat \beta_1$) for the interaction between orchestral instruments ([orch = 1]{.var-text}) and large ensembles ([large = 1]{.var-text}), along with its standard error and t-value.
    -   Interpretations
        -   Fixed effects:
            -   $\hat \alpha_0 = 15.9$ --- The estimated mean performance anxiety (outcome) for solos and small ensembles ([large = 0]{.var-text}) for keyboard players and vocalists ([orch = 0]{.var-text}) is 15.9.
            -   $\hat \alpha_1 = 1.7$ --- Orchestral instrumentalists ([orch = 1]{.var-text}) have an estimated mean [performance anxiety]{.var-text} (outcome) for solos and small ensembles ([large = 0]{.var-text}) which is 1.7 points higher than keyboard players and vocalists ([orch = 0]{.var-text}).
            -   $\hat \beta_0 = −0.9$ --- Keyboard players and vocalists ([orch = 0]{.var-text}) have an estimated mean decrease in [performance anxiety]{.var-text} (outcome) of 0.9 points when playing in large ensembles ([large = 1]{.var-text}) instead of solos or small ensembles ([large = 0]{.var-text}).
            -   $\hat \beta_1 = −1.4$ --- Orchestral instrumentalists ([orch = 1]{.var-text}) have an estimated mean decrease in [performance anxiety]{.var-text} (outcome) of 2.3 points when playing in large ensembles ([large = 1]{.var-text}) instead of solos or small ensembles ([large = 0]{.var-text}), 1.4 points greater than the mean decrease among keyboard players and vocalists ([orch = 0]{.var-text}).
                -   He's calculating simple slope/marginal effect (See [Regression, Interactions](regression-interactions.qmd#sec-reg-inter){style="color: green"}) and choosing to use that as the interpretation for the interaction term
                    -   From Ch. 1 ([link](https://bookdown.org/roback/bookdown-BeyondMLR/ch-MLRreview.html#multiple-linear-regression-with-an-interaction-term)): "We interpret the coefficient for the interaction term by comparing slopes under fast and non-fast conditions; this produces a much more understandable interpretation for a reader than attempting to interpret the -0.011 (interaction coef) directly"
                        -   Fast and non-fast are levels of a main effect and a term in the interaction.
                -   Calculation: The interaction is the difference in slopes for one interaction variable (e.g. large) at different values of the other interaction variable (e.g. [orch]{.var-text})
                    -   Regression eq (ignoring the random effects part):
                        -   $\hat Y_i = 15.93 + 1.693\text{orch}_i - 0.911\text{large} − 1.424\text{orch}_i \times \text{large}_i$
                    -   Examining the [large]{.var-text} slope so only dealing with terms that contain "large"
                        -   [large = 1]{.var-text} is reference category in the interaction that the coefficient is associated with so it remains constant
                    -   [When [orch = 0]{.var-text} and [large = 1]{.var-text}]{.underline}, the slope for [large]{.var-text} is -0.911 = $\hat \beta_0$
                        -   $- 0.911\text{large} − 1.424\text{orch}_i \times \text{large}_i = -0.911 \times 1 - 1.424 \times \boldsymbol{0} \times 1 = -0.911 = \hat \beta_0$
                    -   [When [orch = 1]{.var-text} and [large = 1]{.var-text}]{.underline}, the slope for large is -2.335 (uses this one for his interpretation)
                        -   $- 0.911\text{large} − 1.424\text{orch}_i \times \text{large}_i = -0.911 \times 1 - 1.424 \times \boldsymbol{1} \times 1 = -0.911 - 1.424 = -2.335$ (i.e. "decrease... of 2.3 points")
                    -   The difference in these slopes is the interaction coefficient: $-2.335 - (-0.911) = -1.424$
        -   Variance components
            -   $\hat \sigma_u = 2.4$ --- The estimated standard deviation of [performance anxiety]{.var-text} (outcome) for solos and small ensembles ([large = 0]{.var-text}) is 2.4 points, after controlling for instrument ([orch]{.var-text}) played.
            -   $\hat \sigma_v = 0.7$ --- The estimated standard deviation of differences in [performance anxiety]{.var-text} (outcome) between large ensembles ([large = 1]{.var-text}) and other performance types ([large = 0]{.var-text}) is 0.7 points, after controlling for instrument ([orch]{.var-text}) played.
            -   $\hat \rho_{uv} = −0.64$ --- The estimated correlation between [performance anxiety]{.var-text} scores (outcome) for solos and small ensembles ([large = 0]{.var-text}) and increases in [performance anxiety]{.var-text} (outcome) for large ensembles ([large = 1]{.var-text}) is -0.64, after controlling for instrument ([orch]{.var-text}) played.
                -   Those subjects with higher performance anxiety scores for solos and small ensembles tend to have greater decreases in performance anxiety for large ensemble performances.
            -   $\hat \sigma = 4.7$ --- The estimated standard deviation in residuals for the individual regression models is 4.7 points.

### Model Building Workflow: Simple to Complex {#sec-econ-me-freq-bmlrch8-mbwkfw .unnumbered}

-   Workflow should include:
    -   Fixed effects that allow one to address primary research questions
    -   Fixed effects that control for important covariates at all levels
    -   Investigation of potential interactions
    -   Variables that are centered where interpretations can be enhanced
    -   Important variance components
    -   Removal of unnecessary terms
    -   A final model that tells a "persuasive story parsimoniously"
-   Model Comparison (Also see [multi-level](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-multlev){style="color: green"} \>\> misc \>\> p-values & model comparison)
    -   LR-Test for nested models
    -   AIC, BIC for unnested models
    -   Consider models that involve removing terms that have t-stats \< \|2\|
-   Models
    -   Unconditional Means (aka Random Intercepts)
    -   Random Slopes and Intercepts Model (with 1 covariate)
    -   Random Slopes and Intercepts Model (with 2 covariates)
    -   Random Intercepts (with 2 covariates)
    -   Random Slopes and Intercepts Model (with 3 covariates)
    -   Final Model

#### Unconditional Means (aka Random Intercepts) {#sec-econ-me-freq-bmlrch8-mbwkfw-ri .unnumbered}

-   [Specification]{.underline}

    -   Level 1: $Y_{ij} = a_i + \epsilon_{ij} \quad \text{where}\: \epsilon \sim \mathcal{N}(0, \sigma^2)$
        -   $a_i$ is the true mean response of all observations for subject~i~
    -   Level 2: $a_i = \alpha_0 + u_i \quad \text{where} \: u_i \sim \mathcal{N}(0, \sigma^2_u)$
        -   Each subject's intercept is assumed to be a random value from a normal distribution centered at $\alpha_0$ with variance $\sigma^2_u$.
    -   Composite: $Y_{ij} = \alpha_0 + u_i + \epsilon_{ij}$

-   [Model]{.underline}

    ``` r
    #Model A (Unconditional means model)
    model.a <- lmer(na ~ 1 + (1 | id), REML = T, data = music)
    ##  Groups  Name        Variance Std.Dev.
    ##  id      (Intercept)  4.95    2.22   
    ##  Residual            22.46    4.74
    ##  Number of Level Two groups =  37
    ##            Estimate Std. Error t value
    ## (Intercept)    16.24    0.4279  37.94
    ```

-   [Interpretation]{.underline}

    -   $\hat \alpha_0 = 16.2$ --- The estimated mean performance anxiety score across all performances and all subjects.

    -   $\hat \sigma^2 = 22.5$ --- The estimated variance in within-person deviations.

    -   $\hat \sigma^2_u = 5.0$ (rounded from 4.95) --- The estimated variance in between-person deviations.

    -   ICC

        $$
        \hat \rho = \frac{\text{between-person variability}}{\text{total variability}} = \frac{\hat \sigma^2_u}{\hat \sigma^2_u + \hat \sigma ^2} = \frac{5.0}{5.0 + 22.5} = 0.182
        $$

        -   18.2% of the total variability in performance anxiety scores are attributable to differences among subjects.
            -   \*For plain random intercepts models only\*, you can also say this same number says that the average correlation for any pair of responses from the same individual is a moderately low 0.182.
        -   As $\rho$ approaches 0: responses from an individual are essentially independent and accounting for the multilevel structure of the data becomes less crucial.
        -   As $\rho$ approaches 1: repeated observations from the same individual essentially provide no additional information and accounting for the multilevel structure becomes very important.
        -   Effective Sample Size (ESS): The number of independent pieces of information we have for modeling
            -   With $\rho$ near 0: ESS approaches the total number of observations.
            -   With $\rho$ near 1: ESS approaches the number of subjects in the study.

#### Random Slopes and Intercepts Model (with 1 covariate) {#sec-econ-me-freq-bmlrch8-mbwkfw-rsi1 .unnumbered}

-   1 - Level 1

-   [Specification]{.underline}

    -   Level 1: $Y_{ij} = a_i + b_i \text{large}_{ij} + \epsilon_{ij}$

    -   Level 2

        $$
        a_i = \alpha_0 + u_i \\
        b_i = \beta_0 +v_i
        $$

    -   Composite

        $$
        \begin{aligned}
        &Y_{ij} = [\alpha_0 + \beta_0 \text{large}_{ij}] + [u_i + v_i \text{large}_{ij} + \epsilon_{ij}] \\
        &\begin{aligned}
        \text{where}\quad \epsilon &\sim \mathcal{N}(0, \sigma^2) \: \text{and}\\
        \left[ \begin{array}{cc} u_i \\ v_i \end{array} \right] &\sim \mathcal{N} \left(\left[\begin{array}{cc} 0\\0 \end{array}\right], \left[\begin{array}{cc} \sigma^2_u\\\rho\sigma_u \sigma_v \quad \sigma^2_v \end{array}\right]\right)
        \end{aligned}
        \end{aligned}
        $$

-   [Model]{.underline}

    ``` r
    model.b <- lmer(na ~ large + (large | id), data = music)
    ##  Groups  Name        Variance Std.Dev. Corr 
    ##  id      (Intercept)  6.333  2.517         
    ##          large        0.743  0.862    -0.76
    ##  Residual            21.771  4.666
    ##  Number of Level Two groups =  37
    ##            Estimate Std. Error t value
    ## (Intercept)  16.730    0.4908  34.09
    ## large        -1.676    0.5425  -3.09
    ```

-   [Interpretation]{.underline}

    -   $\hat \alpha_0 = 16.7$ --- The mean [performance anxiety]{.var-text} level (outcome) before solos and small ensemble performances ([large = 0]{.var-text}).
    -   $\hat \beta_0 = −1.7$ --- The mean decrease in [performance anxiety]{.var-text} (outcome) before large ensemble performances ([large = 1]{.var-text}).
        -   Subjects had a [performance anxiety]{.var-text} level of 16.7 before solos and small ensembles, and their anxiety levels were 1.7 points lower, on average, before large ensembles, producing an average [performance anxiety]{.var-text} level before large ensembles of 15.0
        -   Statistically significant since \|t-value\| \> 2
    -   $\hat \sigma^2 = 21.8$ --- The variance in within-person deviations.
    -   $\hat \sigma^2_u = 6.3$ --- The variance in between-person deviations in [performance anxiety]{.var-text} scores (outcome) before solos and small ensembles ([large = 0]{.var-text}).
    -   $\hat \sigma^2_v = 0.7$ --- The variance in between-person deviations in increases (or decreases) (slope) in [performance anxiety]{.var-text} scores (outcome) before large ensembles ([large = 1]{.var-text}).
    -   $\hat \rho_{uv} = −0.76$ (Corr column)
        -   Slopes and intercepts are negatively correlated
        -   A strong negative relationship between a subject's [performance anxiety]{.var-text} (outcome) before solos and small ensembles ([large = 0]{.var-text}) (Intercept) and their (typical) decrease in [performance anxiety]{.var-text} (Slope) before large ensembles ([large = 1]{.var-text}) .

-   [Pseudo-R^2^]{.underline} (Not always a reliable performance measure)

    -   Unconditional Means vs Random Intercepts and Slopes

        $$
        \text{Psuedo R}^2_{L1} = \frac{\hat \sigma^2 (\text{Model A}) - \hat\sigma^2(\text{Model B})}{\hat \sigma^2(\text{Model A})} = \frac{22.5 - 21.8}{22.5} = 0.031
        $$

        -   Where Model A: [Unconditional Means](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-ri){style="color: green"}; Model B: Random intercepts and slopes
        -   FYI
            -   $\text{percent decrease} = \frac{\text{original value} - \text{new value}}{\text{orginal value}}$
                -   pseudo-R^2^ uses this one
                -   If negative, it's a percent increase.
            -   $\text{percent increase} = \frac{\text{new value} - \text{original value}}{\text{original value}}$
                -   If negative, it's a percent decrease.

    -   Positive value means Model B is an improvement over Model A

        -   Means the variance in Model B's error terms is smaller than Model A's, and therefore better fits the data. (I think)

    -   The estimated within-person variance $\hat \sigma^2$ decreased by 3.1% (from 22.5 to 21.8) from the unconditional means model

    -   Implies that only 3.1% of within-person variability in [performance anxiety]{.var-text} scores can be explained by performance type

    -   Values of $\hat \sigma^2_u$ and $\hat \sigma^2_v$ from Model B cannot be compared to between-person variability from Model A using pseudo-R^2^, since the inclusion of performance type has changed the interpretation of these values

    -   Issues

        -   "Because of the complexity of estimating fixed effects and variance components at various levels of a multilevel model, it is not unusual to encounter situations in which covariates in a Level Two equation for the intercept (for example) remain constant (while other aspects of the model change), yet the associated pseudo R-squared values differ or are negative." (?)

#### Random Slopes and Intercepts Model (with 2 covariates) {#sec-econ-me-freq-bmlrch8-mbwkfw-rsi2 .unnumbered}

-   1 - Level 1; 1 - Level 2

-   Specification, Model, Interpretation (see [Multi-Level](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-multlev){style="color: green"} section above)

    -   Says the [large]{.var-text} effect (slope) varies across subjects/units

-   Pseudo-R^2^

    $$
    \begin{align}
    \text{Psuedo R}^2_{L2_u} &= \frac{\hat \sigma^2_u (\text{Model B}) - \hat\sigma^2_u(\text{Model C})}{\hat \sigma^2_u(\text{Model B})} = \frac{6.33 - 5.66}{6.33} = 0.106 \\
    \text{Psuedo R}^2_{L2_v} &= \frac{\hat \sigma^2_v (\text{Model A}) - \hat\sigma^2_v(\text{Model B})}{\hat \sigma^2_v(\text{Model A})} = \frac{0.74 - 0.45}{0.74} = 0.392
    \end{align}
    $$

    -   Model B is [Random Slopes and Intercepts Model (with 1 covariate)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi1){style="color: green"}

    -   Model C is Random Slopes and Intercepts Model (with 2 covariates)

    -   The addition of Level 2 variable, [orch]{.var-text}, in Model C:

        -   (Top) Decreased the between-person variability in *mean* (intercept) [performance anxiety]{.var-text} (outcome) before solos and small ensembles ([large = 0]{.var-text}) by 10.6%
        -   (Bottom) Decreased the between-person variability in the *effect* (slope) of large ensembles ([large = 1]{.var-text}) on [performance anxiety]{.var-text} (outcome) by 39.2%

#### Random Intercepts (with 2 covariates) {#sec-econ-me-freq-bmlrch8-mbwkfw-ri2 .unnumbered}

-   1 - Level 1; 1 - Level 2

-   Instead of assuming that the large ensemble ([large]{.var-text}) effects, after accounting for instrument played ([orch]{.var-text}), vary by individual, we are assuming that large ensemble effect is fixed across subjects.

-   [Specification]{.underline}

    -   Level 1: $Y_{ij} = a_i + b_i \text{large}_{ij} + \epsilon_{ij}$

    -   Level 2

        $$
        \begin{align}
        &a_i = \alpha_0 + \alpha_1 \text{orch}_i + u_i\\
        &b_i = \beta_0 + \beta_1 \text{orch}_i \\
        &\text{where}\: \epsilon \sim \mathcal{N}(0, \sigma^2)\: \text{and} \: u_i \sim \mathcal{N}(0, \sigma^2_u)
        \end{align}
        $$

        -   Only difference is the random effect/error term, $v_i$, isn't specified

    -   Composite

        -   Not given, but probably very similar to the previous model just without $v_i$

-   [Model]{.underline}

    ``` r
    model.c2 <- lmer(na ~ orch + large + orch:large + (1|id), data = music)
    ##  Groups  Name        Variance Std.Dev.
    ##  id      (Intercept)  5.13    2.27   
    ##  Residual            21.88    4.68
    ##  Number of Level Two groups =  37
    ##            Estimate Std. Error t value
    ## (Intercept)  15.9026    0.6187  25.703
    ## orch          1.7100    0.9131   1.873
    ## large        -0.8918    0.8415  -1.060
    ## orch:large   -1.4650    1.0880  -1.347
    ```

-   [Interpretation]{.underline}

    -   Same as previous model except there's no between-units variation estimate for the slope (see [previous model](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi2){style="color: green"} and [multi-level model section](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-multlev){style="color: green"})
    -   Estimates are similar to the previous model's. Largest difference seems to be the between-unit variation for the Intercept (5.66 vs 5.13)

-   [Comparison]{.underline}

    ``` r
            df  AIC
    model.c  8 3003
    model.c2 6 2999
            df  BIC
    model.c  8 3037
    model.c2 6 3025
    ```

    -   [Model C]{.arg-text} is the [previous model](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi2){style="color: green"} and [Model C2]{.arg-text} is this model
    -   Both criterion pick this model to predict best
    -   The more complex model (e.g. varying intercepts *and* varying slopes) doesn't always perform best

#### Random Slopes and Intercepts Model (with 3 covariates) {#sec-econ-me-freq-bmlrch8-mbwkfw-rsi3 .unnumbered}

-   1 - Level 1; 2 - Level 2

-   [MPQnem]{.var-text} has been centered (mean = 31.63)

    -   Otherwise some interpretations would involve [MPQnem = 0]{.var-text} when the minimum score is 11 which would make the interpretation nonsensical

-   [Specification]{.underline}

    -   Level 1: $Y_{ij} = a_i + b_i \text{large}_{ij} + \epsilon_{ij}$

    -   Level 2

        $$
        \begin{align}
        a_i = \alpha_0 + \alpha_1 \text{orch}_i + \alpha_2 \text{MPQnem}_i + u_i \\
        b_i = \beta_0 + \beta_1 \text{orch}_i + \beta_2 \text{MPQnem}_i + v_i
        \end{align}
        $$

    -   Composite

        $$
        Y_{ij} = [\alpha_0 + \alpha_1 \text{orch}_i + \alpha_2 \text{mpqnem}_i + \beta_0 \text{large}_{ij} + \beta_1 \text{orch}_i \text{large}_{ij} + \beta_2 \text{mpqnem}_i \text{large}_{ij}] + [u_i + v_i \text{large}_{ij} + \epsilon_{ij}]
        $$

-   [Model]{.underline}

    ``` r
    model.d <- lmer(na ~ orch + mpqnem + large +
                        orch:large + mpqnem:large +
                        (large | id),
                        data = music)
    ##  Groups  Name        Variance Std.Dev. Corr 
    ##  id      (Intercept)  3.286  1.813         
    ##          large        0.557  0.746    -0.38
    ##  Residual            21.811  4.670
    ##  Number of Level Two groups =  37
    ##               Estimate Std. Error t value
    ## (Intercept)   16.25679    0.54756 29.6893
    ## orch           1.00069    0.81713  1.2246
    ## cmpqnem        0.14823    0.03808  3.8925
    ## large         -1.23484    0.84320 -1.4645
    ## orch:large    -0.94927    1.10620 -0.8581
    ## cmpqnem:large -0.03018    0.05246 -0.5753
    ```

-   [Interpretation]{.underline}

    -   Compared to [Random Slopes and Intercepts Model (with 2 covariates)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi2){style="color: green"}:
        -   Directions of the effects of instrument ([orch]{.var-text}) and performance type ([large]{.var-text}) are consistent
        -   Effect sizes and levels of significance are reduced because of the relative importance of the negative emotionality ([mpqnem]{.var-text}) term
    -   $\alpha_0 = 16.26$ --- The estimated mean [performance anxiety]{.var-text} (outcome) for solos and small ensembles ([large = 0]{.var-text}) is 16.26 for keyboard players and vocalists (orch=0) with an average level of negative emotionality at baseline ([mpqnem = 31.63]{.var-text})
    -   $\hat \alpha_1 = 1.00$ --- Orchestral instrument ([orch = 1]{.var-text}) players have an estimated mean [performance anxiety]{.var-text} (outcome) level before solos and small ensembles ([large = 0]{.var-text}) which is 1.00 point higher than keyboardists and vocalists ([orch = 0]{.var-text}), controlling for the effects of baseline negative emotionality.
    -   $\hat \sigma^2 = 0.15$ --- A one point increase in baseline negative emotionality ([mpqnem = 0]{.var-text}) is associated with an estimated 0.15 mean increase in [performance anxiety]{.var-text} (outcome) levels before solos and small ensembles ([large = 0]{.var-text}), after controlling for instrument ([orch]{.var-text}).
    -   $\hat \beta_0 = −1.23$ --- Keyboard players and vocalists ([orch = 0]{.var-text}) with an average level of baseline negative emotionality levels ([mpqnem = 31.63]{.var-text}) have an estimated mean decrease in [performance anxiety]{.var-text} level (outcome) of 1.23 points before large ensemble performances ([large = 1]{.var-text}) compared to other performance types ([large = 0]{.var-text}).
        -   See [multi-level](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-multlev){style="color: green"}\>\> interpretation for explainer on the interaction slope interpretations
    -   $\hat \beta_1 = −0.95$ --- After accounting for baseline negative emotionality ([mpqnem = 0]{.var-text}), orchestral instrument players ([orch = 1]{.var-text}) have an estimated mean [performance anxiety]{.var-text} level (outcome) before solos and small ensembles ([large = 0]{.var-text}) which is 1.00 point higher than keyboardists and vocalists ([orch = 0]{.var-text}), while the mean [performance anxiety]{.var-text} (outcome) of orchestral players ([orch = 1]{.var-text}) is only .05 points higher before large ensembles ([large = 1]{.var-text}) (a difference of .95 points).
        -   See [multi-level](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-multlev){style="color: green"} \>\> interpretation for explainer on the interaction slope interpretations
    -   $\hat \beta_2 = −0.03$ --- After accounting for instrument, a one-point increase in baseline negative emotionality is associated with an estimated 0.15 mean increase in [performance anxiety]{.var-text} levels before solos and small ensembles, but only an estimated 0.12 increase before large ensembles (a difference of .03 points).

-   [LR-Test for comparing nested models]{.underline}

    ``` r
    drop_in_dev <- anova(model.d, model.c, test = "Chisq")
    #>         npar  AIC  BIC logLik  dev Chisq Df      pval
    #> model.c    8 3007 3041  -1496 2991    NA NA        NA
    #> model.d   10 2996 3039  -1488 2976 14.73  2 0.0006319
    ```

    -   MLE must be used instead of REML to estimate the parameters of each model
    -   [model.d]{.arg-text} is the current and more complex model, Random Slopes and Intercepts Model (with 3 covariates)
    -   [model.c]{.arg-text} is the less complex model, [Random Slopes and Intercepts Model (with 2 covariates)](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-mbwkfw-rsi2){style="color: green"}
    -   Process
        -   The likelihood is larger (and the log-likelihood is less negative) under the larger model (Model D);
        -   $\text{Chisq} = 14.734 = -2 \cdot (-1488 - (-1496))$
        -   Using dof = 2, signifying the number of additional terms in Model D, we obtain a p-value of .0006.
    -   A p-value \< 0.05 indicates the difference in log-likelihoods is significantly different from 0, and therefore the more complex model, model.d, fits the data better.
    -   Note: dropping the [mpqnem:large]{.var-text} term which has a t-stat \< \|2\| (-0.5753) produces a better model than model.d according the LR-test

#### Final Model {#sec-econ-me-freq-bmlrch8-mbwkfw-finmod .unnumbered}

-   [Description]{.underline}

    -   One of other valid final models
    -   Performance type categorical is no longer collapsed into the binary "large" ensemble/not large and is has now been collapsed into the binary, [solo]{.var-text}, [not solo]{.var-text}
    -   Audience categorical has been transformed to dummies: [students]{.var-text}, [juried]{.var-text}, [public]{.var-text} with [instructor]{.var-text} as the reference category.
    -   Varying/random slopes for [previous]{.var-text}, [students]{.var-text}, [juried]{.var-text}, [public]{.var-text}, and [solo]{.var-text}
    -   [mpqnem]{.var-text} is in the [solo]{.var-text} level 2 equation, so the combined model has an interaction between the two in the fixed effects.

-   [Specification]{.underline}

    -   Level 1: $Y_{ij} = a_i + b_i \text{previous}_{ij} + c_i \text{students}_{ij} + d_i \text{juried}_{ij} + e_i \text{public}_{ij} + f_i \text{solo}_{ij} + \epsilon_{ij}$

    -   Level 2

        $$
        \begin{align}
        a_i &= \alpha_0 + \alpha_1 \text{mpqpem}_i + \alpha_2 \text{mpqab}_i + \alpha_3 \text{orch}_i + \alpha_4 \text{mpqnem}_i + u_i \\
        b_i &= \beta_0 + v_i \\
        c_i &= \gamma_0 + w_i \\
        d_i &= \delta_0 + x_i \\
        e_i &= \epsilon_0 + y_i \\
        f_i &= \zeta_0 + \zeta_1 \text{mpqnem}_i + z_i
        \end{align}
        $$

        -   Variance-Covariance matrix

            $$
            \left[\begin{array}{cc} u_i\\v_i\\w_i\\x_i\\y_i\\z_i \end{array} \right] 
            \sim \mathcal{N} \left(
            \left[\begin{array}{cc} 0\\0\\0\\0\\0\\0\end{array} \right],
            \begin{bmatrix}
            \sigma_u^2 \\
            \sigma_{uv} & \sigma_v^2 \\
            \sigma_{uw} & \sigma_{vw} & \sigma^2_w \\
            \sigma_{ux} & \sigma_{vx} & \sigma_{wx} & \sigma_x^2 \\
            \sigma_{uy} & \sigma_{vy} & \sigma_{wy} & \sigma_{xy} & \sigma_{y}^2 \\
            \sigma_{uz} & \sigma_{vz} & \sigma_{wz} & \sigma_{xz} & \sigma_{yz} & \sigma_z^2
            \end{bmatrix}
            \right)  
            $$

        -   6 variance terms and 15 correlation terms at Level Two, along with 1 variance term at Level One.

            -   The number of correlation terms is equal to the number of unique pairs among Level Two random effects

-   [Model]{.underline}

    ``` r
    # Model F (One - of many - reasonable final models)
    model.f <- lmer(na ~ previous + students + juried + 
        public + solo + mpqpem + mpqab + orch + mpqnem + 
        mpqnem:solo + (previous + students + juried + 
        public + solo | id), REML = T, data = music)

    ##  Groups  Name        Variance Std.Dev. Corr       
    ##  id      (Intercept) 14.4802  3.805               
    ##          previous     0.0707  0.266    -0.65     
    ##          students     8.2151  2.866    -0.63  0.00
    ##          juried      18.3177  4.280    -0.64 -0.12
    ##          public      12.8094  3.579    -0.83  0.33
    ##          solo         0.7665  0.876    -0.67  0.47
    ##  Residual            15.2844  3.910     
    ##             
    ##  0.84           
    ##  0.66  0.58     
    ##  0.49  0.21  0.90
    ## 
    ##  Number of Level Two groups =  37
    ##            Estimate Std. Error t value
    ## (Intercept)  8.36883    1.91369  4.3731
    ## previous    -0.14303    0.06247 -2.2895
    ## students     3.61115    0.76796  4.7022
    ## juried       4.07332    1.03130  3.9497
    ## public       3.06453    0.89274  3.4327
    ## solo         0.51647    1.39635  0.3699
    ## mpqpem      -0.08312    0.02408 -3.4524
    ## mpqab        0.20377    0.04740  4.2986
    ## orch         1.53138    0.58384  2.6230
    ## mpqnem       0.11465    0.03591  3.1930
    ## solo:mpqnem  0.08296    0.04158  1.9951
    ```

-   [Interpretation]{.underline}

    -   In general
        -   [Performance anxiety]{.var-text} (outcome) is higher when a musician is performing in front of students, a jury, or the general public rather than their instructor
            -   [students]{.var-text}, [juried]{.var-text}, and [public]{.var-text} are indicator variables created from the [audience]{.var-text} categorical variable (so that "Instructor" is the reference level in this model)
        -   [Performance anxiety]{.var-text} (outcome) is lower for each additional diary the musician previously filled out
            -   [previous]{.var-text} is the number of previous diary entries filled out by that individual
        -   Musicians with lower levels of positive emotionality ([mpqpem]{.var-text}) and higher levels of absorption ([mpqab]{.var-text}) tend to experience greater [performance anxiety]{.var-text} (outcome)
        -   Those who play orchestral instruments experience ([orch = 1]{.var-text}) more [performance anxiety]{.var-text} than those who play keyboards or sing ([orch = 0]{.var-text})
    -   Key terms
        -   $\hat \alpha_4 = 0.11$ ([mpqnem]{.var-text}, fixed) --- A one-point increase in baseline level of negative emotionality ([mpqnem]{.var-text}) is associated with an estimated 0.11 mean increase in [performance anxiety]{.var-text} (outcome) for musicians performing in an ensemble group ([solo=0]{.var-text}), after controlling for previous diary entries ([previous]{.var-text}), [audience]{.var-text} (dummy vars), positive emotionality ([mpqpem]{.var-text}), absorption ([mpqab]{.var-text}), and instrument ([orch]{.var-text}).
        -   $\hat \zeta_1 = 0.08$ ([solo:mpqnem]{.var-text}, fixed) --- When musicians play solos ([solo = 1]{.var-text}), a one-point increase in baseline level of negative emotionality ([mpqnem]{.var-text}) is associated with an estimated 0.19 mean increase in [performance anxiety]{.var-text} (outcome), 0.08 points (73%) higher than musicians playing in ensemble groups ([solo = 0]{.var-text}), controlling for the effects of previous diary entries ([previous]{.var-text}), [audience]{.var-text} (dummy vars), positive emotionality ([mpqpem]{.var-text}), absorption ([mpqab]{.var-text}), and instrument ([orch]{.var-text}).
            -   See [multi-level](econometrics-mixed-effects-frequentist.qmd#sec-econ-me-freq-bmlrch8-multlev){style="color: green"} \>\> interpretation for explainer on the interaction slope interpretations
    -   Addressing the researchers' primary hypothesis:
        -   After controlling for all these factors, we have significant evidence that musicians with higher levels of negative emotionality ([mpqpem]{.var-text}) experience higher levels of [performance anxiety]{.var-text} (outcome), and that this association is even more pronounced (interaction) when musicians are performing solos ([solo = 1]{.var-text}) rather than as part of an ensemble group ([solo = 0]{.var-text}).

## BMLR Chapter 9: Longitudinal Data {#sec-econ-me-freq-bmlrch9 .unnumbered}

-   Beyond Multiple Linear Regression, [Chapter 9](https://bookdown.org/roback/bookdown-BeyondMLR/ch-lon.html): Two-Level Longitudinal Data
-   Research Questions
    -   Which factors most influence a school's performance in Minnesota Comprehensive Assessment (MCA) testing?
    -   How do the average math MCA-II scores for 6th graders enrolled in charter schools differ from scores for students who attend non-charter public schools? Do these differences persist after accounting for differences in student populations?
    -   Are there differences in yearly improvement between charter and non-charter public schools?
-   Data Answers
    -   Within school---changes over time
    -   Between schools---effects of school-specific covariates (charter or non-charter, urban or rural, percent free and reduced lunch, percent special education, and percent non-white) on 2008 math scores and rate of change between 2008 and 2010.
-   Misc
    -   Missing data is a common phenomenon in longitudinal studies
