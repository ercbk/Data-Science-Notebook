[
  {
    "objectID": "qmd/causal-inference.html",
    "href": "qmd/causal-inference.html",
    "title": "Causal Inference",
    "section": "",
    "text": "Misc",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-misc",
    "href": "qmd/causal-inference.html#sec-causinf-misc",
    "title": "Causal Inference",
    "section": "",
    "text": "Notes from\n\nhttps://fabiandablander.com/r/Causal-Inference.html\n\nStatistical models measure associations (e.g. linear, non-linear) which is mutual information among the variables\n\ne.g. wind and leaves moving in a tree (doesn’t answer whether the leaves moving creates the wind or the wind creates leaving moving)\n\nCausal inference predicts the conseqences after an intervention (i.e. action)\n\nYou must know the direction of causation in order to predict the conseqences of an intervention (unlike measuring associations)\nAnswers the question, “What happens if I do this?”\n\nCausal inference is able to reconstruct unobserved counterfactual outcomes.\n\nAnswers the question, “What happens if I had done something else?”\n\nCausal assumptions are necessary in order to make causal inferences\n\nmultiple regression does not distinguish causes from confounds\np-values are not causal statements\n\nDesigned to control type I error rate\n\nAIC, etc are purely predictive\n\nCausal Experiment Assumptions\n\nsee tlverse workshop notes and ebook for listing of assumptions and definitions,  https://tlverse.org/acic2019-workshop/intro.html#identifiability\n\nThe tlverse Project seeks to use ML models to calculate causal effects. Uses Super Learner ensembling and Targeted Maximum Likelihood Estimation (TMLE) which they call Targeted Learning.\n\nIgnorability - By randomly assigning treatment, researchers can ensure that the potential outcomes are independent of treatment assignment, so that the average difference in outcomes between the two groups can only be attributable to treatment\n\nEngineering outcome variables using potential adjustment variables does not automatically adjust for those variables in your model\n\nNotes from There Are No Magic Outcome Variables\nExample\n\n\nP is population density\nX is the variable of interest\nGDP and P have been used to create GDP/P\nP influences X and provides a backdoor path to GDP/P, so P must be adjusted for\nEven if P doesn’t influence X, the point is that constructing GDP/P using P doens’t automatically adjust for P\n\n\nRandomized experiments remove all paths from the treatment variable, X\n\n\nAdjusting for Z, B, and C can add precision to measurement of the treatment effect since they are causal to Y, but they aren’t necessary to get an unbiased estimate of the treatment effect.\n\nTable 2 fallacy (Notes from McElreath video, 2022 SR Lecture 6)\n\n\nThe 2nd table presented in a paper is usually a summary of all the effects of a regression. The fallacy is that the coefficient of each variable is treated as causal.\nExample: The effect of HIV on Stroke\n\nThe model is lm(Stroke ~ HIV + Smoke + Age)\n\nOnly the coefficient of the HIV variable should be treated as causal and none of the other adjustment variables (Smoke, Age)\n\nThe effects for Smoke and Age are only partial.\nThere are likely unobserved confounding variables, U, on the effect of Smoking on Stroke (e.g. other lifestyle variables).\n\nSmoke is confounded so it’s causal estimate is biased\nAge is also confounded since Smoke is now a collider and has been conditioned upon. This opens the non-causal path, Age-Smoke-U-Stroke.\n\nAge-Smoke is frontdoor, but the backdoor path, Smoke-U, also becomes a backdoor path for Age once Smoke is conditioned upon. (aka sub-backdoor path)\nSo any open path that contains a backdoor path must also be closed\n\n\n\nSolutions\n\nDon’t include effect estimates of adjustment variables\nExplicitly interpret each effect estimate according to the causal model\n\nSee 2022 SR at the end of Lecture 6 where McElreath breaks down the interpretation of each adjustment variable estimated effect.\n\n\n\nPartial Identification (Handling Unobserved Confounds)\n\nMisc\n\nAlso see\n\nPaper: Hidden yet quantifiable: A lower bound for confounding strength using randomized trials (code)\n\nUsing RCT results and Observational data, this paper proposes a statistical test and a method for determining the lower bound confounder strength.\nIn the context of pharmacuticals, RCT results are evidently often released after FDA approval, but this method can be used in any field where there’s a combination of RCT and observational studies..\n\n\n\nSometimes the confounding paths of a DAG model can be not be resolved.\n\nFor confounders that influence the treatment and outcome, see:\n\nStructural Causal Models &gt;&gt; Bayesian examples\nIf there’s a mediator, see Other Articles &gt;&gt; Frontdoor Adjustment\n\nMeasure proxies for the unobserved confound if it’s not practical/ethical to measure\n\ni.e. If the confound is ability, then test scores, letters of recommendation, etc. could be proxies.\n\nExample: 2022 SR Lecture 10 video, code\n\n\nA: Admitted to Grad School, G: Gender, D: Dept, u: Ability, T1,2,3: 3 Test Scores\n\nAbility is latent variable/unobserved confounder\nTest Scores are proxies for Ability\n\nBoth models are fit simultaneously\nCouldn’t find a way to use {brms} to code this and Kurz didn’t included it in his brms SR book.\n\n\n\nA biased estimate is better than no estimate. It can provide an upper bound\nFind a natural experiment or design one\nSensitivity Analysis\n\nAfter the analyis, you should be able to make the statement, “In order for the confound to be responsible for the entire causal effect, it was have to be .”\n\n\nPackages\n\n{tipr} - tools for tipping point sensitivity analyses\n\nSteps for using sensitivity analysis\n\nPerform a sensitivity analysis to determine plausibly how much of the causal effect is due to confounding paths\n\nAssume the confound exists, model it’s consequences for different strengths/kinds of influence\nExample: 2022 SR Lecture 10 video, code \n\nA: Admitted to Grad School, G: Gender, D: Dept, u: Unobserved Confounder\nBoth models are fit simultaneously\nValues for β and γ are specified and u is estimated as a parameter\nI think Gender (G) is an interaction in both models which I didn’t think was possible given there are no arrows of influence from gender to u.\n\nSince gender is a moderator it wouldn’t necessarily have to be an influence arrow, it would only need to be an arrow from G to the effect of u on D (see Moderator Analysis), so maybe this is kosher\nCould also be that I’m misunderstanding McElreath’s code he uses to specify his models with {Rethinking}.\n\nCouldn’t find a way to use {brms} to code this and Kurz didn’t included it in his brms SR book.\n\n\nUse previous studies that have effect strengths of those potential confounding variables\nCompare the strengths from the previous studies to the strength determined from the sensitivity analysis. The difference is a good guess for the strength of the causal effect of your treatment variable.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-causdes",
    "href": "qmd/causal-inference.html#sec-causinf-causdes",
    "title": "Causal Inference",
    "section": "Causal Design",
    "text": "Causal Design\n\nNotes from McElreath video\nMisc\n\nWhen trying to determine the relationship (e.g. linear, nonlinear) between variables and remove inconsequential variables, the Double Debiased ML procedure might be useful.\n\nDouble Debiased Machine Learning - basic concepts, links to papers, videos\nEconML (Microsoft) and causalml (Uber) has included the method in their libraries\n\n\nWhen trying to infer causal relationships, we should not blindly enter all variables into a regression in order to “control” for them, but think carefully about what the underlying causal DAG could look like. Otherwise, we might induce spurious associations (e.g. confounding such as collider bias).\nOverview\n\nMake a causal model (i.e. DAG)\n\nNeed background information in order to make the causal assumptions represented in the DAG\nDAGs only show whether or not a variable influences another, not how the influence occurs (e.g. DAGs can’t show interactions between variables or whether the association is non-linear)\n\nUse it to design data collection and statistical procedures\n\nSteps:\n\nDetermine two variables of interest (exposure, outcome) that you want to determine if a causal relationship exists and what effect the exposure has.\nUse domain knowledge or prior scholarship to determine the relevant variable and the likely associations between all variables in data\nCreate the DAG\n\nIdentify the direct causal path between exposure and outcome\nIdentify other explanatory variables and label their directions of influence with each other, the exposure, and the outcome variable\nConsider which variables (especially the exposure and the outcome) have unobserved variables influencing them.\n\nAnalyze the DAG\n\nIdentify colliders and use d-separation to determine conditional independencies\nIdentify additional paths (backdoor paths, sub-backdoor paths) between exposure and outcome\nUse the backdoor criterion to determine the set of variables that need to be adjusted for in order to block all backdoor paths with only the direct causal path remaining open.\nAdd additional adjustment variables that are causal to the outcome variable (but don’t confound the treatment effect) in order to add precision to the estimate of the treatment effect\n\nCreate simulated data that fits the DAG (i.e. a generative model)\nPerform statistical analysis (i.e. SCMs) on the simulated data  to make sure you can measure the causal effect.\nDesign experiment and collect the data\nRun the statistical analysis on the collected data and calculate the average causal effect (ACE) under the assumptions that your DAG and model specifications are correct.\nBased on your results, revise the DAG and SCM as necessary and repeat as necessary\n\nBad Adjustment Variables (Code and more details included in 2022 SR, Lecture 6)\n\nFor all examples, Z is the adjustment variable that’s being considered; X is the treatment and Y is the outcome\n\nIn each scenario, including Z produces a biased estimate of X, so the correct model is Y ~ X.\n\nM-bias\n\n\nZ doesn’t have a direct causal influence on the either X or Y, but when it’s conditioned upon it becomes a collider due to unobserved confounds that have a direct causal influence on X and Y.\nCommon issue in Political Science and network analysis\nExample\n\nY: Health of Person 2\nX: Health of Person 1\nZ: Friendship status\n\nPre-treatment variable (tend to be open to collider paths) since they could be friends before the exposure\n\nU: Hobbies of Person 1\nV: Hobbies of Person 2\n\n\nPost-Treatment Bias\n\n\nZ is a mediator and conditioning upon Z blocks the path from X to Y, but opens the backdoor path through the unobserved confound, U.\nCommon in medical studies  \nExample\n\nY: Lifespan\nX: Win Lottery\nZ: Happiness\nU: Contextual Confounds\n\n\nSelection Bias\n\n\nSame as collider bias\n\nThis version adds an unobserved confounder\n\nExample\n\nY: Income\nX: Education\nZ: Values\nU: Family\n\n\nCase-Control Bias\n\n\nZ is a descendent. Since Z has information about Y, conditioning on it will narrow the variation of Y and distort the measured effect of X.\nAlso see Association &gt;&gt; Single Path DAGs &gt;&gt; Descendent\nExample\n\nY: Occupation\nX: Education\nZ: Income\n\n\nPrecision Parasite\n\n\n2 versions: with and without U\n\nWithout U, conditioning on Z removes variation from X and lessens (but doesn’t bias) the precision of the estimated effect of X on Y (i.e. inflated std.error)\nWith U, the effect of X is biased and that bias is amplified when Z is included.\n\n\nPeer Bias\n\n\nClassic DAG of the Berkley Admission-Race-Department study\nAlso see Structural Causal Models &gt;&gt; Example (Bayesian Peer Bias)\nX is race, E is department, Q is unobserved (e.g. student quality), Y is Admission\nDepartment cannot be conditioned upon because it’s a collider with Q and would bias the estimate of X through a sub-backdoor path, X-E-Q-Y\nOnly the total effect of X on Y can be estimated (Y ~ X) since E cannot be conditioned upon but that’s not interesting and maybe not precise",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-terms",
    "href": "qmd/causal-inference.html#sec-causinf-terms",
    "title": "Causal Inference",
    "section": "Terms",
    "text": "Terms\n\nAverage Causal Efffect (ACE) - average population effect that’s calculated from an intervention (see Counterfactual definition for info on Individual Causal Effects)\n\nIf X is binary, then   is the average causal effect (see Simpson’s Paradox example)\n\nCalculated from a contingency table\n\nAlso, \n\nThis looks like the interpretation of the slope in a regression model.\n\n\nBackdoor Criterion - A valid causal estimate is available if it is possible to condition on variables such that all backdoor paths are closed\n\nGiven two nodes, X and Y, an adjustment set, L, fulfills the backdoor criterion if \n\nno member in L is a descendant of X and\nmembers in L block all backdoor paths (“shutting the backdoor”) between X and Y.\n\nAdjusting for L thus yields the causal effect of X→Y.\nAfter executing an intervention, the conditional distribution in the observational DAG (seeing) will correspond to the interventional distribution (doing) when blocking the spurious path. (see Simpson’s Paradox example)\n\nBackdoor Path - A non-causal path that enters a causal variable in a DAG rather than exits it.\n\ne.g. the path that connects a collider to a causal variable points from the collider to the causal variable\nSub-backdoor Path - this path begins with a frontdoor path but through conditioning on a variable, it opens a connecting backdoor path which biases the treatment effect\n\nsee Misc &gt;&gt; Table 1 Fallacy and Causal Design &gt;&gt; Bad Adjustment Variables &gt;&gt; Peer Bias\n\n\nThe causal effect is the distribution of Y when we change x, averaged over the distributions of the adjustment variables (Z)\nCausal Hierarchy (lowest to highest)\n\nAssociation\n\nassociated action: Seeing - observational; observing the value of Y when X = x\n\n , observational distribution; What values Y would likely take on if X happened to equal x.\n\n\nIntervention\n\nassociated action (do-Calculus): Doing -  experimental; observing the value of Y after setting X = x\n\n , interventional distribution; What values Y would likely take on if X would be set to x.\nUsing the do operator allows us to make inferences about the population but not individuals.\ndo(X) means to cut all of the backdoor paths into X, as if we did a manipulative experiment. The do-operator changes the graph, closing the backdoors.\nThe do-operator defines a causal relationship, because Pr(Y|do(X)) tells us the expected result of manipulating X on Y, given a causal graph.\n\nWe might say that some variable X is a cause of Y when Pr(Y|do(X)) &gt; Pr(Y|do(not-X)).\n\n(makes more sense to me with a binary outcome, Pr(Y = 1|do(X), but maybe Y as a continuous variable can be defined a subset. …I dunno)\n\n\nThe ordinary conditional probability comparison, Pr(Y|X) &gt; Pr(Y|not-X), is not the same. It does not close the backdoor.\nNote that what the do-operator gives you is not just the direct causal effect. It is the total causal effect through all forward paths.\n\nTo get a direct causal effect, you might have to close more backdoors.\n\nThe do-operator can also be used to derive causal inference strategies even when some backdoors cannot be closed.\n\n\nCounterfactual\n\nassociated action: Imagining - what would be the outcome if the alternative would’ve happened.\nIndividual Causal Effects can be calculated but it requires stronger assumptions and deeper understanding of the causal mechanisms\n\nNeed to research this part further.\nIf the underlying SCM is linear then the ICE = ACE.\n\n\n\nA collider along a path blocks that path. However, conditioning on a collider (or any of its descendants) unblocks that path\n\nWhen a collider is conditioned upon, the change in the association between the two nodes it separates is called collider bias.\n\ne.g. if Z is a collider between X and Y, conditioning upon Z will induce an association between X and Y.\n\n\nA conditioning set, \\(L\\), is the set of nodes we condition on (it can be empty).\nConfounding is the situation where a (possibly unobserved) common cause obscures the causal relationship between two or more variables.\n\nThere is more than one causal path between two nodes.\nA causal effect of X on Y is confounded if  \nCollider bias is a type of confounding. When a collider is controlled for, a second (or more) path opens, and the effect is confounded\n\nX and Y are d-separated by [L if conditioning on all members in [L blocks all paths between the nodes, X and Y.\n\nTool for checking the conditional independencies which are visualized in DAGs.\n\nA descendant is a node connected to a parent node by that parent node’s outgoing arrow.\nFrontdoor Adjustment - In a causal chain with three nodes X→Z→Y, we can estimate the effect of X on Y indirectly by combining two distinct quantities: (Useful for when unobserved confounders prevent direct causal estimation)\n\nThe estimate of the effect of X on Z, P(Z|do(X))\nThe estimate of the effect of Z on Y, P(Y|do(Z), X)\n\nFrontdoor Path - a path that exits a causal variable in a DAG rather than enters it.\n\ne.g. the path that connects a causal variable, X, to an outcome variable, Y, has an arrow that points from X to Y.\n\nMarkov Equivalence - A set of DAGs, each with the same conditional independencies\nMediation Analysis - seeks to identify and explain the mechanism or process that underlies an observed relationship between an independent variable and a dependent variable via the inclusion of a third hypothetical variable, known as a mediator variable (z-variable in the DAGs of “pipes” below)\n\nIncluding a mediator and the independent variable in a regression will result in the independent variable not being signficant and the mediator being significant.\n\nModeration Analysis - Like mediation analysis, it allows you to test for the influence of a third variable, Z, on the relationship between variables X and Y, but rather than testing a causal link between these other variables, moderation tests for when or under what conditions an effect occurs.\nA node is a parent of another node if it has an outgoing arrow to that node\nA path from X to Y is a sequence of nodes and edges such that the start and end nodes are X and Y, respectively.\nResidual Confounding occurs when a confounding variable is measured imperfectly or with some error and the adjustment using this imperfect measure does not completely remove the effect of the confounding variable.\n\nExample: Women who smoke during pregnancy have a decreased risk of having a Down syndrome birth.\n\nThis is puzzling, as smoking is not often thought of as a good thing to do. Should we ask women to start smoking during pregnancy?\nIt turns out that there is a relationship between age and smoking during pregnancy, with younger women being more likely to indulge in this bad habit. Younger women are also less likely to give birth to a child with Down syndrome. When you adjust the model relating smoking and Down syndrome for the important covariate of age, then the effect of smoking disappears. But when you make the adjustment using a binary variable (age&lt;35 years, age &gt;=35 years), the protective effect of smoking appears to remain.\n\n\nStructural Causal Models (SCMs) - relate causal and probabilistic statements; each equation is a causal statement\n\n\n\n“:=” is the assignment operator\nX is a direct cause of Y which it influences through the function f( )\n\nwhere f is a statistical model\n\nThe noise variables, ϵX and ϵY, are assumed to be independent.\n\nThere are Stochastic and Deterministic SCMs. Deterministic SCMs presented in article.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-assoc",
    "href": "qmd/causal-inference.html#sec-causinf-assoc",
    "title": "Causal Inference",
    "section": "Association",
    "text": "Association\n\n\n\nFar left: lm(Y ~ X); X and Y show a linear correlation when Z is NOT conditioned upon\nLeft: lm(Y ~ X + Z); X and Y show NO linear correlation when Z is conditioned upon\nRight: lm(Y ~ X); X and Y show NO linear correlation when Z is NOT conditioned upon\nFar Right:  lm(Y ~ X + Z); X and Y show a linear correlation when Z is conditioned upon",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-singpath",
    "href": "qmd/causal-inference.html#sec-causinf-singpath",
    "title": "Causal Inference",
    "section": "Single path DAGs",
    "text": "Single path DAGs\n\n\nFor each of these DAGs, Z would be the only member of the conditioning set.\nThe first 3 DAGs represent the scatter plots above\n\nZ only blocks the path between X and Y when it’s conditioned upon.\n\nX and Y are associated (e.g. linear correlation, mutual information, etc.) when Z is ignored\nConditioning on Z results in X and Y no longer being associated (i.e. conditional independence)\n\nThe first and second DAGs are elemental confounds or relations called “Pipes.”\n\nThe left one\n\nIn general, DO NOT add these variables to your model\n\nThese paths are causal so they shouldn’t be blocked\nIf your goal isn’t causal inference, then adding these variables might provide predictive information\ne.g. If there was a causal arrow from X to Y, the far left DAG would NOT have a backdoor path and therefore Z would not  be conditioned upon to block the path, X-Z-Y\n\nThe path from X to Z is a frontdoor path since the arrow exits X.\n\n\nSometimes you DO condition on these variables\n\nDuring mediation analysis, you condition on these variables as part of the process to determine how much of the effect goes through Z.\nThe mediation path can have an important interpretation depending on your research question\n\ne.g. indirect descrimination\n\nSee Statistical Rethinking &gt;&gt; Chapter 11 &gt;&gt; Conclusion of Berkeley Admissions example\n\nalso Lecture 9 2022 video\n\n\n\n\n\nThe right one is a backdoor path and should be conditioned on.\nEverything you can learn about Y from X (or vice versa) happens through Z, therefore learning about X separately provides no additional information\nZ is traditionally labelled a mediator\n\nThe third DAG is an elemental confound  or relation called a “Fork.”\n\nIn general, add these variables to your model\nThese are backdoor paths and are NOT causal\nX and Y have a common cause in Z and some of the mutual information about Z they each contain, overlaps, and creates an association (when Z isn’t conditioned upon).\n\n\nThe fourth DAG is an elemental confound or relation called a “Collider.”\n\n\nIn general, do NOT add these variables to your model\nZ blocks the path between X and Y unless conditioned upon.\nAn association between X and Y is induced  by conditioning on Z, lm(Y ~ X + Z)\n\nX and Y are independent causes of Z. Z contains information about both X and Y, but X doesn’t contain any information about Y and vice versa.\nA small X and a sufficiently large Y (and vice versa) can produce a Z = 1. So X and Y have compensatory relationship in causing Z.\n\ni.e. For a given value of Z, learning something about X tells us what Y might have been.\n\n\n\nThe last elemental confound or relation is called a “Descendent.”\n\n\nConditioning on a descendent variable, D, is like conditioning on the variable, Z itself, but weaker. A descendent is a variable influenced by another variable.\nControlling for D will also control, to a lesser extent, for Z. The reason is that D has some information about Z. This will (partially) open the path from X to Y, because Z is a collider. The same holds for non-colliders. If you condition on a descendent of Z in the pipe, it’ll still be like (weakly) closing the pipe.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-dualpath",
    "href": "qmd/causal-inference.html#sec-causinf-dualpath",
    "title": "Causal Inference",
    "section": "Dual path DAGs",
    "text": "Dual path DAGs\n\n\nCausal paths do not flow against arrows but associations can.\nTwo examples of DAGs representing confounding\n\nThese are the 2 middle DAGs above with an additional path from X to Y\nIf Z is NOT conditioned on (i.e. top path is not blocked), then the causal effect of X on Y would be confounded.\n\n\n\n\nThe paths from X to Y:\n\nThe path through Z matches the first DAG.\n\nTherefore X and Y are conditionally independent given Z.\n\nThe path through W matches the fourth DAG\n\nTherefore X and Y are conditionally dependent given W.\n\n\nThe path through W (collider) is blocked unless W is conditioned upon\nThe path through Z is open unless Z is conditioned upon\nIf Z and W are conditioned upon, then the path between X and Y is open through W and an association is present.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-interv",
    "href": "qmd/causal-inference.html#sec-causinf-interv",
    "title": "Causal Inference",
    "section": "Intervention",
    "text": "Intervention\n\n\nSince actual interventions are usually unfeasible, we want to be able to determine causality with observational data. This requires two assumptions:\n\nThe intervention occurs locally. Which means that only the variable we target is the one that receives the intervention.\nThe mechanism by which variables interact do not change through interventions; that is, the mechanism by which a cause brings about its effects does not change whether this occurs naturally or by intervention\n\nThe Doing row of DAGs (aka manipulated DAGs) represents setting X = x\n\nFor DAGs 1 and 4, Y is still affected\n\nMoving from seeing to doing didn’t change anything\n\n\nFor DAGs 2 and 3, Y is now UNaffected\n\nUsing the assumptions and some mathematical manipulation (See article for details):\n\n\n\nThus, the interventional distribution we care about is equal to the (observational) conditional distribution of Y given X when we adjust for Z\n\n\n\n\nThe rule: After an intervention, incoming arrows are cut from the node where the intervention took place.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-confound",
    "href": "qmd/causal-inference.html#sec-causinf-confound",
    "title": "Causal Inference",
    "section": "Confounding",
    "text": "Confounding\n\n\nThe backdoor criterion tells us which variable we need to adjust for in order to for our model to yield a causal relationship between two variables (i.e. graphically, nodes)\n\nBlocks all spurious, that is, non-causal paths between X and Y.\nLeaves all directed paths from X to Y unblocked\nCreates no spurious paths\n\nExample\n\nCausal effect of Z on U is confounded by X because in addition to the legitimate causal path Z→Y→W→U, there is also an unblocked path Z←X→W→U which confounds the causal effect\n\nSince X’s arrow enters the causal variable of interest, Z, it’s arrow is a backdoor path and needs to be blocked/closed\nThere are some descendant nodes that make the confounding a little difficult to parse out, but this graph is essentially\n\n\nwhich is the same as the second example DAG for confounding in the Association section\n\n\nThe backdoor criterion would have us condition on X, which blocks the spurious path and renders the causal effect of Z on U unconfounded.\n\nThe reduced, confounding DAG above is the same as the third DAG (without the path from Z to U) in the Association section. Conditioning on Z in that example blocked the path between X and Y, so it makes sense that conditioning on X in the reduced DAG would block the Z to X to U path. And therefore, the Z←X→W→U would also be blocked in the complete DAG.\n\nNote that conditioning on W would also block this spurious path; however, it would also block the causal path, Z→Y→W→U.\n\n\nIf we breakdown the complete DAG into the modular components involving W, we can see these are the same as the first example DAG in the Association section.\nW is also collider for X and Y, but I don’t think that has any bearing when discussing the causal effect of Z on U.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-appsimp",
    "href": "qmd/causal-inference.html#sec-causinf-appsimp",
    "title": "Causal Inference",
    "section": "Application: Simpson’s Paradox Example",
    "text": "Application: Simpson’s Paradox Example\n\nSex as the adjustment variable           \n\nPatients CHOOSE whether or not to take a drug to cure some disease.\nMen choosing to take the drug recover at a higher percentage that those that didn’t\nWomen choosing to take the drug recover at a higher percentage that those that didn’t\nBut overall, those that chose to take the drug recovered at a lower percentage than those that didn’t.\nSo should a doctor prescribe the drug or not?\nSuppose we know that women are more likely to take the drug, that being a woman has an effect on recovery more generally, and that the drug has an effect on recovery. \nCreate DAGs\n\n\nS=1 as being female,\nD=1 as having chosen to take the drug\nR=1 as having recovered\nThe right DAG indicates either forcing everyone to either take the drug or not take the drug\nNotice that   therefore our calculated effect will be confounded.\n\nBackdoor criterion says the manipulated DAG (right) will correspond to the observational DAG (left) if we condition on Sex.\n\n\nUse intervention formula from Intervention section\n\n\nAverage Causal Effect = 0.832 - 0.782 = 0.050. So the drug has a positive effect on average.\n\n\nBlood Pressure as the adjustment variable \n\nBlood Pressure instead of sex is used as the adjustment. Blood Pressure is a post-treatment variable.\nRelatively same observations as before. High or Low Blood Pressure with the drug produces better results than those that chose not to take the drug. Yet overall, those that chose the drug recovered at a lower percentage.\n\nSince Blood Pressure (B) is post-treatment, it has no effect on whether the patient takes the drug or not (D).\nTaking or not taking the drug (D) has an indirect effect on recovery (R) through Blood Pressure (B) along with a direct effect.   so our calculated effect will be unconfounded.\n\nSo with BP as the adjustment variable, the drug now has a small, negative effect (harmful), 0.78 - 0.83 = -0.05\n\nThe unconfounded, average causal effect for the population is negative, therefore the doctor should NOT prescribe the drug.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-scms",
    "href": "qmd/causal-inference.html#sec-causinf-scms",
    "title": "Causal Inference",
    "section": "Structural Causal Models (SCMs)",
    "text": "Structural Causal Models (SCMs)\n\nYou add additional assumptions to your DAG to derive a causal estimator\n“Full Luxury” Bayesian approach\n\n“Full Luxury” is just a term coined by McElreath; it’s just a bayesian model but bayesian models can fully model a DAG where standard regression approachs can fail (see examples)\nNo other approach will find something that the bayesian approach doesn’t\n\nMain disadvantage is that it can be computationally intensive (same with all baysian models)\n\nProvides ways to add “causes” for missingness and measurement error\n\nExample (2 Moms)\n\nNotes from McElreath video\nHypothesis: a mother’s family size is causal to her daughter’s family size\n\nTruth: no relationship\n\nVariables:\n\nM - Mother’s family size (i.e. number of children the birth)\nD - Daughter’s family size\nB1 - Mother’s birth order; binary, first born or not\nB2 - Daughters’ birth order; binary, first born or not\nU - unobserved confounds  (shown as curved dotted line)\n\n\n\nUnobserved confounds (economic status, education, cultural background, etc.) are causal to both Mother and Daughter (curved dotted line) which makes regression, D ~ M, impossible\n\nSee Baysian Two Moms example below for results of a typical regression\nStill possible to calculate the effect of M on D with SCMs\n\n\nAssumptions: Relationships are linear (i.e. linear system)\nCausal Effects\n\n\nWe want m which is the causal effect of M on D\nAssumes causal effect of birth order is the same on mother and daughter\nAside: There is no arrow/coefficient from M to B2 because it’s not germane to the calculation of m\n\nCalculate linear effect (i.e. regression coefficient) without a regression model using a linear system of equations\n\nNote: a regression coefficent, β = cov(X,Y) / var(X)\nWe can’t calculate the covariance of M and D directly because it depends on unobserved confounders but we can calculate the covariance between B1 and D and use that to get m.\nThe covariance for each path is the product of the path coefficients and the variance of the originating causal variable.\nPath B1 → M: cov(B1, M) = b*var(B1)\nPath B1 → D: cov(B1, D) = b*m*var(B1)\n2 equations and 2 unknowns, m and b\nSolve for b in the first equation, substitute b into the second equation, and solve for m\n\nm = cov(B1, D) / cov(B1, M)\n\nStill need an uncertainty of this value (e.g. bootstrap)\n\n\nExample (Bayesian 2 Moms)\n\nSee previous example for link, hypothesis, and definition of the variables\n\nFunctions (right side)\n\nEach variable’s function’s inputs are variables that are causal influences (i.e. have arrows pointing at the particular variable\n\ne.g. M has two arrows pointing at it in the DAG: B1 and u\n\n\nCode\n\nThe assumption is that this is a lineary system, so M and D have Normal distributions for their functions with means as linear regression equations\nB1 and B2 are binary so they get bernoulli distributions\nU gets a standard normal prior\n\nAside: evidently this is a typical prior for latent variables in psychology\n\np, intercepts, sd, k get typical priors for bayesian regressions\n\nResults\n\n\nTruth: no effect\n1st 3 lm models shows how the unobserved confound biases the estimate when using a typical regression model to estimate the causal effect\n\nIncluding B2 adds precision to the biased estimate since it is causal to the outcome D while adding B1 increases the bias\n\nBayesian model isn’t fooled because U is specified as an input to the functions for M and D\n\nInterpretation: There is no reliable estimate of an effect. The most likely effect is a moderately positive one but it could also be negative.\nAdding more simulated data to this example will move the point estimate towards zero\n\n\n\nExample (Bayesian Peer Bias)\n\nAlso see Causal Design &gt;&gt; Bad Adjustment Variables &gt;&gt; Peer Bias\nHypothesis: racial discrimination in acceptance of applicatioon to Berkeley grad schools\n\nTruth: moderate negative effect, -0.8\n\nVariables:\n\nX is race, E is department, Q is an unobserved confound (latent variable: student quality), Y is binary; Admission/No Admission\nR1 and R2 are proxy variables for Q (e.g. test scores, lab work, extracurriculars, etc.)\n\nAssumptions: System is linear\nDAG and Code\n\n\nXX is the race variable with X as the coefficient in the code\n\nThis code uses his {rethinking} package so some of this syntax is unfamiliar\n\nR1 and R2 are shown in the DAG to be influenced by student quality, Q\nEvery prior is normal except for Q’s coefficient\n\nResults\n\n\nTruth: -0.8\n1st 3 glm models shows how the unobserved confound, Q, biases the estimate when using a typical logistic regression model to estimate the causal effect\nBayesian model isn’t fooled because Q is specified as an input to the function for Y\n\nInterpretation: There is a reliably negative effect (no 0 in the CI). The most likely effect is a moderately negative one.\nNot quite equal to the truth but reliably negative and the point estimate is closer than the glms\n\n\n\nExample\n\nAssumptions: Relationships between variables are linear and error terms are independent\nEquations\n\n,  \n\n\nDAG 1 (left) shows the association DAG which represents the SCM\nmanipulated DAG 1 (middle) shows intervention where z is set to a constant\n\nincoming causal arrows get cutoff the intervening variable\n\nmanipulated DAG 1 (right) shows intervention where x is set to a constant\n\nSimulation of the SCM (n = 1000) (code in article)\n\n\nZ is more predictive of Y than X\n\nSimulate interventions (code in article)\n\n\nLeft - histogram of SCM for Y without an intervention\nMiddle - Intervention on Z\n\nconfirms the DAG which shows no effect on Y and Z is not causal\n\nRight - intervention on X\n\nconfirms the DAG which shows an intervention on X produces an effect on Y and X is causal\n\nAverage Causal Effect (ACE) can be determined by subtracting the expected values of interventions where  X = x +1 and  X = x",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-ctrfact",
    "href": "qmd/causal-inference.html#sec-causinf-ctrfact",
    "title": "Causal Inference",
    "section": "Counterfactuals",
    "text": "Counterfactuals\n\nExample(code in article): Test whether Grandma’s home remedy can speed recovery time for the common cold\n\nSCM\n\n\nT is 1/0, i.e. whether patient receives Grandma’s treatment, with p = 0.5; \nR is recovery time\nμ is the intercept\nβ is the average causal effect, since\n\n\nwhere \n\n\nFrom fitting the model, we find μ = 7, β = -2, Τ = 0, ε1 = 0.78\n\nTherefore, the Individual Causal Effect for patient 1\n\n\nJust plug and chug where we substitute T = 1 into the SCM and we already have the T = 0 part from the model\n\n\nIn this case, the SCM is linear, so the ICE = ACE.",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-medanal",
    "href": "qmd/causal-inference.html#sec-causinf-medanal",
    "title": "Causal Inference",
    "section": "Mediation Analysis",
    "text": "Mediation Analysis\n\n\nFigure\n\nc’ is the direct effect of X on the outcome after the indirect path has been removed (i.e. conditioned upon, outcome ~ X + mediator)\nc is the to total effect (outcome ~ X)\nc - c’ equals the indirect effect\nSee definitions below\n\nAllows you to test for the influence of a third variable, the mediator, on the relationship between (i.e. effect of) the treatment variable, X, and the Outcome variable, Y.\nMisc\n\nNotes from: Mediation Models\n\nOverview of packages (Aug 2020)\n\n{brms} very flexible in terms of models. You’ll just have to calculate the effects by hand unless some outside package (e.g. sjstats) takes a brms model and does it for you.\n\nSee below for formulas. {mediation} papers should have other formulas for other types of models (e.g. poisson, binomial)\n\n{mediation} handles a lot for you. Method isn’t bayesian but is very similar to it in a frequentist-bootstrappy-simulation way.\n\nPackage has been substantially updated since that article was written.\n\n\nAlso see\n\nOther Articles &gt;&gt; Frontdoor Adjustment\nStatistical Rethinking &gt;&gt; Chapter 11 &gt;&gt; Conclusion of Berkeley Admissions example\n\nalso Lecture 9 2022 video\n\nebook (w/brms) Introduction to Mediation, Moderation, and Conditional Process Analysis\n\nIncluding a mediator and the independent variable in a regression will result in the independent variable not being signficant and the mediator being significant.\n\nExample: Causal effect of education on income\n\nSay occupation is your mediator. Education has a big impact on your occupation, which in turn has a big impact on your income. You don’t want to control for a mediator if you are interested in the full effect of X on Y! Because a huge part of how X impacts on Y is precisely through the mediation of C, in our case choice of and access to occupation, given a certain level of education. If you ‘control’ for occupation you will be greatly underestimating the importance of education.\n\n\nWhen would you want to only measure the Direct Effect?\n\nExample: Determining the amount of remuneration for discrimination\n\nFrom Simulating confounders, colliders and mediators\nVariables\n\nOutcome: Pay Gap\nTreatment: Gender\n\nIn this case, this variable is actually “gender discrimination in the current workplace in making a pay decision” (for which we use actual, observed Gender as a proxy)\n\nMediators: Occupation and Experience\n\nWhen determining whether a type of descrimination exists, you don’t want to condtion on the mediators, because the effect of gender will be underestimated. So, you’d want the total effect. But here, discrimation is already determined and Gender is now a proxy variable. Under Gender’s new definition, Occupation and Experience might influence the amount of “gender discrimiation,” so they can’t be definitively labelled mediators any more.\nSo if you want to estimate that final “equal pay for equal work” step of the chain then yes it is legitimate to control for occupation and experience.\n\n\nShould always compare a mediation model to a model without mediation\n\nAn unnecessary mediation model will almost certainly be weaker and probably more confusing than the model you would otherwise have.\n\nAverage Causal Mediation Effect (ACME) (aka Indirect Effect)- the expected difference in the potential outcome when the mediator took the value that it would have under the treatment condition as opposed to the control condition, while the treatment status itself is held constant.\n\nIf this isn’t significant, there isn’t a mediation effect\nIt is possible that the ACME takes different values depending on the baseline treatment status. Shown by analyzing the interaction between the treatment variable and the mediator\nδ(t) = E[Y (t, M(t1)) − Y (t, M(t0))]\n\nwhere\n\nt, t1, t0 are particular values of the treatment T such that t1 ≠ t0,\nM(t) is the potential mediator\nY (t, m) is the potential outcome variable\n\n\n\nAverage Direct Effect (ADE) - the expected difference in the potential outcome when the treatment is changed but the mediator is held constant at the value that it would have if the treatment equals t.\n\nζ(t) = E[Y (t1, M(t)) − Y (t0, M(t))]\n\nThe Total Effect of the treatment on the outcome is ACME + ADE.\n\nConditions where you likely do NOT need mediation analysis :\n\nIf you cannot think of your model in temporal or physical terms, such that X necessarily leads to the mediator, which then necessarily leads to the outcome.\nIf you could see the arrows going either direction.\nIf when describing your model, everyone thinks you’re talking about an interaction (a.k.a. moderation).\nIf there is NO strong correlation between key variables (variables of interest) and mediator, and if there is NO strong correlation between mediator and the outcome.\n\nSobel test - tests whether the suspected mediator’s influence on the independent variable is significant.\n\nPerforming the test in R via bda::mediation.test - article\n\nMethods\n\nBaron & Kenny’s (1986) 4-step indirect effect method has low power\nProduct-of-Paths (or difference in coefficients)\n\nc - c’ = a*b (see figure at start of this section) where c - c’ is the indirect effect (aka ACME)\n\nif either a or b are nearly zero, then the indirect effect can only be nearly zero\nFormula only appropriate for the analysis of causal mediation effects when both the mediator and outcome models are linear regressions where treatment (IV) and moderator enter the models additively (e.g. without interaction)\n\nEffect formulas for models with an interaction between treatment and moderator (Paper)\n\nmediator: M = α2 + β2Ti + ξT2Xi + εi2(T~i`)\noutcome: Y = α~3 + β3Ti + γMi + κTiMi + ξT3Xi + εi3(Ti, Mi)\nACME = β2(γ + κt) where t = 0,1\nADE = β3 + κ{α2 + β2t + ξT2Ε(Xi)}\nATE = β2γ + β3 +κ{α2 + β2 + ξT2Ε(Xi)}\n\nAlternatively, fit Y = α1 + β1Ti + ξT1Xi + ηTTiXi + εi1\n\nThen ATE = β1 + ηTE(Xi)\n\n\nNotes\n\nVariables\n\nT is treatment, M is mediator, X is a set of adjustment variables\n\nThe exponentiated T in ξT is to let you know it can be a set of coefficients for a set of adjustment variables (I guess)\n\n\nCouldn’t figure out why curly braces are being used\nACME with have two estimates (t=0, t=1)\nATE (average total effect)\nΕ(Xi) is the sample average of each adjustment variable and it’s multiplied by its associated ξ2 coefficient\nSee paper for other types of models\n\n\n{lavaan}, {brms}\n\nTingley, Yamamoto, Hirose, Keele, & Imai, 2014\n\nQuasi-bayesian approach (paper ,esp Appendix D, for details)\n\nFits the mediation and outcome models (see 1st example)\nTakes the coefficients and vcov matrices from both models\n\nUses the coefs (means) and vcovs (variances) as inputs to a mvnorm function to simulate distributions for the coefficients.\nI do not understand what these are used for… would have to look at the code.\n\nSamples predictions of each model K times for treatment = 1, then for treatment = 0\nCalcs difference between predictions for each set of samples, then averages to get the ACME\n\nAssumes Sequential Ignorability\n\nRequires treatment randomization or an equivalent assignment mechanism\nmediator is also ignorable given the observed treatment and pre-treatment confounders. This additional assumption is quite strong because it excludes the existence of (measured or unmeasured) post-treatment confounders as well as that of unmeasured pretreatment confounders. This assumption, therefore, rules out the possibility of multiple mediators that are causally related to each other (see Section 6 for the method that is designed to deal with such a scenario).\nCan’t be tested but a sensitivity analysis can be conducted using mediation::medsens (see vignette)\n\n{mediation} (vignette)\n\nMultiple types of models for both mediator and outcome\n\nincluding multilevel model functions from {lme4} supported\n\nMethods for:\n\n‘moderated’ mediation\n\nthe magnitude of the ACME depends on (or is moderated by) a pre-treatment covariate. Such a pre-treatment covariate is called a moderator. (see Moderator Analysis)\nACME can depend on treatment status (i.e. interaction between treatment and mediator), but this situation is talking about a separate variable moderating the effect of the treatment on the mediator.\n\nmultiple mediators (which violates sequential ingnorability but can be handled)\nvarious experimental designs (e.g. parallel, crossover)\ntreatment non-compliance\n\nUses MASS (so may have conflicts with dplyr)\nNo latent variable capabilities\n\n\nEtsy article calculates generalized average causal mediation effect (GACME) and generalized average direct effect (GADE) and uses a known mediator to measure the direct causal effect even when the DAG has multiple unknown mediators (paper, video, R code linked in article)\n\nExample: Tingley, 2014 Method\n\nEquations\n\n\n\nPredictions for “job_seek” in the mediator model (top) are used as predictor values in the outcome model (bottom).\n\nData: data(jobs, package = 'mediation')\n\ndepress2: outcome, numeric: Measure of depressive symptoms post-treatment. The outcome variable.\ntreat: treatment, binary: whether participant was randomly selected for the JOBS II training program.\n\n1 = assignment to participation.\n\njob_seek: mediator, ordinal: measures the level of job-search self-efficacy with values from 1 to 5.\necon_hard: adjustment, ordinal: Level of economic hardship pre-treatment with values from 1 to 5.\nsex: adjustment, binary: 1 = female\nage: adjustment, numeric: Age in years\n\n{mediation}\nmodel_mediator &lt;- lm(job_seek ~ treat + econ_hard + sex + age, data = jobs)\nmodel_outcome  &lt;- lm(depress2 ~ treat + econ_hard + sex + age + job_seek, data = jobs)\n\n# Estimation via quasi-Bayesian approximation \nmediation_result &lt;- mediate(\n  model_mediator, \n  model_outcome, \n  sims = 500,\n  treat = \"treat\",\n  mediator = \"job_seek\"\n)\n\nSummary - summary(mediation_result)\n\n\nerror bar plot also available via plot(mediation_result)\nSays ACME isn’t significant, therefore no mediation effect detected.\n“Prop Mediated” is supposed to be the ratio of the indirect effect to the total.\n\nHowever this is not a proportion, and can even be negative, and so “it is mostly a meaningless number.”\n\n\n\n\nExample: product-of-paths (or difference in coefficients)\n\n{lavaan}\nsem_model = '\n  job_seek ~ a*treat + econ_hard + sex + age\n  depress2 ~ c*treat + econ_hard + sex + age + b*job_seek\n  # direct effect\n  direct := c\n  # indirect effect\n  indirect := a*b\n  # total effect\n  total := c + (a*b)\n'\nmodel_sem = sem(sem_model, data=jobs, se='boot', bootstrap=500)\nsummary(model_sem, rsq=T)  # compare with ACME in mediation\nDefined Parameters:\n                  Estimate  Std.Err  z-value  P(&gt;|z|)\n    direct          -0.040    0.045  -0.904    0.366\n    indirect        -0.016    0.012  -1.324    0.185\n    total            -0.056    0.046  -1.224    0.221\n\nAlso outputs the typical summary regression estimates, std.errors, pvals, R2 etc.\nBootstraps std.errors\nSame results for “indirect” here as with {mediation} ACME estimate\nR2s are poor for both regression models which could be why no mediation effect is detected.\n\n{brms}\nmodel_mediator &lt;- bf(job_seek ~ treat + econ_hard + sex + age)\nmodel_outcome  &lt;- bf(depress2 ~ treat + job_seek + econ_hard + sex + age)\nmed_result = brm(\n  model_mediator + model_outcome + set_rescor(FALSE), \n  data = jobs\n)\nsummary(med_result) # regression results\n# using brms we can calculate the indirect effect as follows\nhypothesis(med_result, 'jobseek_treat*depress2_job_seek = 0')\n\nExact same brms syntax (except priors are specified) as in Statistical Rethinking &gt;&gt; Chapter 5 &gt;&gt; Counterfactual Plots\nExample has a mediator DAG as well.\nhypothesis tests H0: a*b == 0\n\npval &lt; 0.05 says there is a mediation effect.\n\n\n{sjstats}\n\nsjstats::mediation(med_result) %&gt;% kable_df()\n\nmediator (b): the effect of “job_seek” on “depress2”\nindirect (c-c’): ACME\ndirect (c’): ADE\nproportion mediated: See {mediation} example",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-modanal",
    "href": "qmd/causal-inference.html#sec-causinf-modanal",
    "title": "Causal Inference",
    "section": "Moderation Analysis",
    "text": "Moderation Analysis\n\n\nMisc\n\nAlso see Introduction to Mediation, Moderation, and Conditional Process Analysis\n\nLike mediation analysis, it allows you to test for the influence of a third variable, Z (moderator), on the relationship between variables X and Y, but rather than testing a causal link between these other variables, moderation tests for when or under what conditions an effect occurs.\n\nModerators are conceptually different from mediators (“when” (moderator) vs “how/why” (mediator)).\n\nThere can be moderated mediation effect though. (see Mediation Analysis &gt;&gt; Methods &gt;&gt; {mediation})\n\nModerators can stengthen, weaken, or reverse the nature of a relationship.\nSome variables may be a moderator or a mediator depending on your question.\n\nAssumption: assumes that there is little to no measurement error in the moderator variable and that the DV did not CAUSE the moderator.\n\nIf moderator error is likely to be high, researchers should collect multiple indicators of the construct and use SEM to estimate latent variables.\nThe safest ways to make sure your moderator is not caused by your DV are to experimentally manipulate the variable or collect the measurement of your moderator before you introduce your IV.\n\nModeration can be tested by interacting variables of interest (moderator x IV) and plotting the simple slopes of the interaction, if present.\n\nSee Regression, Interactions for simple slopes/effects analysis\nMean center both your moderator and your IV to reduce multicolinearity and make interpretation easier. (“c” in variable names indicates variable was centered)\n\nExample: academic self-efficacy (moderator)(confidence in own’s ability to do well in school) moderates the relationship between task importance (independent variable (IV)) and the amount of test anxiety (outcome) a student feels (Nie, Lau, & Liau, 2011).\n\nStudents with high self-efficacy experience less anxiety on important tests (task importance) than students with low self-efficacy while all students feel relatively low anxiety for less important tests.\nSelf-efficacy (Z) is considered a moderator in this case because it interacts with task importance (X), creating a different effect on test anxiety (Y) at different levels of task importance.\n\nExample: What is the relationship between the number of hours of sleep (X, independent variable (IV)) a graduate student receives and the attention that they pay to this tutorial (Y, outcome) and is this relationship influenced by their consumption of coffee (Z, moderator)\nmod &lt;- lm(Y ~ Xc + Zc + Xc*Zc)\nsummary(mod)\n## Coefficients:\n##            Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept) 48.54443    1.17286  41.390  &lt; 2e-16 ***\n## Xc          5.20812    0.34870  14.936  &lt; 2e-16 ***\n## Zc          1.10443    0.15537  7.108 2.08e-10 ***\n## Xc:Zc        0.23384    0.04134  5.656 1.59e-07 ***\n\nSince we have significant interactions in this model, there is no need to interpret the separate main effects of either our IV or our moderator\nPlot the simple slopes (1 SD above and 1 SD below the mean) of the moderating effect\n\n\nFor details on this plot and analysis, see Regression, Interactions &gt;&gt; OLS &gt;&gt; numeric:numeric &gt;&gt; Calculate simple slopes for the IV at 3 representative values for the moderator variable\nInterpretation\n\nThose who drank less coffee (moderator, black line) paid more attention (outcome) with the more sleep (IV) that they got last night but paid less attention overall than average (the red line).\nThose who drank more coffee (moderator, green line) paid more attention (outcome) when they slept more (IV) as well and paid more attention than average.\nThe difference in the slopes for those who drank more or less coffee (moderator) shows that coffee consumption moderates the relationship between hours of sleep and attention paid",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-sr",
    "href": "qmd/causal-inference.html#sec-causinf-sr",
    "title": "Causal Inference",
    "section": "Statistical Rethinking",
    "text": "Statistical Rethinking\n\nMisc\n\nArrows indicate directions of influence\nArrows in DAGs “create” correlations\n\ni.e. if arrow, then correlation\nThe direction it points determines whether its association is causal or not.\n\nUnlike a statistical model, a DAG, if it is correct, will tell you the consequences of intervening to change a variable.\n** The data alone can never tell us when a DAG is right. But the data can tell us when a DAG is wrong. **\nMany dynamical systems cannot be usefully represented by DAGs, because they have complex behavior that is sensitive to initial conditions. But these models can still be analyzed and causal interventions designed from them.\nA DAG path means any series of variables you could walk through to get from one variable to another, ignoring the directions of the arrows.\nThe variable, U, in DAGs represents one or more unobserved variables\n\nUsually has circle around the U or is just represented by a dashed line\n\n“Conditioned upon,” “adjusted for,” or “controlled for” is all the same thing\n“a” or “α” is used in bayesian formulas to represent the intercept\nNotation\n\nX is not independent of Y, i.e \nconditional independence: Y is not associated with some variable X, after conditioning on some other variable Z, i.e. \n\nthey are statements of which variables should be associated with one another (or not) in the data.\nthey are statements of which variables become dis-associated when we condition on some other set of variables.\nThere is no other path of influence from X to Y except through Z\n\n\n(Total ) Causal Effect and Direct Causal Effect\n\n\nWeight (W) is the outcome, Height (H) and Sex (S) are explanatory\n(Total) Causal Effect is simply, W ~ S\nDirect Causal Effect shuts the backdoor paths, W ~ S + H\n\nSometimes we want the total causal effect and not the direct causal effect. (e.g. if H is a post-treatment variable, see SR, Ch.6)\n\n\n\n\n\nTestable Implications\n\nDiffering associations between plausible DAGs that are testable through statistical models\nAny DAG may imply that some variables are independent of others under certain conditions.\nNO conditional independencies → NO testable implications\nwww.dagitty.net - Enter DAG and it will give you the Adjustment Set and Testable Implications\nExample\n\nQuestion: What is the causal relationship between Divorce Rate (D), Marriage Rate (M), and Median Age at Marriage (A)\nData:\n\n2 regressions are fit\n\nD ~ α + βM\n\nShows that M is positively correlated with D\n\nD ~ α + βA\n\nShows that A is negatively correlated with D\n\n\n\nPlausible DAGs (note: marriage cannot influence your age… technically)\n\n\n\nA directly influences D\nM directly influences D\nA directly influences M\nReasoning: First, Age can have a direct effect, perhaps because younger people change faster than older people and are therefore more likely to grow incompatible with a partner. Second, it can have an indirect effect by influencing the marriage rate. If people get married earlier, then the marriage rate may rise, because there are more young people. Consider for example if an evil dictator forced everyone to marry at age 65. Since a smaller fraction of the population lives to 65 than to 25, forcing delayed marriage will also reduce the marriage rate. If marriage rate itself has any direct effect on divorce, maybe by making marriage more or less normative, then some of that direct effect could be the indirect effect of age at marriage.\n\n\n\nSimilar to 1 except M does not directly influence D\nReasoning This DAG is plausible even though there’s a correlation between M and D (regression 1). It could be that M derives it’s correlation with D through it’s association with A.\n\nThe direction of influence doesn’t prevent a correlation between M and D\n\n\n\nTestable implications\n\nDAG 1\n\nThe DAG shows all three are associated to each other, i.e. \nIt would be natural to think about measuring correlation and if a pair shows no correlation you could discard the DAG, but it is NOT a good test since there are many ways two variables can show correlation yet not be directly associated. (see reasoning under DAG 2 above and under DAG2 below)\nDAG1 has NO conditional independencies and therefore, NO testable implications\n\nDAG 2\n\nThis DAG also shows all three variables are associated with each other.\nD and M are associated with one another, because A influences them both. They share a cause, and this leads them to be correlated with one another through that cause. But suppose we condition on A. All of the information in M that is relevant to predicting D is in A. So once we’ve conditioned on A, M tells us nothing more about D\nThe testable implication is that D is independent of M, conditional on A, i.e. \n\n(Conditioning on A does not make D independent of M, because M really influences D all by itself in this model.)\n\ni.e A and M are marginally dependent\n\n\n\nOnly difference between both DAGs is the conditional independence in DAG2.\n\nTest\n\nRun a multiple regression D ~ α + βMM + βAA\nIf the effect measured from regression 1 disappears in the multiple regression, then we can discard DAG 1. If the effect remains, then we discard DAG 2.\n\n\nDAGs that are consistent with the data associations (M & N are associated but the causal relationship isn’t known)\n\nwhere U is an unknown variable. Unobserved variables are circled.\n\nAll three DAGs have no conditional independencies and therefore not testable implications\n\nA set of DAGs, each with the same conditional independencies known as a Markov Equivalence\n\nData cannot eliminate any of these DAGS. Domain knowledge must be used to reduce the number of Markov Equivalent DAGs.\n\n\n\n\n“Shutting the backdoor” to potential confounding paths\n\nSection 6.4\nwww.dagitty.net - Enter DAG and it will give you the Adjustment Set and Testable Implications\nRecipe\n\nList all of the paths connecting X (the potential cause of interest) and Y (the outcome).\nClassify each path by whether it is open or closed. A path is open unless it contains a collider.\nClassify each path by whether it is a backdoor path. A backdoor path has an arrow entering X.\nIf there are any backdoor paths that are also open, decide which variable(s) to condition on to close it.\n\nIf you have a choice between two variables where conditioning on either will close a backdoor path and one of them is causal to the outcome variable, then condition on the variable that is causal to the outcome variable. It will add precision to the estimate of the treatment effect.\nAny frontdoor paths that lead to backdoor paths must also be closed (see Misc &gt;&gt; Table 2 fallacy)\n\n\nExamples:\n\n\n\nProblem: We want to measure the causal effect of X –&gt; Y\nPotential confounding paths: XUAC, XUBC\n\nXUAC doesn’t have a collider so a variable needs conditioned on (aka adjusted for)\n\nU is unobserved, so either A or C. C directly influences Y, so it’s more efficient and will “aid in precision.”\n\nXUBC has a collider, B. So, no need to condition on any variable\n\nSolution: Y ~ a + X + C\n\nlibrary(dagitty)\ndag_6.1 &lt;- dagitty( \"dag { \n    U [unobserved]\n    X -&gt; Y\n    X &lt;- U &lt;- A -&gt; C -&gt; Y\n    U -&gt; B &lt;- C\n}\")\nadjustmentSets( dag_6.1 , exposure=\"X\" , outcome=\"Y\" )\n#&gt; { C }\n#&gt; { A }\n\n\nProblem: We want to measure the causal effect of the number of Waffle Houses, W, on Divorce, D.\nPotential confounding paths: WSM, WSA, WSMA (Also WSAM but McElreath on says there are 3. Maybe a combo of same letters is equivalent?)\n\nWSM doesn’t have a collider and therefore either S or M needs conditioned on\nWSA doesn’t have a collider and therefor either S or A needs conditioned on\nWSMA has a collider, M. So that path is blocked\nM is a choice for WSM but it’s a collider so it’s out. S is in both WSM and WSA, so conditioning on it kills two birds.\n\nSolution: D ~ a + W + S\n\nlibrary(dagitty)\ndag_6.2 &lt;- dagitty( \"dag {\n    A -&gt; D\n    A -&gt; M -&gt; D\n    A &lt;- S -&gt; M\n    S -&gt; W -&gt; D\n}\")\nadjustmentSets( dag_6.2 , exposure=\"W\" , outcome=\"D\" )\n#&gt; { A, M }\n#&gt; { S }\n\nEvidently conditioning on A and M is also a solution\n\nConditioning on M does close WSM but would then open WSMA. So, by then conditioning on A which is on a fork (or pipe depending on the path) it closes WSMA.\n\nIn his brms ebook, Kurz fits these regressions and a couple others for comparison. There wasn’t a consensus point estimate for W in the regressions that adjust for S and A + M.\n\nMcElreath mentions, “This DAG is obviously not satisfactory–it assumes there are no unobserved confounds, which is very unlikely for this sort of data.”\nThe inconsistent point estimates are probably do to an omitted variable(s) that is confounding the regression.\n\nConditional independencies:\nimpliedConditionalIndependencies( dag_6.2 )\n#&gt; A _||_ W | S\n#&gt; D _||_ S | A, M, W\n#&gt; M _||_ W | S",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/causal-inference.html#sec-causinf-othart",
    "href": "qmd/causal-inference.html#sec-causinf-othart",
    "title": "Causal Inference",
    "section": "Other Articles",
    "text": "Other Articles\n\nFrontdoor Adjustment\n\nFrom http://arelbundock.com/posts/frontdoor/\nUseful when an unobserved confounder creates a backdoor path that prevents direct causal estimation\nIn a causal chain with three nodes X→Z→Y, we can estimate the effect of X on Y indirectly by combining two distinct quantities:\n\nThe estimate of the effect of X on Z, P(Z|do(X))\nThe estimate of the effect of Z on Y, P(Y|do(Z), X)\n\nAssumptions\n\nFull mediation: there is no direct path from X to Y, except through Z.\nUn-confoundedness 1: There is no open backdoor from X to Z.\nUn-confoundedness 2: All backdoors from Z to Y are blocked by X\n\nExample: 1\n\nOur goal is to estimate P(Y|do(X)). Unfortunately, this relationship between X and Y is confounded by the unobserved variable U, via this backdoor path: X←U→Y. Therefore, we cannot estimate the causal quantity of interest directly.\n\n\ncause X, a mediator Z, an outcome Y, and an unobserved confounder U\n\nlibrary(data.table)\nset.seed(731460) \nN = 1e5\nU = rbinom(N, 1, prob = .2)\nX = rbinom(N, 1, prob = .1 + U * .6)\nZ = rbinom(N, 1, prob = .3 + X * .5)\nY = rbinom(N, 1, prob = .1 + U * .3 + Z * .5)\ndat = data.table(X, Z, Y)\n\n# truth\ncoef(lm(Y ~ X + U))[\"X\"]\n## 0.2549541\nEstimate the effect of X on Z, P(Z|do(X))\nstep1 = lm(Z ~ X, dat)\nEstimate the effect of Z on Y, P(Y|do(Z), X)\nstep2 = lm(Y ~ Z + X, dat)\nCombine both estimates by multiplication\ncoef(step1)[\"X\"] * coef(step2)[\"Z\"]\n## 0.2496002\n\nExample 2\n\nSame as first example but using {dosearch} package\nlibrary('dosearch')\n   data1 &lt;- \"P(X, Y, Z)\"\nquery1 &lt;- \"P(Y | do(X))\"\ngraph1 &lt;- \"U -&gt; X\n          U -&gt; Y\n          X -&gt; Z\n          Z -&gt; Y \"\n   # compute\n   frontdoor &lt;- dosearch(data1, query1, graph1)\n   frontdoor\n\nOutput:\n\nEstimate the causal effect\ndat[, `P(X)`    := fifelse(X == 1, mean(X), 1 - mean(X)) ][\n    , `P(Z|X)`  := mean(Z), by = X                      ][\n    , `P(Y|Z,X)` := mean(Y), by = .(Z, X)                ][\n    , `P(Z|X)`  := mean(Z), by = X                      ][\n    , Y := NULL                                          ]\ndat = unique(dat)\ndat[, `P(Y|do(Z))` := sum(`P(Y|Z,X)` * `P(X)`), by = Z]\n`P(Y|do(X=0))` = with(dat[X == 0], \n  `P(Z|X)`          [Z == 1] * \n  `P(Y|do(Z))`      [Z == 1] +\n  (1 - `P(Z|X)`)    [Z == 0] * \n  `P(Y|do(Z))`      [Z == 0]\n)\n`P(Y|do(X=1))` = with(dat[X == 1], {\n  `P(Z|X)`          [Z == 1] * \n  `P(Y|do(Z))`      [Z == 1] +\n  (1 - `P(Z|X)`)    [Z == 0] * \n  `P(Y|do(Z))`      [Z == 0]\n})\n`P(Y|do(X=1))` - `P(Y|do(X=0))`\n## 0.249766\nComparison\n\nTruth: 0.2549541\nlm: 0.2496002\ndosearch: 0.249766",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "qmd/business-plots.html",
    "href": "qmd/business-plots.html",
    "title": "Business Plots",
    "section": "",
    "text": "Misc",
    "crumbs": [
      "Business Plots"
    ]
  },
  {
    "objectID": "qmd/business-plots.html#sec-bizplots-misc",
    "href": "qmd/business-plots.html#sec-bizplots-misc",
    "title": "Business Plots",
    "section": "",
    "text": "{modelplotr}\n\nGithub, Vignette\nNice implementations but package is not maintained\nNotes for marketing and financial graphs taken from articles and vignettes introducing that package.",
    "crumbs": [
      "Business Plots"
    ]
  },
  {
    "objectID": "qmd/business-plots.html#sec-bizplots-market",
    "href": "qmd/business-plots.html#sec-bizplots-market",
    "title": "Business Plots",
    "section": "Marketing Plots",
    "text": "Marketing Plots\n\nTL;DR - Most useful/popular are the Cumulative Gains and Cumulative Response graphs.\nThe example objective is to select the customers of a bank that are most likely to respond to an offer to purchase a “term deposit”. The outcome is binary: “term deposit” or “no”\nInformation from models used in these plots\n\nPredicted probability for the target class\nX-Axis: Equally sized groups based on this predicted probability\n\ne.g. Splitting observations into deciles. Top 10% in predicted probability for target class would be in the first decile.\n\nNumber of observed target class observations in these groups\n\nThe test dataset is used for the plots to get a realistic idea of what a marketing campaign in the would would produce.\n\nResponse Plot has some GOF capability so I could maybe see using the validation set with that plot to compare models with.\n\n\n\nCumulative Gains\n\n\nAKA Gains Plot\nAnswers the question: “When we apply the model and select the best X quantiles, what % of the actual target class observations can we expect to target?”\n\ny-axis = % of positive events (1s in binary classification) out of the entire dataset\n\nHow to apply:\n\nChoose a probability threshold (i.e. the corresponding quantile on the x-axis). The graph shows the percentage of observations on the y-axis that are within that threshold\nChoose the percentage of customers that you can afford to target with your campaign. The corresponding quantile on the x-axis shows the quantile and therefore the associated probability of positive result.\n\n“When we select 20% with the highest probability according to gradient boosted trees, this selection holds 87% of all term deposit cases in test data.”\n\nSays using the top 20% will include 87% of all the 1s (in binary classification) in the entire dataset.\n\n\nIf the gains is 87%, then there are potentially 13% of the total 1s that won’t be included in the campaign if we only target the top 20% percent.\n\nwizard model (perfect model) line - line takes steepest route to 100% on y-axis as possible, depending on the percentage of your outcome variable is the target level.\n\nFor the graph above, it looks like around 12% of the outcome variable values are the positive event case since the line reaches the 100% on the y-axis a little past the 1st decile. So the perfect model predicts all those values as being the positive class.\n\n\n\n\nCumulative Lift\n\n\nAKA Index or Lift Plot\nEspecially useful for companies with little to no experience with data models\nAnswers the question: “When we apply the model and select the best X quantiles, how many times better is that than using no model at all?”\n“no model at all” (i.e. coin flip) is a random model (also seen in the gains plot) is represented by a horizontal line at y = 1 or 100% depending on how the y-axis is specified. It is the ratio of the % of actual target category observations in each quantile to the overall % of actual target category observations after randomization of the rows of the data set.\nThe amount of lift can’t be generalized to all models and all data sets. So there aren’t guidelines as to what is a “good” lift score and what isn’t. If 50% of your data belongs to the target (positive) class of interest, a perfect model would ‘only’ do twice as good (lift: 2) as a random selection. If 10% of the data belong to the positive class, then lift = 10 or 1000% is the best possible lift score.\nHow to apply:\n\nChoose a quantile (x-axis) and the corresponding y value can be used to explain to stakeholders how many times or what percent better this model is at selecting the top prospects than random selection.\n\n“A term deposit campaign targeted at a selection of 20% of all customers based on our gradient boosted trees model can be expected to have a 4 times higher response (434%) compared to a random sample of customers.”\n\n\n\n\n\nResponse Plot\n\n\nPlots the percentage of *target class* observations per quantile\n\nnote: the cumulative gains y-axis is total observations where this plot’s y-axis is just positive class (1s in a binary classification model)\n\nAnswers the question: “When we apply the model and select quantile X, what is the expected % of target class observations in that quantile?” but also gives information about the model fit.\nHow to apply:\n\nThis plot is more important in what it tells about the model fit than what it says about how many observations are in a particular quantile\n\nA good fitting model will have a sharp sloping line with the highest response % in the lower quantiles. This says that the model is giving high probability scores to the vast majority of the positive class observations\nFor model comparison: the earlier the line crosses the horizontal (random model) line should indicate a steeper slope and therefore a better fit.\n\n“When we select decile 1 (10th percentile) according to model gradient boosted trees in dataset test data the % of term deposit cases in the selection is 51%.”\nThe horizontal line represents a random model (i.e. the % of target class cases in the total set)\n\nFrom the quantile where the line intersects the horizontal dashed-line and onwards, the % of target class cases is lower than a random selection of cases would hold.\n\n\n\n\n\nCumulative Response\n\n\nAnswers the question: “When we apply the model and select up until quantile X, what is the expected % of target class observations in the selection?\n\nOften used to decide - together with business colleagues - up until what decile to select for a marketing campaign\n\nHow to apply:\n\n“When we select quantiles 1 until 30 according to model gradient boosted trees in dataset test data, the % of term deposit cases in the selection is 36%.”\n\nIn other words, targeting these customers should produce a response rate (percent of customers purchasing a term deposit) of 35% on average as compared to randomly selecting the same number of customers which is 12% (term deposits/total obs for the test set).\nThe y-axis is the percentage of 1s (in binary classification) in that subset (quantiles from 1 to 30). Different from cumulative gains where the y-axis is the percentage of 1s in the entire dataset.\n\nIs that response big enough to have a successfull campaign, given costs and other expectations? Will the absolute number of sold term deposits meet the targets? Or do we lose too much of all potential term deposit buyers by only selecting the top 30%? To answer that question, we can go back to the cumulative gains plot.\nThe dashed horizontal is the same as in the Response Plot",
    "crumbs": [
      "Business Plots"
    ]
  },
  {
    "objectID": "qmd/business-plots.html#sec-bizplots-fin",
    "href": "qmd/business-plots.html#sec-bizplots-fin",
    "title": "Business Plots",
    "section": "Financial Plots",
    "text": "Financial Plots\n\nExample objective is to select the customers of a bank that are most likely to respond to an offer to purchase a “term deposit”. The outcome is binary: “term deposit” or “no”\n\nfixed costs = $75,000 (a tv commercial and some glossy print material)\nvariable costs per unit = $50 (customers are given an incentive to buy)\nprofit per unit = $250\n\nInformation from models used in these plots\n\nSame stuff as Marketing Plots\nFixed Costs (e.g. sales force expenses, advertising campaigns, sales promotion, and distribution costs)\nVariable Costs per unit (e.g.sales commission, bonuses, and performance allowances)\nProfit per Sale\n\nThe test dataset is used for the plots to get a realistic idea of what a marketing campaign in the would would cost and return. A validation set could be used on the Revenue and Costs Plot and models could be compared based risk of nonprofitability.\n\n\nProfit Plot\n\n\nAnswers the question: “When we apply the model and select up until quantile X, what is the expected profit of the campaign?”\nHow to apply:\n\nThe most profitable quantile is the one directly under the apex of the curve.\nThe most profitable quantile is highlighted by default, but this can be specified if so desired\nannotation means?\n\n\n\n\nCosts and Revenues Plot\n\n\nAnswers the question: “When we apply the model and select up until decile X, what are the expected revenues and investments of the campaign?”\nThe costs are the cumulative costs of selecting up until a given decile and consist of both fixed costs and variable costs.\nThe revenues take into account the expected response % - as plotted in the cumulative response plot - as well as the expected revenue per response.\nSolid curve is the revenue and the dashed diagonal line is the total costs\nHow to apply:\n\nThe campaign is profitable in the plot area where revenues exceed costs.\nGives an idea of the range of spending that can be considered while the campaign remains profitable. Ranges could be associated with risk. The smaller the range, the greater the risk given the uncertainty of the models. Various campaign ranges could be compared based on this risk.\nSee profits plot for optimal quantile.\n\n\n\n\nROI Plot\n\n\nAnswers the question: “When we apply the model and select up until decile X, what is the expected % return on investment of the campaign?”\nThe quantile at which the campaign profit is maximized is not necessarily the same as the quantile where the campaign ROI is maximized\n\nIt can be the case that a bigger selection (higher decile) results in a higher profit, however this selection needs a larger investment (cost), impacting the ROI negatively.\nSo maximum ROI can be considered the most effficient use of resources, but it takes money to make (the most) money.\n\nBasic formula for ROI = Net Profit / Total Investment * 100\nHow to apply:\n\nThe quantile directly underneath the apex of the curve is where the ROI is maximized.",
    "crumbs": [
      "Business Plots"
    ]
  },
  {
    "objectID": "qmd/web-design.html",
    "href": "qmd/web-design.html",
    "title": "Web Design",
    "section": "",
    "text": "Misc",
    "crumbs": [
      "Web",
      "Web Design"
    ]
  },
  {
    "objectID": "qmd/web-design.html#sec-webdes-misc",
    "href": "qmd/web-design.html#sec-webdes-misc",
    "title": "Web Design",
    "section": "",
    "text": "Using “Brand” to help choose font, palette, and imagery\n\nNotes from Erik Kennedy Video\nBrand is just adjectives to describe your business, organization, etc.\n\ne.g. Trustworthy, Geeky, Casual, Precise, Fun, Technical, etc.\n\nCommon Brands\n\n\n“Neat, modern”, “Luxury, formal”, etc. are more of what I’d consider brand adjectives\n“Clean & Simple”,“Fancy”, “Techie”, etc. are how I’d describe the sites that epitomize those brands, but they could also be brand descriptors\n\nBlending Brands\n\n\nShows names of company websites that most represent the brand/website types\ne.g. The Apple website is a blend of Techie and Fancy.\n\n\nWebsites should be under 14kb (article)\n\nMost web servers TCP slow start algorithm starts by sending 10 TCP packets which works out to 14kb\n\n404 pages\n\nGuidelines\n\nbe brief: the message on the 404 page should be straightforward and easy to understand, informing the user that the page they were trying to access is not available.\nbe contrite: the tone of the 404 page should be friendly and apologetic, acknowledging the user’s inconvenience and expressing empathy.\nbe helpful: provide links to other areas of the website or a search box that can help users find what they’re looking for quickly and easily.\nbe informative: include contact information, such as a feedback form, social media account, or email address to give users an alternative way to reach out to you for assistance.\nbe you: incorporate your brand’s visual identity, including logos and colors, to help reinforce brand recognition and create a cohesive user experience.\n\nExamples\n\n404 Page SVG Animations That Maximize Visitor Retention\n21 Stunning 404 Pages to Convert Lost Visitors 2023\nguinslym/awesome-404: A curated list of awesome 404 web pages greynoise’s ‘404’ equivalent and hrbmstr’s.",
    "crumbs": [
      "Web",
      "Web Design"
    ]
  },
  {
    "objectID": "qmd/git-general.html",
    "href": "qmd/git-general.html",
    "title": "26  General",
    "section": "",
    "text": "26.1 Misc",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  },
  {
    "objectID": "qmd/git-general.html#misc",
    "href": "qmd/git-general.html#misc",
    "title": "26  General",
    "section": "",
    "text": "View HTML file in browser\n\nSyntax: “https://raw.githack.com/&lt;acct name&gt;/&lt;repo name&gt;/&lt;branch name&gt;/&lt;directory name&gt;/&lt;file name&gt;.html”\n\nInstalling from a git repo (From link)\n\nMake a fork of the repo and then clone it to your local machine.\nTo update, after setting an upstream remote (git remote add upstream git://github.com/benfulcher/hctsa.git) you can use git pull upstream main.\nTo update the submodule in the repo, git submodule update --init\n\nStart R project and Git repo in whichever order (I think)\n\nCreate R project in RStudio\n\nChoose “New Directory” for all the templated projects (e.g. quarto book, shiny, etc.). None of the other choices have them.\n\nIf you’ve already created a directory, it will NOT overwrite this directory or add to it. So you’ll either have alter the name of your old directory or choose a new name.\n\n\nCreate repo on Github\n\nAdd license and readme\n\nDo work\nTools &gt;&gt; Version Control &gt;&gt; Project Set-up &gt;&gt; Version Control System &gt;&gt; Select Git\nOpen terminal and go to working directory of project\ngit checkout -B main\ngit pull origin main --allow-unrelated-histories\ngit add .\ngit commit -m \"initial commit\"\ngit push --set-upstream origin main \n\nTurn off “LF will be replaced by CRLF the next time Git touches it”\n\nMessage spams terminal when committing changes from a window machines. Has to do with line endings in windows vs unix.\nTurn off: git config core.autocrlf true\nSee SO post for more details\n\nURL format to download files from repositories\n\nhttps://raw.githubusercontent.com/user/repository/branch/filename\n\n# Or evidently this way works too\n# adds ?raw=true to the end of the url\nfeat_all_url &lt;- url(\"https://github.com/notast/hierarchical-forecasting/blob/main/3feat_all.RData?raw=true\")\nload(feat_all_url)\nclose(feat_all_url)\nGet filelist from repo and download to a directory\n\n** Directory urls change as commits are made **\n\nlibrary(httr)\n\n# example: get url for the data dir of covidcast repo\nreq &lt;- httr::GET(\"https://api.github.com/repos/ercbk/Indiana-COVIDcast-Dashboard/git/trees/master?recursive=1\") %&gt;% \n  httr::content()\n# alphabetical order\ntrees &lt;- req$tree %&gt;% \n  map(., ~pluck(.x, 1)) %&gt;% \n  as.character()\n# returns 20 which is first instance, so 19 should the \"data\" folder\ndetect_index(trees, ~str_detect(., \"data/\"))\n# url for data dir\nreq$tree[[19]]$url\n\n# example\n# Get all the file paths from a repo\nreq &lt;- GET(\"https://api.github.com/repos/etiennebacher/tidytuesday/git/trees/master?recursive=1\")\n# any request errors get printed\nstop_for_status(req)\nfile_paths &lt;- unlist(lapply(content(req)$tree, \"[\", \"path\"), use.names = F)\n# file_path wanted &lt;- filter file path to file you want\n# gets the very last part of the path\nfile_wanted &lt;- basename(file_path_wanted)\norigin &lt;- paste0(\"https://raw.githubusercontent.com/etiennebacher/tidytuesday/master/\", file_wanted)\ndestination &lt;- \"output-path-with-filename-ext\"\n# if file doesn't already exist, download it from repo into destination\nif (!file.exists(destination)) {\n      # if root dir doesn't exist create it\n      if (!file.exists(\"_gallery/img\")) {\n        dir.create(\"_gallery/img\")\n      }\n      download.file(origin, destination)\nThe insides of .git",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  },
  {
    "objectID": "qmd/git-general.html#optimizations",
    "href": "qmd/git-general.html#optimizations",
    "title": "26  General",
    "section": "26.2 Optimizations",
    "text": "26.2 Optimizations\n\nFor large repos, simple actions, like running git status or adding new commits can take many seconds. Cloning repos can take many hours.\nBenefits\n\nIt improves the overall performance of your development workflow, allowing you to work more efficiently. This is especially important when working with large organizations and open source projects, where multiple developers are constantly committing changes to the same repository. A faster repository means less time waiting for Git commands such as git clone or git push to finish. It helps to optimize the storage space, as large files are replaced by pointers which take up less space. This can help avoid storage issues, especially when working with remote servers.\n\nMisc\n\nSee How to Improve Performance in Git: The Complete Guide\n\nExplainer, config settings, advanced gc, checkout, and clone commands\n\nUse .gitignore\n\nGenerated files, like cache or build files\n\nThey will be modified at each different generation — and there’s no need to keep track of those changes.\n\nThird-party libraries\n\nInstead, aim for a list of the required dependencies (and the correct version) so that everyone can download and install them whenever the repo is cloned.\n\nFor example, with a package.json file for JavaScript projects you can (and should) exclude the /node_modules folder.\n.DS_Store files (which are automatically created by macOS) are another good candidate\n\n\n\nGit LFS\n\nDesigned specifically to handle large file versioning. LFS saves your local repositories from becoming unnecessarily big, preventing you from downloading unnessary data.\n\nGit LFS intercepts any large files and sends them to a separate server, leaving a smaller pointer file in the repository that links to the actual asset on the Git LFS server.\n\nThis is an extension to the standard Git feature set, so you will need to make sure that your code hosting provider supports it (all the popular ones do).\nAlso need to download and install the CLI extension on your machine before installing it in your repository.\nSet-Up\n$ git lfs install\n$ git lfs track \"*.wav\"\n$ git lfs track \"images/*.psd\"\n$ git lfs track \"videos\"\n$ git add .gitattributes\n\nTells Git LFS which file extensions it should manage.\n.gitattributes notes the file names and patterns in this text file and, just like any other change, it should be staged and committed to the repository.\nCan now add files and commit as normal\nList all file extensions being tracked: git lfs track\nList all files being managed: git lfs ls-files",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  },
  {
    "objectID": "qmd/git-general.html#troubleshooting",
    "href": "qmd/git-general.html#troubleshooting",
    "title": "26  General",
    "section": "26.3 Troubleshooting",
    "text": "26.3 Troubleshooting\n\nKeeps asking for username/password when pushing\n\nSolution: You (or if you used usethis::use_github/git) probably set-up a https connection when you need a ssh connection.\n\nsee https://docs.github.com/en/get-started/getting-started-with-git/managing-remote-repositories#changing-a-remote-repositorys-url to change from https to ssh.\n\n\nUndo a commit, but save changes made (e.g. you forgot to pull before you pushed)\n\nSteps\n\ngit log - Shows commit history. Copy the hash for your last commit\ngit diff &lt;last commit hash&gt; &gt; patch - save the diff of the latest commit to a file\ngit reset --hard HEAD^ to revert to the previous commit\n\n**After this, your changes will be lost locally **\n\ngit log - confirm that you are now at the previous commit\ngit pull - correct the mistake you made in first place\npatch -p1 &lt; patch - apply the changes you originally made\ngit diff - to confirm that the changes have been reapplied\nNow, you do the regular commit, push routine\n\n\nUndo uncommitted changes: git stash followed by git stash drop\n\n“but only use if you commit often” - guessing this is not good if your commit is somehow large and/or involves multiple files\n\nSearch commits by string: git log --grep &lt;string&gt;",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  },
  {
    "objectID": "qmd/git-general.html#pulling",
    "href": "qmd/git-general.html#pulling",
    "title": "26  General",
    "section": "26.4 Pulling",
    "text": "26.4 Pulling\n\nSave your changes, pull in an update, apply your changes\ngit stash\ngit pull\ngit stash pop\n\ngit stash pop throws away the (topmost, by default) stash after applying it, whereas\ngit stash apply leaves it in the stash list for possible later reuse (or you can then git stash drop it).\n\nRe potential merge conflicts\n\n“For instance, say your stashed changes conflict with other changes that you’ve made since you first created the stash. Both pop and apply will helpfully trigger merge conflict resolution mode, allowing you to nicely resolve such conflicts… and neither will get rid of the stash, even though perhaps you’re expecting pop too. Since a lot of people expect stashes to just be a simple stack, this often leads to them popping the same stash accidentally later because they thought it was gone.”\n\nPulling is fetching + merging\n\nFetching just gets the info about the commits made to the remote repo\ngit fetch origin\nSome technical discussion for always using git pull –ff\n\nhttps://blog.sffc.xyz/post/185195398930/why-you-should-use-git-pull-ff-only-git-is-a\nhttps://megakemp.com/2019/03/20/the-case-for-pull-rebase/\nit’s still confusing but pull rebase sounds fine to me\n–global tag says do it for all my repos\nnot sure what the true and only are for\n\ngit pull –help will open doc in browser\n\n\nPulling by rebase\n\nLocal: using this method as default\ngit config pull.rebase true\ngit pull\nRemote\ngit pull --rebase\n\nPulling by fast-forward\n\nLocal: using this method as default\ngit config --global pull.ff only\ngit pull\nRemote\ngit pull --ff",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  },
  {
    "objectID": "qmd/git-general.html#branching",
    "href": "qmd/git-general.html#branching",
    "title": "26  General",
    "section": "26.5 Branching",
    "text": "26.5 Branching\n\nMisc\n\nCreate a new branch for each ticket you are working on or each data model. It can get sloppy when you put all your code changes on one branch.\n\nCreate a branch (e.g. “testing”)\ngit branch testing\nWork in a branch\ngit checkout testing\nThe files in your working directory change to the version saved in that branch\nIt adds, removes, and modifies files automatically to make sure your working copy is what the branch looked like on your last commit to it.\nCreate and work in a branch\n# new way\ngit switch -c testing\nor\ngit checkout -b testing\nor\ngit branch testing\ngit checkout testing\ncreates the branch and switches you to working in that branch\nIf you did a bunch of changes in a codebase, only to realize that you’re working on `master`,  switch will bring those local changes with you to the new branch. So I guess they won’t affect master then.\n\nUnless If you already committed to main, then those changes are both in your new branch and in main. So you would still have to clean up the main branch.\n\nDeleting a branch\n\nlocal branch\ngit branch -d testing\n\nremote branch\ngit push &lt;remoteName&gt; --delete &lt;branchName&gt;\nSee existing branches\ngit branch\nSee what has been commited the remote repo branches\ngit fetch origin\ngit branch -vv\n“origin” is the name of the remote\nresult\ntesting    7e424c3 [origin/testing: ahead 2, behind 1] change abc \nmaster      1ae2a45 [origin/master] Deploy index fix\n* issue    f8674d9 [origin/issue: behind 1] should do it         \ncart        5ea463a Try something new\nformat: branch, last commit sha-1, local branch status vs remote branch status, commit message\nthe star indicates the HEAD pointer’s location (where you’re at, i.e. checkout)\ntesting branch\n\n“ahead 2” means  I committed twice to the local testing branch and this work has not been pushed to the remote testing branch repo yet.\n“behind 1” means someone has pushed a commit to the remote testing branch repo and we haven’t merged this work to our local testing branch\n\nGet the last 10 branches that you’ve committed to locally:\ngit branch --sort=-committerdate | head -n 10\nRename branch\n# change locally\ngit branch --move &lt;bad-branch-name&gt; &lt;corrected-branch-name&gt;\n# change remotely in repo\ngit push --set-upstream origin &lt;corrected-branch-name&gt;\n# confirm change\ngit branch --all\nHEAD determines to which branch new commits are added\n\nExample\n\n“testing” branch is created (not shown in above picture)\n\nHEAD points at “master” branch\n“master” branch and the new “testing” branch both point at commit, f30ab.\nf30ab commit points to previous commit 34ac2\n\nuser executes checkout to “testing” branch (not shown in picture)\n\nHEAD now points to testing branch\n\nuser commits 87ab2 (shown in pic)\n\n87ab2 is committed to the “testing” branch\n“testing” branch is now ahead of the “master” branch by 1 commit\n\n\nExample\n\nEverything above happens but now another user commits the master branch.\n\nBoth branches are in conflict. The testing branch is ahead and behind by 1 commit\n\n\n\nMerging\n\n\nNotes\n\nNEVER merge your branch locally on your machine with the master branch, ALWAYS merge online via pull request\n\nSteps\n\nPush final changes and use of a pull request\nSwitch to master branch locally and pull the merged changes\n\n\n\nUpdate branch with work that’s been done in master branch\n\nAfter updating your local branch, push to remote repo (no commit necessary)\n# while in branch\ngit merge master\n\n\nFast-Forward\n\nExample\n\nBefore the merge\n\nthe testing branch is 1 commit ahead of the master branch and the master branch doesnt have a new commit\n\nAfter the merge\n\nmaster is moved forward to the testing branch commit\n\n\nCode (merging work in branch with the master branch for production)\n# currently in test branch\ngit checkout master\ngit merge testing\n\nLines in file are marked\n# &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.html\n# &lt;div id=\"footer\"&gt;contact : email.support@github.com&lt;/div&gt;\n# =======\n# &lt;div id=\"footer\"&gt;\n# please contact us at support@github.com\n# &lt;/div&gt;\n# &gt;&gt;&gt;&gt;&gt;&gt;&gt; iss53:index.html\nAbove ======= is the master branch version of the code and below is the iss53 branch version\nMake necessary changes and save the file\ngit add . or git add &lt;resolved file&gt;\n\nTells git that conflict is resolved\n\nCheck status to confirm everything has been resolved\ngit status\n\n    On branch master\n    All conflicts fixed but you are still merging.\n      (use \"git commit\" to conclude merge)\n    Changes to be committed:\n      modified:  index.html\ngit commit\n\nno message required (there’s a default message) but you can add one if you want\n\nExample\n\niss53 branch ahead of master by 2 commits (c3, c5) and behind 1 commit (c2)\nSame code as Fast-Forward merge but git handles the merge a bit differently\ngit checkout master \ngit merge iss53\n\n\n\nC6 (right pic) is called a “merge commit.” Its created by git and points to two commits instead of one.\nNo need to merge with master (i.e. update local iss53 branch with c4 changes in master) before committing final changes\n\nIf there are changes in the same lines of code C4 and C5, then there will be a conflict (See below, Conflicts &gt;&gt; Example)\n\n\nConflicts\n\nExample\n\nChanged files in C4 (see above example) are in the same lines of the same files that you made changes to in C5\n\nRemember: you’re now in the master branch since you did checkout master as part of the merge code\nSteps\n\nCheck status to which files are causing the conflict (e.g. index.html)\ngit status\n  Unmerged paths:\n  (use \"git add &lt;file&gt;...\" to mark resolution) \n    both modified:      index.html\n\n\n\n\nMoving between branches\n\nfrom master to testing\ngit checkout testing\n\nlocal files are deleted and replaced with branch versions\n\nalternative: worktree\n\nExample\n\nWhat happens when you move from branch-a to branch-b\nBRANCH-A        BRANCH-B\nalpha.txt      alpha.txt\nbravo.txt\ncharlie.txt    charlie.txt\n                delta.txt\n\nbravo text is deleted from your local disc and delta.txt is added\nIf any changes to alpha.txt or charlie.txt have been made and no commit has been made, the checkout will be aborted\n\nSo either revert the changes or commit the changes\n\nUntracked files or newly created files\n\nIf you have branch-A checked out and you create a new file called echo.txt, Git will not touch this file when you checkout branch-B. This way, you can decide that you want to commit echo.txt against branch-B without having to go through the hassle of (1) move the file outside the repo, (2) checkout the correct branch, and (3) move the file back into the repo.",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  },
  {
    "objectID": "qmd/git-general.html#collaboration",
    "href": "qmd/git-general.html#collaboration",
    "title": "26  General",
    "section": "26.6 Collaboration",
    "text": "26.6 Collaboration\n\nAdd collaborators to your repository\nOne person invites the others and provides them with read/write access (github docs)\n\nSteps\n\nGo to the settings for your repository\nmanage access &gt;&gt; “invite a collaborator”\n\nSearch for each collaborator by full name, acct name, or email\nClick “Add &lt;name&gt; to &lt;repo&gt;”\n\nEach collaborator will need to accept the invitation\n\nSent by email",
    "crumbs": [
      "Git",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>General</span>"
    ]
  }
]